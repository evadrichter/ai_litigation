,Unnamed: 0,Caption,Brief Description,Algorithm,Jurisdiction,Application Areas,Cause of Action,Issues,Date Action Filed,New Activity,Link,Status,sig_summary,ext_summary,recent_activity,Year Filed,Status_Cat
0,0,A.T. v. OpenAI LP,"Plaintiffs file lawsuit against OpenAI and related entities, alleging that their collection of data to train their generative AI products, including ChatGPT, Dall-E, and Vall-E, violates the Electronic Communications Privacy Act, the Computer Fraud and Abuse Act, the California Invasion of Privacy Act, the California Unfair Competition Law, and the New York General Business Law, and gives rise to causes of action for negligence, invasion of privacy, intrusion upon seclusion, larceny / receipt of stolen property, conversion, and unjust enrichment.",ChatGPT,Federal: US Dist. Ct. N.D. Ca.,Generative AI,"California Invasion of Privacy Act, Computer Fraud and Abuse Act, 18 USC 1030, Conversion, Electronic Privacy Communications Act, 18 USC 2510, Intrusion Upon Seclusion, Larceny / Receipt of Stolen Property, New York General Business Law, Negligence, Right to Privacy, Unjust Enrichment",Accountability,2023-09-05,9/5/2023,https://blogs.gwu.edu/law-eti/?page_id=10&pid=101,Active,,"Summary of Facts and Activity to DateComplaint filed September 5, 2023",Complaint filed,2023.0,Active
1,1,"ACLU v. Clearview AI, Inc.","Class transferred and consolidated into In re Clearview, complaint charged that Clearview violated violates BIPA. Sought injunctive relief and litigation costs, court considering motion to dismiss on April 2",Clearview,"State: Ill. Cir. Ct. (Cook County, Chancery Div.)",Facial Recognition,BIPA,Privacy,2020-05-28,5/11/2022,https://blogs.gwu.edu/law-eti/?page_id=10&pid=34,Closed (Settlement),"Under the terms of the settlement, Clearview is banned from making its faceprint database available to most businesses and other private entities nationwide. Clearview is also barred from selling access to its database to any entity in Illinois, including state and local police, for five years. Clearview must also also allow Illinois residents to block their facial data from Clearview's Database. Clearview still has the ability to contract with other state governments and the federal government, and any other contractor that is engaged in authorized support of a government agency.","Summary of Facts and Activity to DateThe plaintiffs filed this class action against Clearview for violating plaintiffs' rights under BIPA by collecting images and data without their knowledge, ""much less the consent"" of the plaintiffs, then storing the data. The complaint requested injunctive relief against Clearview for collecting face prints from photographs online, compiling those into a database, and keeping links of where they got the images. The crux of the issue is that Clearview has not attempted to inform or obtain consent from the people it is collecting data on. The next issue is Clearview's clientele: it offered billionaires, individual police officers without the agency's knowledge, and multiple major retail chains.Clearview ""voluntarily"" ended all accounts of all non-government users and all Illinois entities in an attempt to avoid jurisdiction.Clearview filed its motion to dismiss on October 7, 2020, arguing: 1. Clearview is not subject to jurisdiction in Illinois because it ended all of its conduct in Illinois, alternatively suggests it collects photos from NY, 2. BIPA does not regulate out of state conduct, 3. Clearview is protected under the First Amendment, and 4. even if Clearview was subject to BIPA, BIPA does not regulate photographs.Plaintiffs filed a surreply on January 5, 2021 that 1. BIPA is not a direct regulation of speech, 2. BIPA is not subject to strict scrutiny and 3. BIPA survives intermediate scrutiny.On May 11, 2022 The court signed a consent order ending the case.","Court signed consent order ending case on May 11, 2022",2020.0,Settled
2,2,ACLU v. DOJ,"The ACLU of Massachusetts brought suit against the Department of Justice, Drug Enforcement Agency and the Federal Bureau of Investigation in response to the lack of response to their Freedom of Information Act Request for all policies, contracts and records relating to facial recognition and identifying program and technology.",,Federal: US Dist. Ct D. Massachusetts,"Constitutional Law, Facial Recognition","FOIA 5 U.S.C. § 552, Injunction","Facial Recognition, Privacy, Use of Race, Unreliability/Miscalculationns",2019-10-31,10/13/2021,https://blogs.gwu.edu/law-eti/?page_id=10&pid=10,Active,,Summary of Facts and Activity to Date,Closed without entry of judgement (may be reopened upon motion of any party when their present cooperation on FBI's processing of responsive documents comes to an end).,2019.0,Active
3,3,"Aerotek, Inc. v. Boyd",Texas Supreme Court rules that e-signatures on new hire paperwork can compel arbitration for a company that was sued for racial discrimination,,State: Texas Circuit Court,"Employment, Hiring","Contracts, Arbitration",Use of Race,2018-01-01,7/1/2021,https://blogs.gwu.edu/law-eti/?page_id=10&pid=58,Active: On Remand,"This case concerns electronic hiring application, requiring signatures on multiple documents including a mutual arbitration agreement before continuing with the hiring paperwork. Each applicant had a unique username and password that is tied to each document. The plaintiffs all claimed that they had never seen the arbitration agreement when Aerotek moved to compel arbitration at trial. However, Boyd's unique username and password was date and timestamped as reviewing and accepting the arbitration policy. The Texas Supreme Court found this use of electronic onboarding requiring arbitration polices more common, especially those companies with Texas injury benefit plans.","Summary of Facts and Activity to DateThe plaintiffs were four contractors hired by Aerotek to be placed with client companies. The plaintiffs sued corporation Aerotek for racial discrimination and retaliation after being fired. Aerotek filed a motion to compel arbitration that the plaintiffs allegedly agreed to during electronic onboarding. The trial court ruled that Aerotek had failed to conclusively establish validity of the arbitration agreement. At trial, the Federal Arbitration Act governed, and although Aerotek provided evidence of Boyd's unique ID being used and the date stamp, because Boyd said he has never seen the agreement before, the court followed an El Paso Case that the ""facts"" issue could be resolved by the judge in Boyd's favor. The dissent disagreed, instead arguing that the standard of review should be whether “Aerotek presented evidence that a reasonable fact finder could not disregard establishing appellees’ electronically signed the arbitration agreement at issue despite appellees’ statements that they had not agreed to arbitrate.” The Dallas Court of Appeals on August 27, 2019 affirmed the trial court's finding for the plaintiffs. Aerotek appealed to the Texas Supreme Court, who granted review on February 25, 2020. The court ultimately reversed and remanded, finding that the trial court erred in denying the motion to compel arbitration because there is no way the four could have completed onboarding without signing the agreement and that there was a valid contract. This inability to avoid the arbitration agreement is highlighted by the option to complete the application ni person if the person does not have access to the technology: three of the four completed it online and one completed the application in the office with an administrative assistant, and all four signed the arbitration caluse. The dissent from the Texas Supreme Court","Billing Issued, Reverse and Remanded",2018.0,Active
4,4,Andersen v. Stability AI Ltd.,"Three artists file class action lawsuit alleging copyright infringement, violation of rights of publicity, and other causes of action based on use of their visual art as training data for an artificial intelligence image generation tool.",Stable Diffusion,Federal: US Dist. Ct. N.D. Ca.,"Copyright, Generative AI, Intellectual Property","Copyright Infringement, Unfair Competition, Right of Publicity, 17 U.S.C. 1202 Removal of Copyright Management Information",Misuse of AI,2023-01-13,10/30/2023,https://blogs.gwu.edu/law-eti/?page_id=10&pid=82,,"This is the first lawsuit filed in the United States alleging that an artificial intelligence image generation tool infringed the copyright and the rights of publicity of artists by using their works as training data. In the Order on Motions to Dismiss and Strike filed on October 30, 2023, the court limited the lawsuit in a number of significant ways. First, the court made clear that the copyright actions depend on registration of the plaintiffs' works; it dismissed the copyright actions of two of the three plaintiffs (McKernan and Ortiz) because they had not registered claims of copyright in any of their works, and it limited the copyright actions of plaintiff Andersen to the works in which she had registered claims of copyright. Second, the court was skeptical of plaintiffs' claims that the Stable Diffusion or Midjourney models could contain ""compressed copies"" of works owned by the plaintiffs, and it also suggested that the models could not be ""derivative"" of the plaintiffs' works in the copyright sense without being substantially similar to those works. Third, the court concluded that the complaint did not contain specific enough allegations that the defendants had removed copyright management information from the plaintiffs' works in violation of 17 USC 1202. Fourth, the court concluded that the complaint did not contain specific enough allegations about how the defendants violated the plaintiffs' right of publicity by using their names in advertising, or by allowing users of the text-to-image tools to use their names to generate images.  Fifth, the court held that the unfair competition claims were preempted by the Copyright Act insofar as they depended on copying, and otherwise were not supported by specific enough allegations of fraud. Sixth, the court held that the plaintiffs had not yet provided sufficient allegations that defendant DeviantArt breached its contract with the plaintiffs.  While most of the motions to dismiss were granted with leave to amend, this opinion has placed many obstacles in the plaintiffs' pursuit of many of their claims.","Summary of Facts and Activity to DateThree artists -- Sarah Andersen, Kelly McKernan, and Karla Ortiz -- filed this lawsuit on behalf of a class of artists against four defendants -- Stability AI, Ltd. Stability AI, Inc., Midjourney, Inc., and DevantArt, Inc. -- alleging that visual art that the artists created were used as training data for an artificial intelligence image generation tool called Stable Diffusion, also used by the public under the names Midjourney, DreamStudio, and DreamUp.  Plaintiffs allege use of their visual art infringed their copyright in that art, violated their rights of publicity, involved unlawful removal of copyright management information, and amounted to unfair competition.The complaint alleges that defendants copied their images to use as training data for Stable Diffusion, and also alleges that Stable Diffusion maintains what are effectively copies of their images, because they are files that allow the images to be reconstructed from random noise. The complaint also alleges that the resulting AI image generation tools, all of which are based on Stable Diffusion, allow users to create art ""in the style"" of particular artists, and that that capability violations both the Copyright Act and the artists' right of publicity.On October 30, 2023, the court issued an order granting many of the defendants' motions to dismiss and strike, many of which with leave to amend - see the Summary of Significance for details.",Order on Motions to Dismiss and Strike,2023.0,Not specified
5,5,Ark. Dep’t of Human Servs. v. Ledgerwood,"Low income plaintiffs with physical disabilities sued when the Department of Health Services replaced their nurse assessment questionaire ArPath to determine hours of care with Resource Utilization Groups, drastically reducing attendant-care hours allotted per patient, successfully challenged this rulemaking under the APA and court unanimously granted a permanent injunction",RUGs,State: Arkansas,"Disabilities Benefits, Health, Public Benefits","Administrative Procedure Act, Permanent Injunction, Preliminary Injunction","Justiciability, Lack of Remedy, Transparency in Change of Algorithm, Transparency/Trade Secrecy",2017-01-26,4/11/2019,https://blogs.gwu.edu/law-eti/?page_id=10&pid=15,Inactive: Judgement for P,"For 17 years Arkansas used a questionnaire called ArPath, where a professional nurse used their discretion to assess a patient's Attendant Care Hours. The nurse would assess the patient with 286 questions about the patient's ""functional abilities, medical conditions, mental status, and caregiving arrangements."" The nurse used professional judgement and discretion to determine the number of care hours needed.In 2016, Arkansas switched without notice to a computer algorithm ArChoice, with the nurse no longer having discretion for hours as they are allotted based on the patient's Resource Utilization Group. The use of ArChoice cut attendant hours for 47% of patients.The circuit court granted an injunction against the state continuing to use this algorithm.DHS then purposely promulgated an Emergency Rule using the exact RUGs it was enjoined from using, however because it allowed nurses to use ""modest"" discretion to adjust the hours the Supreme Court reversed the circuit court's finding of contempt against using the emergency algorithm.A non-judicial development is the state legislature holding DHS accountable by ordering numerous reviews of the algorithm.","Summary of Facts and Activity to DateThe Arkansas Department of Health Services had calculated Home and Community Based Services (HCBS) through the discretion of a nurse assessing patients with a questionnaire. In 2014 and 2015, DHS began meeting with Medicaid service providers to discuss changes to the program including an increase in hourly rates but did not include any patient beneficiaries of the program in these discussions. On August 23, 2015, DHS proposed new rulemaking to go into effect on January 1, 2016, with the final rule submitted to DHS on December 17, 2015. The only notification that patients received of any change was on December 1, 2015 when patients were notified of the change to ArChoice with an explicit statement ""Your services and provider will remain the same way.""Plaintiffs sued in 2016 for a temporary restraining order and a permanent injunction, and brought an ultra vires claim, declaratory judgement, and injury by an agency under Arkansas law. Plaintiffs maintained that the proposed rule and final rule did not indicate a change in calculation proposed or adopted, did not define the 23 tiers of the RUGs, did not specify criteria that the RUGs use to calculate hours and what each tier's hours would be, did not include the algorithm for the RUGs, or describe how the algorithms work in sufficient detail, or provide any data or studies on RUGs that the agency ""relied on"" when switching to this system . This algorithm ArChoice calculated a Patient-Centered Service Plan by placing each patient into one of 23 Resource Utilization Groups, which cut patient attendant hours for 47%.This was not a class action lawsuit.The circuit court granted the temporary restraining order for the plaintiffs on February 17, finding the plaintiffs met their burden for likelihood of success on the merits, irreparable injury, and in the public interest. This TRO enjoined DHS from continuing to use this algorithm for the Home and Community Based Services,DHS appealed the TRO to the Supreme Court of Arkansas, arguing that the circuit court abused its discretion finding irreparable harm and likelihood of success on the merits.The Supreme Court affirmed the February TRO, finding that the circuit court did not abuse its discretion as it agreed the plaintiffs met their burden, noting that the irreparable harm warrants the futility exception of exhaustion of remedies in Arkansas state law.DHS further appealed the Circuit Court finding it in contempt for not complying with the temporary restraining order, which the Supreme Court reversed but dismissed as moot. The dissent did not agree with the reversal of contempt, as DHS purposely promulgated an emergency rule using the exact RUGs it was enjoined from using.",Supreme Court Dismissed Appeal,2017.0,Decided
6,6,Authors Guild v. OpenAI Inc.,"Authors organization and many individual authors file suit against OpenAI Inc. and affiliated entities,",ChatGPT,Federal: US Dist. Ct. S.D.N.Y.,Generative AI,Copyright Infringement,Copyright Infringement,2023-09-09,9/19/2023,https://blogs.gwu.edu/law-eti/?page_id=10&pid=98,Active,,"Summary of Facts and Activity to DateComplaint filed September 19, 2023",Complaint filed,2023.0,Active
7,7,Baker v. CVS Health Corporation,"A candidate interviewing for a position with CVS Health has alleged that he and other interviewees were subjected to an artificial intelligence-powered lie detector test without the appropriate notification, according to a class action complaint recently removed to the U.S. District Court for the District of Massachusetts.",,U.S. District Court for the District of Massachusetts,"Civil Rights, Employment, Generative AI, Hiring","Civil Rights, Permanent Injunction","Failure to Disclosure, Misuse of AI, Unaware of Use of Algorithm",2023-06-30,1/26/2024,https://blogs.gwu.edu/law-eti/?page_id=10&pid=115,Active,"The lawsuit alleges that Brendan Baker participated in an interview using CVS's automated interview and application software. CVS contracted with HireVue, which utilizes an AI tool to help employers screen job candidates, according to the complaint.","Summary of Facts and Activity to DateThe lawsuit alleges that Brendan Baker participated in an interview using CVS's automated interview and application software. CVS contracted with HireVue, which utilizes an AI tool to help employers screen job candidates, according to the complaint.Baker is seeking declaratory and injunctive relief to enjoin CVS from illegally using the application in the future. Baker is also alleging violations of Massachusetts General Laws chapter 149, Section 19B(2)(b) which states that it is unlawful ""to require or administer a lie detector test as a condition of employment or continued employment,"" and that employer who violates this may be subject to criminal penalties and civil liabilities, the complaint said.Baker argues that HireVue interviews fall under Massachusetts' definition of ""lie detector test"" because ""HireVue, itself, confirms that view interviewing holds the potential to 'provide the ability to scale your lie detection, screen out embellishers, and hone in on those who are actually a fit for the role,'"" by answering a set of questions about integrity, work ethic, and cheating, the complaint said.""HireVue then uploads candidates' respective interview videos to the application programming interface ('API') of Affectiva, an artificial intelligence company that works to understand human emotions, cognitive states, and activities by analyzing facial and vocal expressions,"" the complaint said.""With these and/or other inputs (i.e., 'candidate[s] voice intonation, speech inflection, eye contact, perceived 'enthusiasm' for the role, and up until recently, facial expressions') HireVue builds 'a database of deep, rich psychographic information on millions of people,' purportedly evaluates hundreds of a job applicant's personality traits, and ultimately draws conclusions regarding a job applicant's degree of cultural fit with companies. HireVue conveys these findings to employers by 'assign[ing] each applicant a numerical 'employability' score' or 'competency-level scoring report[.]'"" according to the complaint, which said scores can be tailored to each employer's needs.Baker, who was not hired by CVS, initially filed the lawsuit in Suffolk Superior Court in April, before it was moved to the district court June 30.",Leave to File Document,2023.0,Active
8,8,"Barrows et al v. Humana, Inc.","Plaintiffs who had post-acute care coverage terminated filed a class action complaint alleging that a national health insurance company’s reliance on artificial intelligence (AI) tools to deny certain medical claims under Medicare Advantage plans constituted breach of contract, breach of the implied covenant of good faith and fair dealing, unjust enrichment, and insurance bad faith. The improper usage of AI to make coverage decisions, while ignoring clinical determinations made by providers, can prevent patients from being able to afford critical treatments and harm patient health.",,US District Court for the Western District of Kentucky,"Civil Rights, Health","Breach of Contract, Breach of Implied Warranty, Contracts, Unjust Enrichment","Lack of Human Review, Functionality",2023-12-12,12/14/2023,https://blogs.gwu.edu/law-eti/?page_id=10&pid=112,Active,The potential wrongful denial of claims by health insurers relying on AI tools could jeopardize access to needed health care services.,"Summary of Facts and Activity to DateHealth insurance company Humana unlawfully deploys artificial intelligence (AI) to wrongfully deny elderly patients care that is owed to them under Medicare Advantage plans, a new class action lawsuit alleges.On 12/12/2023 Barrows filed a Contract - Insurance lawsuit against Humana, Inc. This case was filed in U.S. District Courts, Kentucky Western District Court.Plaintiffs Joanne Barrows and Susan Hagood claim Humana uses AI in place of human doctors to override live physicians determinations “as to medically necessary care patients require.”The plaintiffs argue Humana is aware that predictions made by its AI model, nH Predict, are “highly inaccurate” and “not based on patients’ medical needs,” but still continues using it to deny patients’ coverage anyway.“Despite the high rate of wrongful denials, Humana continues to systemically use this flawed AI Model to deny claims,” the Humana class action states.The plaintiffs want to represent a nationwide class and multistate subclass of individuals who purchased a Medicare Advantage health insurance plan through Humana during the period of four years prior to the filing of the complaint through the present.",Order of Recusal,2023.0,Active
9,9,Barry v. Lyon,"Sixth Circuit affirmed reversing the automatic disqualification and inadequate notice of the Michigan's Department of Health and Human Services when they employed an algorithm that disqualified from food assistant benefits anyone with an outstanding felony warrant, including inaccurately accusing thousands",,Federal: US Dist. Ct. E.D. Michigan,"Criminal Justice, Food Assistance","Due Process, Supplemental Nutrition Assistance Program","Lack of Human Review, Lack of Remedy to prove innocence, Unreliability/Miscalculationns",2013-07-01,9/25/2016,https://blogs.gwu.edu/law-eti/?page_id=10&pid=20,Inactive,,"Summary of Facts and Activity to DateThe case centers around Supplemental Nutrition Assistance Program (SNAP) Benefits. An individual fleeing to avoid prosecution, custody, or confinement after conviction for a crime or attempted crime is not entitled to SNAP Benefits. Michigan had an automated program that compared lists of public assistance recipients with a list of outstanding felony warrants obtained. When the program detected a match it automatically closed the recipient's file and sent them a letter of termination of benefits. The District Court held that the Michigan policy violated the SNAP Act and the Constitution and issued an injunction requiring Michigan to halt its policy of automatic termination of benefits based solely on the existence of a felony warrant and to provide actual notice of valid disqualification. The Sixth Circuit affirmed the District Court's ruling.",Sixth Circuit Court of Appeals Affirm District Court; Remand to District Court to enforce injunction,2013.0,Inactive
10,10,Basbanes v. Microsoft Corporation,"OpenAI and its financial backer Microsoft (MSFT.O), were sued on Jan 5, 2024, in Manhattan federal court by a pair of nonfiction authors who say the companies misused their work to train the artificial-intelligence models behind the popular chatbot ChatGPT and other AI-based services. Writers Nicholas Basbanes and Nicholas Gage told the court in a proposed class action, that the companies infringed their copyrights by including several of their books as part of the data used to train OpenAI's GPT large language model.",,US District Court for the Southern District of New York,"Copyright, Generative AI, Infringement, Intellectual Property",Copyright Infringement,Copyright Infringement,2024-01-05,1/18/2024,https://blogs.gwu.edu/law-eti/?page_id=10&pid=110,Active,OpenAI Inc. and Microsoft Corp. are facing another copyright lawsuit from a pair of journalists who alleged their books and articles were used to train ChatGPT. The purported class action comes only a week after the two leading AI companies were hit by a groundbreaking suit from The New York Times Co.,"Summary of Facts and Activity to DateInvestigative journalist Nicholas Gage and author Nicholas Basbanes said in the complaint, filed on Jan 5, 2024, in Manhattan federal court, that OpenAI has admitted to using e-book datasets including “Books2"" that likely comes from pirated repositories online.The suit mirrors a number of similar class actions from high-profile authors including Sarah Silverman and George R.R. Martin, and the writers’ organization Authors Guild, which also allege their work was scraped without permission to be used for AI model training.OpenAI and Microsoft didn’t immediately return a request for comment. AI companies have argued copying books and articles for the purpose of training large language models falls under copyright law’s fair use doctrine.",Notice Regarding Pro Hac Vice Motion,2024.0,Active
11,11,Bauserman v. Unemployment Insurance Agency ;,"Class action against Michigan's Unemployment Insurance Agency's use of MiDAS (Michigan Integrated Data Automated System) that wrongfully accused 40,000 residents of fraud, resulting in civil penalties including seizure of tax refunds with a limited time to appeal, with claims court lawsuit seeking redress and to make this automated system illegal; lawsuit in federal court against agency officials and system developer",MIDAS,Federal: US Dist. Ct. E. D. Michigan,"Agency, Fraud, Unemployment Insurance","Due Process Clause, Negligence","Accountability, Lack of Human Review, Notice, Role of Expert Testimony, Socioeconomics Bias, Use of Race, Miscalculation",2013-01-01,10/20/2022,https://blogs.gwu.edu/law-eti/?page_id=10&pid=8,Closed (Settlement),"This is one case that was brought after the MiDAS algorithm falsely accused thousands of fraud that resulted in three outcomes: 1. seizure of state or federal income taxes refunds, 2. forced repayment of benefits, or 3. wage garnishments.The algorithm resulted in the UIA wrongfully accusing thousands of fraud, and notifying the claimants with 10 days to rebut.The Court of Appeals and Supreme Court opinions relate to the lack of notice and loss of property followed by the automated decision system spotting the ""suspected fraud"" rather than the use of the automated decision system,","Summary of Facts and Activity to DateSince August 12, 2012, the class members allege their due process rights of fair and just treatment were violated when the automated decision system MiDAS determined guilt of fraud without providing notice, proving guilt, or affording a way to challenge. Based on the algorithm, the claimants were disqualified or ineligible for unemployment benefits.The putative class complaint filed on September 9, 2015, stating that the MiDAS deprived the claimants of presenting evidence to ""real people."" This resulted in claimants paying or ""satisfying their debt"" even if they did not owe money. Originally filed by Bauserman, the amended complaint added Broe and Williams.UIA issued redeterminations of some class members to clear them of fraud, and then moved for summary judgement. One of the arguments the Court of Claims judge denied is that the complaint was not filed within six months of the event happening that gave rise of the cause of action. However, the Court of Appeals reversed on July 18, 2017, concluding that the claims did not accrue when the plaintiffs received the redetermination notices, but the original notice alleging fraudulent conduct. The plaintiffs appealed to the Supreme Court, who had the option to grant the appeal or take action.Supreme Court took action in April 2019, affirming the judgement for Bauserman and Broe but not for Williams who had not filed within six months of the letter, stating that ""plaintiffs did not incur an "" ‘actionable harm’ "" in their due-process claims until they were deprived of their property when their income tax refunds were seized or their wages were garnished.""Court of Appeals opinion on remand in December 5, 2019 said that plaintiffs raised cognizable constitutional tort claims and thus did not grant summary disposition.The UIA appealed to Supreme Court was accepted because there is no case law on how or when a court can award money damages in a case where the plaintiffs allege a violation of their due process rights.""Michigan's Supreme Court considered the argument on leave from December 5, 2019 for Unemployment Insurance Agency appeal, and ordered oral arguments to be scheduled on November 25, 2020.On July 26, 2022, the Michigan Supreme Court issued an opinion in which they agreed with the lower courts' holding that there was a cognizable constitutional tort claim in which the plaintiffs were eligible to receive money damages and that the plaintiffs were properly denied summary disposition. This was because enforcement of the relevant constitutional provision, Const. 1963, art. 1. section 17, was not given to the legislature and there was no other adequate remedy. The Michigan Supreme Court Remanded the case to the Court of Claims.The case settled for 20 million dollars in October 20, 2022.",Settlement,2013.0,Settled
12,12,Berliner v. Nassau County,"Nassau residents brought a class action against the county for an inaccurate and incomplete property tax reassessment algorithm as unfair and unconstitutional, granted a preliminary injunction against the county using this reassessment for 2020 real property taxes, almost settling but for the question of legal fees",,State: New York-Nassau County,"Constitutional Law, Real Property, Tax","42 USC 1983, Due Process, Equal Protection, Preliminary Injunction","Lack of Human Review, Notice, Transparency in Change of Algorithm, Underperformance",2019-04-30,3/8/2021,https://blogs.gwu.edu/law-eti/?page_id=10&pid=4,Inactive,"Berliner filed this class action to get disclosure of the county's property tax reassessment algorithm. The county discontinued its argument of trade secrecy and produced the algorithm, leading residents to challenge the legality because the algorithm had missing files that would not let the code run effectively.A New York lower court ruled that the class action of Nassau County residents can move forward, the ruling resulted in the discontinuation of the Reassessment algorithm in question and reverting to the previous market value and tax levels for the 2020 tax assessment. Plaintiffs allege that ""the reassessment was rushed, and conducted in an arbitrary, unscientific, and unfair manner lacking uniformity; that the reassessment failed to capture fair residential market values; that the use of neighborhood factoring produced striking discrepancies among similar properties; and was performed under a veil of secrecy with the utilization of undisclosed software and algorithms.""","Summary of Facts and Activity to DateIn March 2018, Nassau County legislature approved reassessments of real property tax for the 2020-2021 tax season using. The algorithm used data of recent sales of comparable houses to produce a predictive model, then multiplying by a neighborhood factor of one of the 324 neighborhoods in the county to assess property value, with neighborhood factors ranging from .6 to 1.9.In November 2018, the residents were notified of their preliminary market values that would roll out in April 2020, with 85,000 of the 400,000 houses needing reassessment before April 2020. The properties lowered in value did not have their tax accordingly lowered.In the complaint filed in April 2019, the plaintiffs allege: the countywide reassessment was rushed, and conducted in an arbitrary, unscientific, and unfair manner lacking uniformity; that the reassessment failed to capture fair residential market values; that the use of neighborhood factoring produced striking discrepancies among similar properties; and was performed under a veil of secrecy with the utilization of undisclosed software and algorithms."" The underassessed homes would see their taxes increase, and over assessed homes would challenge the valuation.During this time in summer of 2020, a second lawsuit by Sean M. McCarthy is dismissed with ID Number 607458 / 2020.Judgement on Plaintiff's October 1, 2020 motion for attorney's fees as part of the settlement agreement, ordered on December 1, corrected on December 22 and entered on December 28 awarding fees and costs of $300,000 to Plaintiffs.Nassau County Appeals to the Appellate Division of the Supreme Court of the State of New York, did the court err in finding the plaintiffs had established entitlement to award?In March 2021, plaintiffs filed certificate for satisfaction of judgment.In April 2021, plaintiffs brought issue with Nassau County sending out fliers that stated ""ALERT NASSAU COUNTY DID NOT RAISE TAXES"" and other statements relating to the lawsuit.",Plaintiffs filed satisfaction of judgment,2019.0,Inactive
13,13,Bertuccelli v. Universal City Studios LLC,Court allows facial recognition expert to testify about his algorithmic facial reocnigtion analysis of the allegedly infringing and infringed masks to determine if a human would find them substantially similar,,Federal: US Dist. Ct. E.D. Louisiana,"Copyright, Intellectual Property","Copyright Infringement, Federal Rule of Evidence 702",Role of Expert Testimony,2019-02-12,6/14/2021,https://blogs.gwu.edu/law-eti/?page_id=10&pid=13,Inactive: Dismissed,,"Summary of Facts and Activity to DateThis order on a motion to exclude expert testimony in a copyright infringement lawsuit approves of the use of ""artificial intelligence facial recognition analysis"" to determine whether two masks were substantially similar In a copyright infringement case, The court held that the testimony of plaintiff's expert witness Dr. Edward R. Griffor is admissible.  Dr. Griffor performed ""artificial intelligence assisted facial recognition analysis of the King Cake Baby and Happy Death Day mask to determine whether the use of mathematics and target facial recognition algorithms comparing the two works would find that human perception would view the works as substantially similar."" After the March order, multiple motions by the Plaintiff for leave to consult experts were granted. In May 2021, the court denied the Plaintiffs' Motion for Partial Clarification, Partial Reconsideration, and Incorporated Motion for Leave to Amend. The court then denied a Motion to Strike Jury Demand in June 2021, with defendants then submitting proposed jury instructions. The court then granted the motion to expedite the trial, and then denied defendant's motion to exclude untimely evidence. The parties settled on June 14 and the case was dismissed.",Dismissal of Case,2019.0,Dismissed
14,14,"Broccolino v. Clearview AI, Inc.",,Clearview,Federal: US Dist Ct. S.D. New York; Transferred to US Dist. Ct. N.D. Illinois,Facial Recognition,,Privacy,2020-03-12,1/12/2021,https://blogs.gwu.edu/law-eti/?page_id=10&pid=31,Active,"Unlike the other complaints, Broccolino's complaint noted that Clearview was used in the Middle East and Russia, and that Google and Facebook had sent notices that Clearview's conduct violated their terms of use by not seeking consent. However, it did not go further with these issues and only filed its cause of action under BIPA.Broccolino's complaint also notes that Clearview violated BIPA by not writing and making available a retention schedule for permanently destroying biometric identifiers and information.","Summary of Facts and Activity to DatePlaintiff filed complaint on March 13, 2020 alleging that Clearview violated BIPA. Plaintiff sent Clearview a letter requesting confirmation that her likeness was in the database on March 3, 2020 through the ""appropriate channels"" of its website with no response.This is the second case that the Judge in Calderon described saying it was better suited for Illinois on April 15, included in Judge McMahon's directive on April 22, she wrote of Calderon, Burke, Broccolino, and McPherson, McMahon suggested the cases are better brought in Illinois because they concern BIPA.Broccolino was ordered to respond to Mutnick's Motion to Intervene, which was denied on May 29.On September 9 with now six cases before her, Judge McMahon stayed all six SDNY cases until MDL was worked out.",MDL Transfer Out,2020.0,Active
15,15,Brooks v. Commonwealth,The court dismissed the Virginia ACLU’s challenge to the risk assessment tool because the algorithm was only advisory in nature,,State: Circuit Court of the City of Waynesboro Virginia,"Criminal Justice, Recidivism, Sentencing",Due Process,"Use of Race, AI Adjacent",2004-01-01,,https://blogs.gwu.edu/law-eti/?page_id=10&pid=67,Inactive,"In a case involving risk assessment calculation tools, the Court of Appeals of Virginia notes that the General Assembly created the Virginia Criminal Sentencing Commission in 1994 to develop and implement ""discretionary sentencing guidelines"" to assist the judiciary in imposing sentences. The sex offense risk assessment guidelines of factors that were statistically significant to recidivism predictions.  The general assembly then ""developed a risk assessment instrument that scored risk factors according to their relative importance in the statistical model.""","Summary of Facts and Activity to DateDefendant Drew Brooks was arrested and charged with statutory rape. Brooks pleaded guilty, and the judge ordered a pre-sentence report: ""The sentencing guidelines worksheets prepared with the pre-sentence report calculated an active sentence of 7 to 16 months. After adjusting the recommendation for the defendant's risk assessment score, the upper limit of the recommendation increased to 24 months. The trial court imposed an active sentence of 18 months."" The risk assessment guidelines were a tool for the judge to consider but was not required to follow. The trial court sentenced him to ten years in prison, relying heavily on risk assessment factors to calculate recidivism. Brooks appealed this use. In affirming the trial court's use of the risk assessment factors,  The Court of Appeals notes that the court will not interfere when the sentence is within the legislature set statutory limits.  Because statutory rape is subject to imprisonment of 2 to 10 years, and 10 years was within the statutory limits, the trial court did not err in sentencing. Even though the judge heavily relied on the risk assessment factors, the court properly exercised discretion.",,2004.0,Inactive
16,16,"Burke v. Clearview AI, Inc.","Class transferred and consolidated into In re Clearview, complaint charged that Clearview violated BIPA, CCPA, Cal. commercial misappropriation, unjust enrichment and sought seeking injunctive relief, damages, restitution, disgorgement, and litigation costs",Clearview,Federal: US Dist. Ct. S.D. California; Transferred to US Dist Ct. S.D. New York; Transferred to US Dist. Ct. N.D. Illinois,Facial Recognition,"California Consumer Privacy Act, Illinois Biometric Information Privacy Act, Unjust Enrichment, Commercial Misappropriation",Privacy,2020-02-27,1/13/2021,https://blogs.gwu.edu/law-eti/?page_id=10&pid=23,Active,The complaint was originally brought in California under both BIPA and the CCPA before being transferred to SDNY and then Northern District of Illinois.,"Summary of Facts and Activity to DateThe amended complaint brought against Clearview, its two co founders, and the directors and officers as Does 1-10, argued Clearview violated California's unfair competition law, consumer privacy law, committed misappropriation and received unjust enrichment, as well as violated the Illinois BIPA.The plaintiffs that they had uploaded images of themselves to Google and Facebook in the years Clearview actively scraped, plaintiffs never consented or gave written permission to Clearview, thus Clearview profited off of the plaintiffs' images and took away their control of their biometric information.The complaint differentiates biometric information as defined by Illinois and by California, and argues Clearview knowingly and willfully violated both.The four subclasses are: 1. commercial misappropriation, 2. BIPA, 3. CCPA and 4. unjust enrichment.On April 17, the case was transferred from the Southern District of California to SDNY after a joint motion from Burke.On April 24, the case was accepted as related to Calderon, and then reassigned to Judge McMahon who oversaw the total six Clearview cases in New York, at the time the five.The six New York cases were stayed by Judge McMahon on September 9 pending a decision on MDL.",MDL Transfer out,2020.0,Active
17,17,C.S. et al v. Saiki:,"Judge granted Oregon residents relying on in-home attendants an injunction against an aglorithm that vastly cut their hours, and ordered restoration of their previous algorithm that produced the expected hours for disabilities benefits while the state developed a new assessment algorithm",ANA-C; CNA-C,Federal: US Dist. Ct. D. Oregon,"Disabilities Benefits, Health, Public Benefits","Preliminary Injunction, Title II Americans with Disabilities Act","Lack of Scholarly Review, Transparency in Change of Algorithm",2017-04-01,12/12/2023,https://blogs.gwu.edu/law-eti/?page_id=10&pid=16,Active,"The Oregon Office of Developmental Disability Services implemented the ANA-C or CNA-C assessment tool to calculate authorized hours for in-home attendant hours for those with intellectual or developmental disabilities. The plaintiffs filed this action because they received a decrease in hours for services. The complaint filed for a preliminary injunction against the further use of this assessment tool, and was ordered to prospectively restore all hours by ANA-C or CNA-C and notify the affected people.The DDS could continue to use the ANA-C or CNA-C to evaluate those with intellectual or developmental disabilities but could not reduce in-home attendant care services below the “status quo” level of care that they received as of November 1, 2016.","Summary of Facts and Activity to DateOn April 10, 2017, Plaintiffs filed a complaint, a Motion for a Preliminary Injunction, and Motion for Protective Order and to Proceed Anonymously. On April 19, 2017, the judge granted the preliminary injunction, and the following day granted Motion to Proceed Anonymously. The case stalled in the rest of 2017, with joint status report filed every six months in 2018, 2019, 2020, and 2021, with no real update other than 2019 the motion for a class action was denied as moot. The case was stayed until December 2021. On December 12th, 2023, Judge McShane granted a motion to continue the stay and the parties must file a joint status report by May 1st, 2024.",Case stayed,2017.0,Active
18,18,Cahoo v. Fast Enterprises,Court denied granting Fast Enterprises' motion for dismissal on lack of subject matter jurisdiction,MiDAS,Federal: US Dist. Ct. E. D. Michigan,"Agency, Constitutional Law, Fraud, Unemployment Insurance",Due Process,"Accountability, Lack of Human Review, Lack of Remedy, Notice, Role of Expert Testimony, Socioeconomics Bias, Use of Race, Miscalculation",2017-03-02,3/18/2021,https://blogs.gwu.edu/law-eti/?page_id=10&pid=44,Active,,Summary of Facts and Activity to DateThis is a continuation of Cahoo v. SAS Industries; the caption changed once SAS Industries' Motion to Dismiss was granted.,Order,2017.0,Active
19,19,Cahoo v. SAS Indus.,Court dismissed case against SAS for lack of subject matter jurisdiction,MiDAS,Federal: US Dist. Ct. E. D. Michigan,"Agency, Constitutional Law, Fraud, Unemployment Insurance",Due Process,"Accountability, Lack of Human Review, Lack of Remedy, Notice, Role of Expert Testimony, Socioeconomics Bias, Use of Race, Miscalculation",2017-03-02,8/11/2020,https://blogs.gwu.edu/law-eti/?page_id=10&pid=43,Inactive: Dismissed,"This case is continued in Cahoo v. Fast, as the court recognized the claim for negligence in the software design and monitoring, but granted SAS's motion to dismiss because inadequate damages pled.",Summary of Facts and Activity to Date,Dismissed against SAS,2017.0,Dismissed
20,20,"Calderon v. Clearview AI, Inc.","Violates BIPA; seeking injunctive relief (including deletion of data), statutory damages, and litigation costs",Clearview,Federal: US Dist Ct. S.D. New York; Transferred to US Dist. Ct. N.D. Illinois,Facial Recognition,BIPA,Privacy,2020-02-13,1/12/2021,https://blogs.gwu.edu/law-eti/?page_id=10&pid=30,Inactive,"Like other Illinois cases, this complaint is brought against both Clearview and CDW. However, a complaint was filed in both Illinois and SDNY on the same day. Mutnick's motion to intervene was denied on May 29, 2020.","Summary of Facts and Activity to DateThe plaintiffs filed complaint in SDNY even though they are residetn and citizens of Illinois. The complaint alleges that the photographs of the plaintiffs contained metadata reflecting the location of Ilinois, and thus plaintiffs are ""informed and believes"" that their facial biometrics are contained in Clearview's database and have been disclosed to and used by CDW and CPD.On April 14, the Judge issued a directive to consolidate the two New York cases before her, also indicating that the cases were better suited for Illinois because they were about Illinois statutes. Judge said: ""There are only two related cases pending before me. Should this New York court end up being the place where this Illinois statute gets interpreted, and where alleged violations of Illinois law are litigated, my inclination would be to consolidate the two cases and allow the three law firms involved for the plaintiffs to divide the laboring oar, on the understanding that I would not be paying three, or even two, sets of lawyers to appear and do the work of one at any conference, hearing, deposition, or other event. ... I simply have two related but identical class actions in front of me, as to which attorneys' fees will be parceled out eventually (should plaintiffs prevail) as though it were a single case. I thus decline to take any action on the ""lead plaintiffs counsel"" motion filed in Calderon until I have entertained any motions addressed to the complaints that may be filed by the defendants. In that regard, the cases shall be consolidated, and a single motion shall be filed under each docket number, addressed to the pleadings as they have been filed. The allegations against the common defendant (Clearview) are in all relevant respects identical; there is no need for separate motions in the two cases.""Mutnick's motion to intervene was denied, and this case did not see any motion to dismiss from Clearview before it was transferred.",MDL Transfer Out,2020.0,Inactive
21,21,"Carmean v. Macy's Retail Holdings, Inc","Macy's use of Clearview violates BIPA, Ill. UDAP (both unfair and deceptive), Ill. invasion of privacy; seeking injunctive relief (including deletion of data and compliance monitoring), damages, litigation costs, and was not consolidated in the Clearview MDL.",Clearview,Federal: US Dist. Ct. N.D. Illinois,Facial Recognition,"Illinois Biometric Information Privacy Act, Illinois Unfair and Deceptive Acts",Privacy,2020-08-05,3/16/2021,https://blogs.gwu.edu/law-eti/?page_id=10&pid=28,Inactive,"This case was not combined with the other nine cases for in re Clearview litigation in the Northern District of Illinois because Clearview was not a defendant, as it was about Macy's use of Clearview.The complaints mentions that a 2020 article shed light on 2,200 of Clearview clientele, which included department stores, and that Macy had run 6,000 customers through the database, which is illegal in Illinois without notice and consent.","Summary of Facts and Activity to DateOriginally filed under the incorrect name Carmine.The complaint contends that Macy's use of Clearview to run through 6,000 customers violates the Biometric Information Privacy Act (""BIPA"") and the Illinois Consumer Fraud and Deceptive Business Practices (""ICFA""). Under both BIPA and ICFA, the complaint argues: 1. plaintiff posted pictures of herself on social media, and others posted pictures of her on social media, 2. Macy's never notified or procured a written release from the class members to collect, obtain, or use their Clearview positive identifications, 3. violation of privacy with punitive and actual damages.The complaint admits: ""Because Carmine has such a widespread and active social media presence, on information and belief, Carmine’s biometric information and identifiers and her personal and private information are contained in Clearview’s database.""The complaint sought relief: 1. Macy's expunge/delete/remove all information and data about the class members, 2. Macy's will not use its Clearview positive identification information in the future, and 3. submit and pay for court-supervised monitoring of their database for BIPA compliance.On March 15th, 2021 the plaintiff Carmean filled a notice of voluntary dismissal and on March 16th, the civil case was terminated. The case was dismissed without prejudice.",Notice of Voluntary Dismissal,2020.0,Inactive
22,22,Carpenter v. McDonald’s Corporation,"Customer brought putative class action against fast food restaurant, asserting violation of Illinois Biometric Information Privacy Act (BIPA) by collecting customers’ voiceprint biometrics via artificial intelligence (AI) voice assistant technology in drive-through lanes and storing, disclosing, and disseminating biometric information without customers' consent.",,N.D. Illinois,Biometric Data,Biometric Information Privacy Act,Privacy,2021-05-28,7/14/2023,https://blogs.gwu.edu/law-eti/?page_id=10&pid=78,Closed (Settlement),"At the stage of motion to dismiss, the court can consider patent for fast food restaurant's AI voice assistant technology.","Summary of Facts and Activity to DateMcDonald's deploys an artificial intelligence voice assistant in the drive-through lanes of various McDonald's restaurants that uses voice recognition technology to allow customers to place orders without interacting with a person.The court considered patent for fast food restaurant's AI voice assistant technology and found that the technology may allow McDonald's to collect, collate, or otherwise obtain a voiceprint.On July 7th, 2023 the parties agreed to a settlement and the court dismissed the case with prejudice on July 14th, 2023 via minute order.",Minute Order dismissing case,2021.0,Settled
23,23,CCC Info. Servs. Inc. v. Tractable Inc.,Trial court denied defendant Tractable's motion to compel arbitration after Plaintiff CCC Information Services Inc. accused Tractable employees committed fraud to access CCC Info Services' proprietary software and then used this data to Tractable's advantage.,,Federal: US Dist. Ct. N.D. Illinois,"Agency, Intellectual Property, Licensing Agreement","Breach of Contract, Trademark infringement, Arbitration","Infringement, Transparency/Trade Secrecy",2018-11-26,11/3/2023,https://blogs.gwu.edu/law-eti/?page_id=10&pid=47,Active,"By denying the motion to compel arbitration, this case about infringing the algorithm software will go forward.","Summary of Facts and Activity to DateCCC Info Services uses an algorithm and database to calculate vehicle damage estimates, which it then licenses to independent automobile appraisers.Plaintiff CCC Information Services brought suit, claiming that Tractable fraudulently obtained access to CCC's algorithm through Tractable employees pretending to be customers and entering into a licensing agreement with an arbitration clause, and that Tractable then sought to reverse engineer the algorithm and recreate it. Plaintiff brought this action under the Computer Fraud and Abuse Act, the The Defend Trade Secrets Act Of 2016, The Illinois Trade Secrets Act Of 2016, Illinois Deceptive Trade Practices Act, trademark infringement, right to chattels, common fraud, unjust enrichment, and declaratory relief.The relief included destroying or returning any data and material relating to the platform and algorithm.The court denied Tractable's motion to compel arbitration and stay the proceedings in May 2019. The court's reasoning is that non-parties to contracts cannot compel arbitration clauses.The court held a joint status report in March 2021, of which it is not published yet where the case will lead.On November 3rd, 2023 the court entered into a joint motion to extend the stay of discovery and extended close of fact discovery. Discovery is stayed until 01/31/2024 and fact discovery shall close on 04/30/2024.",Joint Status Report Status,2018.0,Active
24,24,"Chabon et al. v. Meta Platforms, Inc.","Authors Michael Chabon, David Henry Hwang, Matthew Klam, Rachel Louise Snyder, and Ayelet Waldman file suit on behalf of themselves and similarly situated authors against Meta Platforms, Inc. and affiliated entities, alleging that the defendants have engaged in direct copyright infringement, vicarious copyright infringement, unlawful removal of copyright management information, violation of the California unfair competition act, negligence, and unjust enrichment, by copying their works of authorship without authorization to train various versions of the generative AI tool LLaMA.",LLaMA,Federal: US Dist. Ct. N.D. Ca.,Generative AI,"Copyright Infringement, Negligence, Unjust Enrichment, Unfair Competition, 17 U.S.C. 1202 Removal of Copyright Management Information",Copyright Infringement,2023-09-12,12/7/2023,https://blogs.gwu.edu/law-eti/?page_id=10&pid=100,Active,,"Summary of Facts and Activity to DateComplaint filed September 12. 2023; reassigned to Judge Vince Chhabria September 22, 2023.On December 7th, 2023 the case was closed and consolidated with Kadrey v. Meta Platforms, Inc.",Reassignment to Judge Vince Chhabria,2023.0,Active
25,25,Chabon et al. v. OpenAI,"Authors Michael Chabon, David Henry Hwang, Matthew Klam, Rachel Louise Snyder, and Ayelet Waldman file suit on behalf of themselves and similarly situated authors against OpenAI and affiliated entities, alleging that the defendants have engaged in direct copyright infringement, vicarious copyright infringement, unlawful removal of copyright management information, violation of the California unfair competition act, negligence, and unjust enrichment, by copying their works of authorship without authorization to train various versions of the generative AI tool ChatGPT.",ChatGPT,Federal: US Dist. Ct. N.D. Ca.,Generative AI,"Copyright Infringement, Negligence, Unjust Enrichment, Unfair Competition, 17 U.S.C. 1202 Removal of Copyright Management Information",Copyright Infringement,2023-09-08,9/8/2023,https://blogs.gwu.edu/law-eti/?page_id=10&pid=99,Active,,"Summary of Facts and Activity to DateComplaint filed September 8, 2023",Complaint filed,2023.0,Active
26,26,"Concord Music Group, Inc. v. Anthropic PBC","A group of music publishers, including Concord Music Group, Inc., ABKCO Music, Inc., and many companies that are components of Universal Music Publishing Group, bring this copyright infringement action against generative AI developer Anthropic PBC. They claim that Anthropic has used lyrics in which they own copyright to train its generative AI models, and has created models that generate lyrics that are substantially similar to the lyrics in which the plaintiffs own copyright. The complaint includes counts of direct and indirect infringement, and removal of copyright management information.",Claude,Federal: U.S. Dist. Ct. M.D. Tenn.,Generative AI,Copyright Infringement,Copyright Infringement,2023-10-18,10/18/2023,https://blogs.gwu.edu/law-eti/?page_id=10&pid=103,Active,,"Summary of Facts and Activity to DateComplaint filed October 18, 2023.",Complaint filed,2023.0,Active
27,27,"Connecticut Fair Housing Center, et al. v. CoreLogic Rental Property Solutions",The Connecticut Fair Housing Center and the National Housing Law Project have filed a new lawsuit in the U.S. District Court for the District of Connecticut contending that CoreLogic Rental Property Solutions (“CoreLogic”) violates the Fair Housing Act by disproportionately disqualifying African-American and Latino applicants from securing housing based on discriminatory use of criminal records as rental criteria.,,U.S. District Court for the District of Connecticut,"Civil Rights, Housing","Fair Housing Act, Unfair and Deceptive Trade Practices","Lack of Remedy, Socioeconomics Bias, Use of Race",2018-04-24,8/4/2023,https://blogs.gwu.edu/law-eti/?page_id=10&pid=109,Active,"The Connecticut Fair Housing Center and the National Housing Law Project have filed a new lawsuit in the U.S. District Court for the District of Connecticut contending that CoreLogic Rental Property Solutions (“CoreLogic”) violates the Fair Housing Act by disproportionately disqualifying African-American and Latino applicants from securing housing based on discriminatory use of criminal records as rental criteria.The lawsuit asserts that CoreLogic’s tenant screening tool denied a Connecticut mother’s request to move her disabled son into her apartment based on a record of a dismissed shoplifting arrest from 2014.  Although rental decisions have traditionally been made by housing providers, today many landlords contract with third-party tenant-screeners to make admission decisions for them.  This litigation seeks to ensure that CoreLogic and all tenant-screening companies who functionally make rental decisions on behalf of landlords make those decisions in accordance with fair housing requirements.This litigation seeks to ensure that CoreLogic and all tenant-screening companies follow fair housing requirements when they functionally make rental decisions on behalf of landlords, which adversely affected both Ms. Arroyo and the Connecticut Fair Housing Center and its mission of ensuring fair housing for the people of Connecticut.The U.S. Department of Housing & Urban Development observed in 2016 that excluding rental applicants because of their criminal records disproportionately harms Latinos and African Americans, who are significantly more likely than whites to be arrested or convicted.  Studies show such disparities are linked to differential enforcement rather than to differences in likelihood of engaging in criminal activity.  HUD advised that to avoid discriminating, an “individualized review” should be conducted considering the nature of the offense, how long ago it occurred, intervening changed circumstances, and other relevant factors to avoid denying housing to an applicant who does not pose a genuine and ongoing threat to persons or property.  Further, HUD’s guidance specifically advises landlords not to consider arrests that did not result in a conviction in making their evaluations.","Summary of Facts and Activity to DateCohen Milstein is partnering with Connecticut Fair Housing Center and the National Housing Law Project in the representation of Carmen Arroyo, as well as the Connecticut Fair Housing Center itself, against CoreLogic Rental Property Solutions (“CoreLogic”), a third-party tenant-screening company, for violating the Fair Housing Act by discriminatory use of criminal records as rental criteria.Originally filed on April 24, 2018 with the U.S. District Court, District of Connecticut, the lawsuit asserts that CoreLogic’s automated tenant screening software tool (“CrimSAFE”) denied Carmen Arroyo’s request to move her disabled son into her rental apartment based on a record of a dismissed shoplifting arrest from 2014, before he became disabled.On August 7, 2020, the U.S. District Court, District of Connecticut denied CoreLogic’s motion for summary judgment regarding Plaintiffs’ standing and Plaintiffs’ claims of race and national origin discrimination in violation of the Fair Housing Act.On July 20, 2023, after a bench trial that was started on March 14, 2022 and subsequently postponed by the court to re-start on October 24, 2022 and ultimately concluded on November 4, 2022, the court ruled that CoreLogic is not subject to the FHA. Plaintiffs filed an appeal with the United States Court of Appeals for the Second Circuit on August 4, 2023.On November 24, 2023, the Department of Justice filed an amicus brief with the Second Circuit, asking the appellate court to remand the case with instructions for reconsidering whether CoreLogic’s actions create liability under the Fair Housing Act.",Plaintiffs filed an appeal with the Second Circuit,2018.0,Active
28,28,Deyerler v. HireVue Inc.,"Plaintiff files a class action lawsuit claiming the defendant violated Illinois, Biometric Information Privacy Act (BIPA). Plaintiff alleges defendant, illegally collected her biometric data without her written permission when she interviewed using the website, profited from her and other class members data, and finally that the defendant failed to provide a retention schedule and/or guidelines for permanently destroying it.",,"District Court, N.D. Illinois",Biometric Data,Biometric Information Privacy Act,"Failure to Disclosure, Personally identifiable Information, Privacy",2022-03-10,12/28/2023,https://blogs.gwu.edu/law-eti/?page_id=10&pid=133,Active,,"Summary of Facts and Activity to DateThe defendant, HireVue Inc., uses an algorithm to assess a job candidate's qualifications based on their facial characteristics. The complaint alleges that the defendant failed to inform plaintiffs that their biometric data was being collected and failed to obtain consent to gather the data. The complaint further alleges that defendant profited from the data and has not made a publicly available plan for how long the defendant plans to keep the data and how long the data. On March 10, 2022, the case was removed from the Circuit Court of Cook County Illinois and was sent to the Federal District Court for the Northern District of Illinois.",,2022.0,Active
29,29,"Dinerstein v. Google, LLC","Judge dismissed patient suit against Google and University of Chicago Medical Center over patient health records that the univeresity transferred to Google for machine learning data, arguing it was a prima facie violation of HIPAA, on appeal currently",,Federal: US Dist. Ct. N.D. Illinois,"Health, Privacy","Breach of Contract, CCPA, HIPAA","Personally identifiable Information, Terms of Service",2019-06-26,7/11/2023,https://blogs.gwu.edu/law-eti/?page_id=10&pid=14,Inactive,"This case considers the issue of re-identification of de-identified health data. The University of Chicago gave Google de-identified health data to create a predictive health model. However, because of all the additional data Google has, there is a risk of the shared de-identified personal health information being re-identified. If you combine the patients geolocation information that Google already has, with the Electronic Health Records given by the hospital (which include the date and time of hospital services) Google has the data points to identify who these patients really are.","Summary of Facts and Activity to DateUniversity of Chicago and Google partnered to use machine learning to create a predictive health model to reduce hospital readmission and anticipate future medical events. Part of this partnership involved the university disclosing to Google the ""de-identified"" electronic health records of hospital patients. Dinerstein was a patient and sued the hospital for breach of contract, sued Google for tortious interference with contract, and sued them both for intrusion upon seclusion.On July 11th, 2023, the Seventh Circuit Court of Appeals affirmed the lower courts dismissal, stating that the injuries Dinerstein alleged lacked plausibility, concreteness, or imminence.","Oral Argument, 7th Circuit",2019.0,Inactive
30,30,"Doe 1 v. Github, Inc.","Anonymous plaintiffs sue Github, Microsoft, and Open AI for alleged wrongs committed in training Codex and Copilot generative AI coding tools, including removal of copyright management information, breach of open-source license, unfair competition, and others","Copilot, Codex",Federal: US Dist. Ct. N.D. Ca.,Generative AI,"California Consumer Privacy Act, Negligence, 17 U.S.C. 1202 Removal of Copyright Management Information",Accountability,2022-11-03,7/26/2023,https://blogs.gwu.edu/law-eti/?page_id=10&pid=89,Active,,Summary of Facts and Activity to Date,Order re: Discovery Dispute,2022.0,Active
31,31,"Equal Employment Opportunity Commission v. iTutorGroup, Inc.","In the lawsuit, EEOC v. iTutorGroup, Inc., the EEOC alleged that iTutorGroup’s hiring software automatically rejected older job applicants in violation of the Age Discrimination in Employment Act (“ADEA”). This settlement comes amongst the EEOC’s stated intent to enforce anti-discrimination laws in connection with the use of AI in workplace decisions, and is likely the first of many more litigations and settlements in this area.",,U.S. District Court for the Eastern District of New York,"Employment, Generative AI, Hiring","Civil Rights, Permanent Injunction","Programmer Bias, Socioeconomics Bias",2022-05-05,9/8/2023,https://blogs.gwu.edu/law-eti/?page_id=10&pid=120,Inactive,"Given the significant increase in the use of AI in the workplace by employers, the EEOC is expected to continue to focus on the use of AI and bring more litigation in this area. The recent settlement is an important reminder for employers to proactively monitor the developing law and guidance in this area, including at the state and local level. As but one example, New York City’s legislation (Local Law 144) recently became effective and prohibits employers from using an automated decision tool in certain employment decisions unless the employer first ensures that the tool has been audited for bias within the preceding year.","Summary of Facts and Activity to DateThe EEOC Litigation. On May 5, 2022, the EEOC filed a complaint against iTutorGroup, an organization that hires remote English tutors for students in China, in the Eastern District of New York. The EEOC alleged that the company violated the ADEA by implementing a software hiring program that “intentionally discriminated against older applicants because of their age” by “automatically reject[ing] female applicants age 55 or older and male applicants age 60 or older,” effectively screening out over 200 applicants. The purported discriminatory software was discovered when an applicant submitted two applications identical in all but birth date. According to the EEOC, the applicant used one application with their real date of birth and filed a second application with a more recent date of birth. The candidate allegedly received an interview only when using the more recent date of birth.On August 9, 2023, the Equal Employment Opportunity Commission (“EEOC”) announced the settlement of the agency’s first lawsuit involving the alleged discriminatory use of artificial intelligence (“AI”) in the workplace.On September 8, 2023, federal court approved a consent decree from the Equal Employment Opportunity Commission (EEOC) with iTutorGroup Inc. and its affiliates (“iTutor”) over alleged age discrimination in hiring, stemming from automated systems in recruiting software. According to the consent decree, iTutor will pay $365,000 to over 200 job candidates who were automatically screened out by iTutor’s recruiting software to resolve the EEOC’s claims.",Order of Settlement,2022.0,Inactive
32,32,"Estate of Gene B. Lokken et al. v. UnitedHealth Group, Inc. et al.","Health insurer UnitedHealthcare is facing a class action alleging it used an artificial intelligence algorithm to wrongfully deny coverage to elderly people for care under their Medicare Advantage health policies. Filed Tuesday in the US District Court for the District of Minnesota, the lawsuit alleges UnitedHealthcare made health-care determinations via its “nH Predict” algorithm, overrode physician recommendations, and denied elderly patients’ claims for stays in extended care facilities. Doing so “resulted in a significant increase in the number of post-acute care coverage denials,” the lawsuit said.",,US District Court for the District of Minnesota,"Generative AI, Health","Breach of Contract, Unjust Enrichment","Individualized Assessment, Lack of Human Review, Lack of Remedy, Misuse of AI, Socioeconomics Bias",2023-11-14,2/5/2024,https://blogs.gwu.edu/law-eti/?page_id=10&pid=130,Active,"As health care payers increasingly rely on artificial intelligence (“AI”) to speed up patient claim adjudication and prior-authorization determinations, providers should be on the lookout for algorithms designed to deny claims with minimal human oversight. Two putative class action lawsuits filed against Cigna and UnitedHealth in November 2023 allege that the payers’ respective AI models, “PxDx” and “nH Predict,” were used in place of real medical professionals to wrongfully deny medically necessary care.","Summary of Facts and Activity to DateThe estates of Gene B. Lokken and Dale Henry Tetzloff — both of whom were insured by UnitedHealth prior to their deaths — claim UnitedHealth Group Inc. uses a flawed AI model, called naviHealth predict, to determine coverage criteria for patients.The putative class action, filed in November 2023 against UnitedHealth in Minnesota federal court, alleges that the insurer knowingly used an AI tool with a high error rate to override physician recommendations and to deny elderly patients care owed to them through Medicare Advantage healthcare plans.Lokken's and Tetzloff's estates argue that UnitedHealth's AI model determines patients' coverage criteria for post-acute care settings with ""rigid and unrealistic predictions for recovery"" and overrides what an actual physician recommends, purportedly resulting in the denial of recommended and needed care. The country's largest health insurance company then ""bank[s] on the patients' impaired conditions, lack of knowledge, and lack of resources to appeal the erroneous AI-powered decisions,"" according to the complaint.In response, UnitedHealth Group filed motion to dismiss on Feburary 5th, 2024.",Defendant file motion to dismiss,2023.0,Active
33,33,"e-ventures Worldwide, LLC v. Google, Inc.","This lawsuit, brought in the Middle District of Florida, alleges that Google's statement that it does not censor search results is ""false, deceptive, and misleading,"" and thus violates the Lanham Act and the Florida Deceptive and Unfair Trade Practices Act. The plaintiff company argues that Google made all of its websites disappear from search results, and because Google dominates the search engine market, essentially made the plaintiff's website disappear from the internet. The court ultimately dismissed, stating that the First Amendment protected Google's decision making when displaying search results.",SEO,M.D. Fla.,"Advertising, Trading","Unfair and Deceptive Practices, Unfair and Deceptive Trade Practices",Targeted Advertising,2014-11-04,,https://blogs.gwu.edu/law-eti/?page_id=10&pid=84,Inactive: Judgment for D,,Summary of Facts and Activity to Date,,2014.0,Decided
34,34,Ewert v. Canada,Canada's Supreme Court ruled that Correctional Service of Canada breached their statutory duty to take all reasonable steps to learn how the algorithms did not account for indigenous populations when an inmate argued the that the psychological and risk assessment algorithms were invalid when applied to Indigenous inmates for lack of research,,International: Canada,"Criminal Justice, Recidivism","Corrections and Conditional Release Act, S.C. 1992, c. 20, s. 24(1)","Cross Culture Validity, Insufficient Research, Socioeconomics Bias, Use of Race, Unreliability/Miscalculationns",2014-10-20,6/13/2018,https://blogs.gwu.edu/law-eti/?page_id=10&pid=7,Inactive: Judgement for P,"Canada's Supreme Court ruled that CSC breached their statutory duty when they did not take all reasonable steps to study the cross-cultural validity of the algorithm on indigenous populations. The dissent took issue with Ewert bringing this case for the use of the psychological and risk assessment algorithms on all indigenous inmates, arguing that Ewert should have just brought suit about his specific results of the algorithm since that is what the relief related to. The majority however emphasized that Indigenous inmates were less likely to be granted early release, were classified as high risk, and the tools had been developed using information from non-indigenous populations.The majority and dissent also disagreed on whether the CSC should test for accuracy (majority) or validity (dissent).The five tools Ewert challenged were: ""Hare Psychopathy Checklist-Revised (“PCL-R”), a tool that was designed to assess the presence of psychopathy but is also used to assess the risk of recidivism. Mr. Ewert also challenged the use of the Violence Risk Appraisal Guide (“VRAG”) and the Sex Offender Risk Appraisal Guide (“SORAG”), two actuarial tools designed to assess the risk of violent recidivism; the Static-99, an actuarial tool designed to estimate the probability of sexual and violent recidivism; and the Violence Risk Scale – Sex Offender (“VRS-SO”), a rating scale designed to assess the risk of sexual recidivism that is used in connection with the delivery of sex offender treatment.""","Summary of Facts and Activity to DateThe Corrections and Conditional Release Act requires the Correctional Services of Canada (""CSC"") to take ""all reasonable steps"" to ensure information is accurate and complete about an inmate. The CSC used five different risk assessment algorithmic tools to make decisions about the inmates.Ewert is an inmate serving two sentences for murder and attempted murder. Ewert is Métis. Ewert filed the first suit about these internal review tools as early as early April 2000. Ultimately, Ewert's complaint is that the tools were made based on non-Indigenous people and were less accurate for him, and that CSC was violating the law by not showing proof first that the algorithms worked on Indigenous offenders. Ewert also brought claims for his Charter rights which were rejected by the Supreme Court.The CSC made claims to Ewert that they would study indigenous populations and the five psychological and risk assessment algorithms in 2007. However, by 2015 they had still not produced any cross-cultural validity data.In 2015, the Federal Court ruled for Ewert, granting declaratory relief and an injunction for using the algorithms on himself in the future and not using any of the past algorithmic results. Ewert's expert showed that there was a research gap on the validity of the tests, and the court mandated further study.Federal Court of Appeals overruled, finding Ewert did not show enough evidence of ""false results and conclusions"" and thus was not entitled to the injunction and research mandate.The Supreme Court on June 13, 2018 ruled for Ewert, holding that CSC had not taken reasonable steps to ensure and prove that its psychological and statistical algorithms that make decisions about Indigenous inmates are effective. The majority cites to facts that indigenous offenders are less likely to be granted early release, and classified as higher risk than non-indigenous inmates. The majority also points to CSC using the tools even with concerns. However, the Supreme court decision did not reinstate the injunction that the court of appeals overruled.The dissent disagreed on the definition of ""information"" about inmates to be the factual information and biographical information, and that CSC only needed to keep accurate records of the results of the tools. The dissent proposed that Ewert should have appealed the specific decisions the algorithm made about him rather than saying the whole algorithm did not take into account indigenous offenders.",Supreme Court Judgement,2014.0,Decided
35,35,"Faridian v. DoNotPay, Inc.","A DoNotPay consumer filed a class action lawsuit earlier this month in a California state court, alleging that the company violated California’s unfair competition law by holding itself out as a lawyer and engaged in the unauthorized practice of law by providing legal services without a law license. Jonathan Faridian claims that he used the company’s document drafting services under the belief that he was “purchasing legal documents and services that would be fit for use from a lawyer that was competent to provide them.” But many of the documents provided by DoNotPay were allegedly unusable as they included details that were inaccurate based on the information provided by Faridian. In one instance, the documents provided by DoNotPay were completely blank and were never delivered to the opposing party, Faridian alleges.",,US District Court for the Northern District of California,"Advertising, Fraud, Generative AI, Legal Research",Unfair Competition,"Unaware of Use of Algorithm, Reliability",2023-03-03,1/30/2024,https://blogs.gwu.edu/law-eti/?page_id=10&pid=119,Active,"A question here is whether DoNotPay’s use of artificial intelligence pushes this service beyond the mere provision of forms and general information and into the realm of legal advice. And whether the result would be any different if unlicensed humans provided the services instead of AI.Courts and regulators have consistently refused to accept AI as an author or creator of anything from a patent and copyright perspective. How does that perspective factor into a situation where AI is accused of giving legal advice? In this situation, it would make more sense to look at what DoNotPay is doing, rather than focus on whether humans or AI are doing it.","Summary of Facts and Activity to DateOn March 3, a class action was filed in the Superior Court of California, San Francisco County, by Jonathan Faridian as the named plaintiff against DoNotPay, claiming the defendant engaged in ""unlawful, unfair, and/or fraudulent business practices"" in violation of California's Unfair Competition Law.[6]The complaint highlights DoNotPay's display of the slogan, ""The World's First Robot Lawyer,"" on its website, along with snapshots marketing other services such as ""Defamation Demand Letters,"" ""Create a Power of Attorney,"" and ""Sue Anyone in Small Claims Court"" and a clickable button marked ""Solve This Problem For Me.""It alleges that, although ""DoNotPay is not a lawyer or law firm,"" the website ""offers customers the ability to purportedly hire a lawyer at the click of a button to handle a variety of legal matters,"" and that Faridian in fact ""believed he was purchasing legal documents and services that would be fit for use from a lawyer that was competent to provide them.""Faridian further alleges that the services provided to him ""were substandard and poorly done.""In short, the Faridian complaint focuses on the ""lawyer"" part of ""World's First Robot Lawyer"" and claims that, although DoNotPay holds itself out as one, it is not, in fact, a lawyer.The case is removed the SuperiorCourt of the State of California for the County of San Francisco to US District Court for the Northern District of California on April, 7th, 2023.",Motion Hearing AND Order on Motion for Miscellaneous Relief,2023.0,Active
36,36,"Federal Trade Commission v. Kochava, Inc.","The Federal Trade Commission filed a lawsuit against data broker Kochava Inc. for selling geolocation data from hundreds of millions of mobile devices that can be used to trace the movements of individuals to and from sensitive locations. Kochava’s data can reveal people’s visits to reproductive health clinics, places of worship, homeless and domestic violence shelters, and addiction recovery facilities. The FTC alleges that by selling data tracking people, Kochava is enabling others to identify individuals and exposing them to threats of stigma, stalking, discrimination, job loss, and even physical violence. The FTC’s lawsuit seeks to halt Kochava’s sale of sensitive geolocation data and require the company to delete the sensitive geolocation information it has collected.",,"District Court, D. Idaho","Health, Personal Injury, Privacy, Social Media","FTC Act, Permanent Injunction, Unfair and Deceptive Practices, Unfair and Deceptive Trade Practices",Privacy,2022-08-29,2/3/2024,https://blogs.gwu.edu/law-eti/?page_id=10&pid=128,Active,"Coming in the wake of the agency’s warning of a coming crackdown on commercial surveillance, this action reveals much about the agency’s stance toward data broker collection of consumer data, and geolocation data in particular. With this action, and the advance of the FTC’s ambitious commercial surveillance rulemaking effort,2 companies may be in for greater challenges over their use and sharing of consumer data.","Summary of Facts and Activity to DateOn August 29, 2022, the agency had filed suit against Kochava in the U.S. District Court for the District of Idaho for its alleged unlawful sales of precise geolocation data from hundreds of millions of mobile devices.As a marketing data broker, Kochava allegedly collects information about consumers, including data collected from hundreds of millions of consumer mobile devices. The FTC alleges that Kochava sells this information to its clients in customized data feeds that match unique mobile device identification numbers with timestamped latitude and longitude locations. Kochava allegedly made this data available to clients for a monthly subscription fee, along with a free sample, enabling clients to improve their advertising with analysis of foot traffic, user demographics, and other measurements.According to the FTC, Kochava’s sales of tracking data, or “sensitive geolocation data,” enabled the identification of individuals, “exposing them to threats of stigma, stalking, discrimination, job loss, and even physical violence.”The FTC’s complaint singles out Kochava’s alleged lack of technical controls to prevent identification of customers, pointing out that the company could have used a blacklist to remove or obfuscate location signals around sensitive locations within data setsWith this lawsuit, the FTC seeks to halt Kochava’s sale of sensitive geolocation data, and delete the sensitive geolocation data it has collected so far.On May 4, 2023, an Idaho federal judge dismissed the lawsuit and ruled that the Federal Trade Commission (FTC) needs stronger assertions of consumer harm in order for its data privacy suit against Kochava to proceed. The court simultaneously found no basis for Kochava’s suit to block the FTC’s enforcement action. The judge sided with Kochava’s argument that the agency had not adequately supported its claim that the company sales of geolocation data constituted unfair conduct under Section 5 of the FTC Act, finding no allegations that the practices “created a ‘significant risk’ of concrete harm.” The court gave the FTC the opportunity to refile. The FTC submitted a new complaint in June, 2023. Kochava requested that the court keep the amended complaint under seal, which it did until it could rule on the merits of the parties’ arguments.On November 3, 2023, the court granted the FTC’s motion to unseal the amended complaint, finding no “compelling reason” to keep the amended complaint under seal and rejecting Kochava’s arguments that the amended complaint’s allegations were “knowingly false” or “misleading.” As a result, the FTC’s amended complaint has been unsealed to the public.In all, the amended complaint generally alleges Kochava “sells data in several different forms” in its mobile data marketplace and that “Kochava uses records of consumers’ precise geolocation over time to categorize consumers into audience segments and then sell lists of consumers to others with promises that the details revealed by consumers’ movements will assist the third parties to identify and target individual consumers.”  All of this is done, according to the FTC, “without consumers’ knowledge or consent.”Kochava has claimed that many of the allegations in the amended complaint are misleading or are otherwise foreclosed by Kochava’s subsequent implementation of a Privacy Block feature following the FTC’s initial investigation.",Memorandum Decision and Order on Motion to Dismiss First Amended Complaint,2022.0,Active
37,37,"Flora v. Prisma Labs, Inc.","In Flora v. Prisma Labs, the plaintiffs allege Prisma failed to meet all of the Illinois Biometric Privacy Act (BIPA)’s procedural requirements before collecting Lensa users’ selfies, pulling their facial geometry information from those images, and training the model on those geometries to output personalized avatars.",,US District Court for the Northern District of California,"Biometric Data, Facial Recognition, Generative AI","Illinois Biometric Information Privacy Act, Unjust Enrichment","Facial Recognition, Failure to Disclosure, Personally identifiable Information, Unaware of Use of Algorithm",2023-02-15,8/8/2023,https://blogs.gwu.edu/law-eti/?page_id=10&pid=121,Active,"With Artificial Intelligence-generated portraits widely trending in social media, an Illinois class action lawsuit charges Prisma Labs, the company known for its Lensa smartphone app and AI art, with unlawfully collecting Illinois residents’ biometric data through their “Magic Avatars” AI-generated art. The Lensa app has been downloaded by millions and the “Magic Avatars” function used and shared by everybody from basketball stars to celebrities.Today’s class action lawsuit also highlights concerns from artists that the Lensa-created “magic avatars”—which use the open-source AI model Stable Diffusion that trained on 2.3 billion captioned images from the internet—violate the copyrights of art they have posted online. The suit further alleges that despite Lensa’s Terms of Use mandating a “no nudes” policy, the app would generate nudes from images containing nothing but headshots or fully-clothed images.","Summary of Facts and Activity to DateIn February 2023, plaintiffs filed suit against Prisma Labs, Inc., developer of the photo-editing app Lensa, alleging that the company violated the Illinois Biometric Information Act (BIPA) by purportedly storing Lensa users’ facial geometries without their consent. First, they allege Prisma violated section 15(a), requiring Prisma to develop a written policy establishing a schedule to destroy biometric data after a certain time; they allege Prisma violated section 15(b) for collecting user’s biometric data without first notifying the user in writing of the purpose and length of collect and receiving a written release form; they also allege violations of sections 15(c) by profiting off of biometric data collected to improve Lensa, 15(d) by transferring users’ biometric data to third-party cloud servers without disclosing this and receiving user consent, and 15(e) for failing to store user’s biometric data in a way that meets the industry standard of care. Importantly, the Flora plaintiffs rely heavily on the version of Prisma’s Privacy Policy that was in place when they downloaded the app in early December 2022. According to them, the wording of that policy was vague with the terms it used to describe the facial information Lensa collects, never using the terms “facial geometry” or “biometric” despite using the term “face data” in a separate part of the Policy (after claiming the company does not collect such data).The Flora plaintiffs also suggest that Prisma’s Privacy Policy states the company deletes users’ biometric data (gleaned from their uploaded selfies) within 24 hours of creating the avatars. But this claim by Prisma is spurious, as the ML community is still trying to understand the extent to which models memorize training data in ways that make it impossible to delete or remove that data from the ultimate models.In June, Prisma moved to compel arbitration on the ground that the plaintiffs had agreed to Lensa’s Terms of Use which provided that “all disputes arising out of or relating to these Terms or Lensa will be resolved through confidential binding arbitration.”  In opposing Prisma’s motion, the plaintiffs argued that the arbitration agreement was unconscionable.  The court rejected that argument.According to the court, the arbitration agreement, which was clearly written and labeled within the Terms of Use and provided users with the opportunity to opt out of binding arbitration, was not procedurally unconscionable.  Therefore, because “both procedural and substantive unconscionability must be present in order for an agreement to be enforceable,” the court did not address the question of whether the arbitration agreement was also substantively unconscionable.Despite rejecting the plaintiffs’ unconscionability argument, the court did agree with their argument that the arbitration agreement’s forum selection clause conflicted with the Judicial Arbitration and Mediation Services’ (JAMS) Consumer Minimum Standards by not providing users with the right to arbitrate in their home state.  According to the court, this rendered the agreement’s forum selection clause impermissibly illusory because of the possibility that JAMS might refuse to arbitrate the dispute based on the agreement’s failure to meet JAMS’ minimum standards.  Nevertheless, the court found the illusory forum selection clause severable.  Accordingly, the court severed the clause and compelled arbitration.",Order on Motion to Compel,2023.0,Active
38,38,Flores v. Stanford,Action claiming that parole procedures violate due process because they are based in part on risk assessment algorithms and do not involve the assessment of individual files,,"Federal: U.S. District Court, S.D. New York","Criminal Justice, Detention and Release",Due Process,"Individualized Assessment, Lack of Human Review",2018-03-20,4/11/2022,https://blogs.gwu.edu/law-eti/?page_id=10&pid=68,Active,The plaintiffs will have access to COMPAS and examine whether the programming holds young offenders' ages against them by treating youth as an aggravating factor in various ways and thus discriminates against them in the parole hearing.,"Summary of Facts and Activity to DateThis is a class action against the New York State Board of Parole. Each plaintiff was convicted by a New York State court of committing homicide as a juvenile. Each received an indeterminate prison sentence up to a maximum term of life with the possibility of parole, to be served in the custody of theNew York State Department of Corrections and CommunitySupervision (“DOCCS”). The Board assigns a “lead” commissioner for each parole interview. During the interview, only that lead commissioner has acomplete copy of the offender's parole file. Non-lead commissioners allegedly receive only a partial, “book copy” of the offender's file, one of which is “COMPAS report”—areport applying Correctional Offender Management Profiling for Alternative Sanctions (“COMPAS”), which DOCCS allegedly uses as a predictive risk assessment tool.The plaintiffs argue COMPAS holds young offenders' ages against them by treating youth as an aggravating factor in various ways. They seek to have access to COMPAS as the part of the discovery.On February 2nd, 2023 the court ordered that the parties should discuss settlement in good faith and as of May 5th, 2023 the parties have still been in mediation.",Order for good faith settlement,2018.0,Active
39,39,Force v. Facebook,"Suit dismissed against Facebook and cert denied by the Supreme Court, plaintiffs arguing that Facebook's algorithm suggests friends and groups based on similar interests, and highlights popular posts the user would like, and thus Facebook was providing the terrorist organization Hamas with means to reach an audience it would not otherwise have access to.",,Federal: US Dist. Ct. S.D. New York; Transferred to E.D.N.Y.,"Advertising, Social Media, Terrorism","Antiterrorism Act, Section 230","Lack of Remedy, Targeted Advertising",2016-07-10,5/18/2020,https://blogs.gwu.edu/law-eti/?page_id=10&pid=45,Inactive: cert denied,"The 2nd Circuit Dissent is the most important part of this case, which would have held Facebook liable for its algorithms and not immunized under Section 230: ""After collecting mountains of data about each user's activity on and off its platform, Facebook unleashes its algorithms to generate friend, group, and event suggestions based on what it perceives to be the user's interests. Id. at 345-46 ¶¶ 608-14. If a user posts about a Hamas attack or searches for information about a Hamas leader, Facebook may ""suggest"" that that user become friends with Hamas terrorists on Facebook or join Hamas-related Facebook groups. By ""facilitating] [Hamas's] ability to reach and engage an audience it could not otherwise reach as effectively,"" plaintiffs allege that Facebook's algorithms provide material support and personnel to terrorists. Id. at 347 ¶ 622; see id. at 352-58 ¶¶ 646-77. As applied to the algorithms, plaintiffs' claims do not seek to punish Facebook for the content others post, for deciding whether to publish third parties' content, or for editing (or failing to edit) others' content before publishing it. In short, they do not rely on treating Facebook as ""the publisher"" of others' information. Instead, they would hold Facebook liable for its affirmative role in bringing terrorists together.""","Summary of Facts and Activity to DatePlaintiffs filed their complaint on July 10, 2016, stating that Facebook uses algorithms to collect data and then ""actively"" suggest friends and groups to users, and ""actively"" promote posts that the user might like. Additionally, Facebook's uses targeted advertising. The complaint argues that Facebook allowed Hamas to reach and engage with the audience it would not have otherwise been able to effectively reach, and thus resulted in terrorist attacks.The amended complaint after the case was transferred to EDNY asserts this case concerns Section 230, and that Facebook violated the Anti-Terrorism Act by providing ""material support"" to Hamas through their algorithms. The amended complaint adds that Facebook had the power to flag, review and remove these Hamas accounts.The court granted Facebook's motion to dismiss because the claims were against Facebook in its publisher/speaker role under Section 230, and denied Force's motion to alter judgement and allow a second amended complaint. The reasoning:In July 2019, the Second Circuit affirmed that Section 230 immunized Facebook. The majority also rejected foreign law claims. Interestingly, Chief Judge Katzmann dissent in part to say that Section 230 did not immunize against these certain alleged actions of bringing terrorists together. The Second Circuit denied rehearing on August 29, 2019.Supreme Court denied certiorari on May 18, 2020.",Supreme Court Denied Cert,2016.0,Inactive
40,40,FTC v. Rite Aid Corp.,"On December 19, 2023, the Federal Trade Commission (“FTC”) announced that it reached a settlement with Rite Aid Corporation and Rite Aid Headquarters Corporation (collectively, “Rite Aid”) to resolve allegations that the companies violated Section 5 of the FTC Act (as well as a prior settlement with the agency) by failing to implement reasonable procedures to prevent harm to consumers while using facial recognition technology. The proposed settlement would ban Rite Aid from using facial recognition surveillance for five years and requires it to delete all biometric data collected in connection with its surveillance and to implement new safeguards.",,Eastern District of Pennsylvania,"Biometric Data, Facial Recognition, Generative AI","FTC Act, Permanent Injunction","Facial Recognition, False Positive Dilemma, Individualized Assessment, Lack of Human Review, Lack of Remedy, Misuse of AI, Personally identifiable Information, Unreliability",2023-12-19,12/19/2023,https://blogs.gwu.edu/law-eti/?page_id=10&pid=129,Active,"The complaint against Rite Aid marks the first time the FTC has used what’s known as its unfairness authority for enforcement action in relation to an AI system—an area for which privacy experts and advocacy groups have called on the agency to initiate rulemaking.Federal lawmakers have introduced legislation on algorithmic bias, but no bills have reached the House or Senate floor. Meanwhile, state regulators in Colorado, California, and elsewhere have made pushes for rules on when companies are required to notify customers about the use of AI, similar to the stipulated order’s requirements.In the lieu of federal law, the FTC has explored a rulemaking process to regulate commercial surveillance. The Rite Aid settlement could hint at how the agency may answer some of the questions raised about fairness and accuracy obligations raised in its August 2020 notice of proposed rulemaking, said Hutson.The action also highlights the agency’s growing interest in another tool in its belt: model deletion. The order is the sixth time in recent history, and the third in the past year, that the FTC has required a company to delete ill-gotten data used in algorithms and associated products.","Summary of Facts and Activity to DateOn December 19, 2023, the Federal Trade Commission (FTC or Commission) announced its settlement of an enforcement action against retail pharmacy chain Rite Aid over alleged violations of Section 5 of the FTC Act (Section 5) stemming from its use of facial biometric technology.According to the FTC’s complaint, Rite Aid “used facial recognition technology in hundreds of its retail pharmacy locations to identify patrons that it had previously deemed likely to engage in shoplifting or other criminal behavior.”  The FTC claimed that the technology sent alerts to Rite Aid’s employees when patrons were matched with entries in the company’s “watchlist database.”  Rite Aid employees allegedly took action against patrons who triggered the matches by, for example, subjecting them to in-person surveillance.  The FTC claimed that Rite Aid failed to consider or address foreseeable harm to patrons by such conduct, including failing to (1) test the technology’s accuracy, (2) enforce image quality standards necessary for the technology to function accurately, (3) take reasonable steps to train employees, and (4) “take steps to assess or address risks that its . . . [the] technology would disproportionately harm consumers because of their race, gender, or other demographic characteristics.”The proposed order will require Rite Aid to implement comprehensive safeguards to prevent these types of harm to consumers when deploying automated systems that use biometric information to track them or flag them as security risks. It also will require Rite Aid to discontinue using any such technology if it cannot control potential risks to consumers. To settle charges it violated a 2010 Commission data security order by failing to adequately oversee its service providers, Rite Aid will also be required to implement a robust information security program, which must be overseen by the company’s top executives.The proposed FTC consent order is subject to a 30-day public comment period following publication in the Federal Register.Rite Aid filed for relief under Chapter 11 of the Bankruptcy Code on October 15, 2023.  Accordingly, the settlement is also subject to approval by the U.S. Bankruptcy Court overseeing the company’s bankruptcy proceeding.",File Complaint,2023.0,Active
41,41,"Getty Images (US), Inc. v. Stability AI, Inc.","Leading stock image distributor sues developer of text-to-image generative AI model Stable Diffusion, alleging that many images in which it owns copyright have been used without authorization to train the model, and that its trademark has also been infringed through the appearance of the Getty Images watermark in images produced by Stable Diffusion as output.",Stable Diffusion,Federal: US Dist. Ct. D. Del.,Generative AI,"Copyright Infringement, Trademark infringement, Unfair and Deceptive Trade Practices, Unfair Competition, 17 U.S.C. 1202 Removal of Copyright Management Information",Copyright Infringement,2023-02-03,5/2/2023,https://blogs.gwu.edu/law-eti/?page_id=10&pid=94,Active,,"Summary of Facts and Activity to DateLeading stock image distributor Getty Images sues Stability AI, Inc., developer of text-to-image generative AI model Stable Diffusion, alleging that many images in which it owns copyright have been used without authorization to train the model, and that its trademark has also been infringed through the appearance of the Getty Images watermark in images produced by Stable Diffusion as output. Case was assigned to Judge Gregory Williams on February 8, 2023.  On May 2, 2023, defendant filed motion to dismiss for lack of personal jurisdiction, for failure to join a necessary party, and for failure to state a claim, and alternatively to transfer claim to the Northern District of California. On January 8, 2024 the case was reassigned to Judge Jennifer L. Hall.",Defendant filed motion to dismiss or to transfer,2023.0,Active
42,42,"Getty Images (US), Inc. v. Stability AI, Ltd.","Leading group of stock image companies sues developer of generative AI tool Stable Diffusion for copyright infringement, database right infringement, and trademark infringement.",Stable Diffusion,International - UK - High Court of Justice - Chancery Division - Intellectual Property List,Generative AI,Copyright Infringement,Copyright Infringement,2023-01-16,12/1/2023,https://blogs.gwu.edu/law-eti/?page_id=10&pid=87,Active,"The court's December 1, 2023 denial of Stability AI's summary judgment motion suggests that obtaining dismissal on jurisdictional and geographical grounds may not be that easy. Stability AI produced some affidavits suggesting that no training of Stable Diffusion had taken place in the UK, but the court decided that Getty still might be able to obtain evidence that some part of the training involving copying of images in which Getty owned copyright could have taken place in the UK.  Stability AI also argued that a UK provision regarding importation of infringing articles only applied to material objects, and that the importation of the Stable Diffusion software into the UK could therefore not violate that provision, but the court rejected that narrow interpretation.","Summary of Facts and Activity to DateGetty sues developer of generative AI tool Stable Diffusion in the UK for copyright infringement, database right infringement, and trademark infringement.  On December 1, 2023, the court denied Stability AI's motions for summary judgment or to strike.  On the claim for copyright infringement stemming from Stability AI's copying of Getty's images as training data, Stability AI moved for summary judgment on the ground that none of the training of Stable Diffusion was done in the UK, and therefore there was no infringement of UK copyright.  The court held that summary judgment was inappropriate because there was still some chance that Getty could prove that some of the training had taken place in the UK.  On the claim of secondary copyright infringement for importing an infringing article into the UK, Stability AI moved for summary judgment on the ground that importation involves material objects, and it at most sent information -- the pre-trained Stable Diffusion software -- into the UK, and not material objects.  The court rejected that narrow interpretation of importation.  The court also indicated that Stability AI had dropped its motions with regard to trademark infringement and passing off, so those would go to trial as well.",Court denies Stability AI's motions for summary judgment and to strike,2023.0,Active
43,43,"Gonzalez v. Google, LLC","Family of Nohemi Gonzalez, a victim in the 2015 ISIS attacks in Paris, sued Google and YouTube under the Anti-Terrorism Act. Gonzalez asserts that Google should not be eligible for immunity under Section 230 because YouTube recommended ISIS videos to users and collected ad payments from said videos. Arguments heard by Supreme Court on 2/21/2023. A Per Curium decision was reached on 5/18/2023.",,Ninth Circuit,"Social Media, Terrorism",Antiterrorism Act,Accountability,2016-06-14,5/18/2023,https://blogs.gwu.edu/law-eti/?page_id=10&pid=83,Active,"Nohemi Gonzalez, a US citizen, was studying in Paris in November, 2015, when ISIS terrorists fired into the crowd at her cafe, killing her and several others.  Gonzalez's family argues that YouTube, and YouTube's owner Google, lost Section 230 immunity because YouTube recommended ISIS content to others.  They also argue that the Anti-Terrorism Act (ATA) circumvents Section 230 immunity and that Google and YouTube provided knowing assistance to ISIS because they were aware that ISIS videos on their platform were being used for propaganda and that ISIS had monetized their videos on YouTube.","Summary of Facts and Activity to DateNohemi Gonzalez, a US citizen, was studying in Paris in November, 2015, when ISIS terrorists fired into the crowd at her cafe, killing her and several others.  The next day, ISIS claimed responsibility for the Paris attacks via a written statement and a video posted to YouTube. Gonzalez's family sued YouTube and Google, YouTube's owner, arguing that YouTube should be considered the ""publisher"" of the videos because YouTube had recommended ISIS videos to other users, allowing ISIS propaganda to reach more people.  Additionally, they argue that YouTube and Google are liable under the Anti-Terrorism Statute (ATA) because YouTube and Google knowingly allowed monetization of ISIS videos, allowing ISIS to profit from their YouTube videos.  Plaintiffs also argue that the ATA bypasses Section 230 immunity.The Northern District of California ruled that Section 230 immunity still applied to videos recommended by YouTube because the videos were uploaded by a user.  The District Court also ruled that the ATA did not bypass Section 230; rather, the laws should be read as cooperative, and Section 230 still protected a internet service provider whose service was used by a terrorist group to upload content.  Gonzalez appealed to the Ninth Circuit.The Ninth Circuit upheld the District Court's decision.Gonzalez petitioned for certiorari on 04/06/2022. The Supreme Court granted cert on 10/03/2022.The Supreme Court heard oral arguments for the case on 02/21/2023.On 5/18/2023, the Supreme Court decided the case Twitter v. Taamneh, where the court held that the families claims against the social media companies was not allowed under the antiterrorism act and that they did not make a ruling under Section 230. The Court in a Per Curium decision for Gonzalez vacated the Ninth Circuit judgement and remanded the case back to be reconsidered in light of the decision in Twitter.",Per Curium Decision by Supreme Court of the United States on 02/21/2023,2016.0,Active
44,44,"Hall v. Clearview AI, Inc.","Conversion, violates BIPA, Ill. UDAP; seeking injunctive relief (including deletion of data and compliance monitoring), damages, and litigation costs",Clearview,Federal: US Dist. Ct. N.D. Illinois; Transferred to US Dist Ct. S.D. New York; Transferred to US Dist. Ct. N.D. Illinois,Facial Recognition,"BIPA, UDAP","Facial Recognition, Privacy",2020-02-05,8/12/2020,https://blogs.gwu.edu/law-eti/?page_id=10&pid=38,Active,"The plaintiff voluntarily dismissed CDW as a defendant, while other similar suits did not. This case is one of three brought in ND Illinois that is consolidated with six SDNY cases, and at the time of the motion to dismiss there were already two Illinois and four SDNY cases on Clearview's radar.","Summary of Facts and Activity to DatePlaintiff Hall filed complaint on behalf of class action on February 5, just days after the first Clearview case was filed. Hall brought the case against Clearview, Clearview's founders, and CDW as a third party contractor to sell or lease access tothe surveillance database. On July 27, Plaintiff Hall voluntarily dismissed CDW as a defendant.The claims under BIPA and ICFA revolve around the report in January 2020 by the New York Times and Chicago Tribute that Clearview scraped 3 billion images from social media sites. Hall's action is based on: ""Because Hall has such a widespread and active social media presence, on information and belief, Hall’s biometric information and identifiers and his personal and private information are contained in Clearview’s database."" Hall claims to have experienced stress, anxiety, and emotional distress knowing that his private data was in Clearview's database, and he is at a higher risk for stalking and harassment, and has suffered ""actual damages"" from the loss of control of his biometric data.Clearview filed a motion to dismiss or transfer venue on April 27. The memorandum in support lists that New York is the Nexus of the cases, and that the plaintiff's claims overlap claims brought by others, four of six of which were brought in SDNY.The court denied the motion dismiss, and the case was combined into In Re Clearview in ND Illinois in January 2021 as all of the cases share: ""(1) share a common defendant (Clearview) and procedural posture (preanswer); (2) are putative class actions involving a class of Illinois residents; (3) allege that Defendants violated the Illinois Biometric Information Privacy Act (“BIPA”); and (4) seek the same relief"" as stated in the motion to transfer.Consolidated under Mutnick v. Clearview AI, Inc., still in ND Ill.",MDL Transfer,2020.0,Active
45,45,Henderson v. Steinsburg,"Prisoner files Section 1983 challenge to denial of parole using COMPAS risk assessment report, claims COMPAS algorithm discriminates on basis of race in violation of Equal Protection Clause",COMPAS,Federal: US Dist. Ct. W.D. Wisconsin,"Criminal Justice, Sentencing","42 USC 1983, Equal Protection",Use of Race,2018-07-16,4/5/2021,https://blogs.gwu.edu/law-eti/?page_id=10&pid=2,Active,"Plaintiff argued that defendants in charge of Northpointe knew of COMPAS's racial bias, and that the Wisconsin Parole Board defendants still used COMPAS even knowing it was biased instead of paying for an update or improvement. Henderson also argued that he had no way of knowing how the algorithm came to the predetermined, biased conclusion because he was not allowed access to the proprietary tool and that the correctional officers could inaccurately provide ""false negative comments"" into African American inmates' files without them knowing.The judge differentiates Henderson from Loomis because Loomis was a due process case about trade secrecy and use of gender, not an equal protection case, and studies do raise the concern about COMPAS and race. The Judge also notes that in the defendant's second motion to dismiss, it is not clear if the 2014 COMPAS risk assessment that produced the low risk was the same used to determine parole one year later, and thus converted the motion to dismiss into a summary judgment motion to give both plaintiff and defendants time for new briefs. In the motion for summary judgement, defendant insisted that there was no connection between COMPAS and Henderson's denial of parole.","Summary of Facts and Activity to DateTitus Henderson was convicted and incarcerated in the state of Wisconsin in July 1995, serving a 40-year sentence. In October 2014, COMPAS determined Henderson was low risk. After a Parole Hearing in November 2015, Henderson claims he was denied Parole and transfer from Wisconsin to Mississippi because of COMPAS's biased algorithm for both gender and against African-Americans because he would not sign the interstate compact release because it did not apply to him as a PMR inmate.In a March 2020 Memorandum, the Judge converted the Motion to Dismiss into a Summary Judgement Motion because he could not decide the issue solely on the pleadings and the 2014 COMPAS report, requiring new brief and Henderson's response. Judge rejected defendants' claims in their first motion to dismiss, arguing there is enough information to infer that the Department of Corrections knew of the racial bias and its harm to African American inmates, and rejecting the defendant's use of Loomis because Loomis was not an equal protection case. The Judge also denied in part defendants' argument that Henderson did not exhaust all other avenues before bringing this claim, only dismissing one defendant from the case.Defendants filed a motion for summary judgement on April 9, 2020, arguing that Henderson was not denied parole based on the COMPAS report.On November 12, 2020 defendants jointly filed to stay deadlines, with trial supposed to start on January 11, 2021 because they were waiting on responses to their motion to strike plaintiff's expert witness.On March 26, 2021 the Judge ordered the case dismissed, and on April 5, 2021 Henderson filed notice of appeal in the Seventh Circuit.",Appeal to 7th Circuit filed,2018.0,Active
46,46,Houston Federation of Teachers v. Houston Independent School District,"Texas Supreme Court rules in favor of teachers' procedural due process objections to the school district not turning over the code of how the teacher VAM (value added model) ratings were calculated that resulting in employment terminations, pay raises, and tenure",EVAAS,Federal: US Dist. Ct. S.D. Texas,"Constitutional Law, Employment, Performance Assessment, Termination","42 USC 1983, Procedural Due Process","Accountability, Transparency/Trade Secrecy",2014-04-30,8/13/2017,https://blogs.gwu.edu/law-eti/?page_id=10&pid=17,Inactive: Judgement for P,"Key to this case was the transparency of the proprietary value-added algorithm from a private enterprise, namely the ability for the teachers to access and thus understand how they were evaluated. HISD provided the data to SAS who generates the EVAAS scores and reports, of which HISD does not independently verify the results. The issue arises that teachers are not allowed to wait to challenge their EVAAS score once their contract has been terminated/not renewed.Plaintiffs bring issue with the HISD using the value-added measure and comparative growth measures on student test scores to evaluate if the teacher has added a value to the student's learning and performance on the state test. In their complaint, plaintiffs note the lack of scholarship supported value added models for individual teachers, citing: 1. VAMs for effectiveness are highly unstable, 2. teacher ratings significantly affected by the students assigned to them, and 3. VAM do not portray all the influences on a student's progress. Plaintiffs asserted that value added models merely predict how well a student will perform in the future based on past performance and can have large errors even with years of data.Plaintiffs also bring issue with the private company SAS whose algorithm HISD employed. This SAS VAM provides only a statistical estimate for what it dubbed the ""Teacher Gain Index"": it predicts the level of growth for a student, then evaluates if the student met that growth. The growth in 2013 was calculated compared to nationwide, which could result in negative or positive TGI scores for each student's class. The possible negative or positive results are translated into five categories as its ""value added rating"": TGI 2 or above is well above value added, and TGI -2 or below is well below, with the median greater than -1 but less than 1 meaning ""no detectable difference.""The teachers below the value-added rating were placed on growth plans to increase their scores, while not defining what is necessary growth as the scores are calculated after spring exams and teachers instruct new students in the fall. The teachers receive only vague generalities of their scores, not what they are doing that impacted the scores. Plaintiffs allege that administrators would conduct classroom observations of low scoring EVAAS teachers to find deficiencies to justify the low score. Plaintiffs cite that 74% of principals responded they were pressured to give teachers lower scores than they deserved.In the partial summary judgement order, the court noted that while procedural due process standards do not require exact replication, since EVAAS scores were calculated to the second decimal so an error could create a different VAM rating, so because teachers have no way of verification of their scores they are subject to mistaken deprivation of property interests in their jobs. The substantive due process summary judgement motion was granted because even though EVAAS falls short in many ways, under the constitutional standard of rationality government entities can use ""blunt tools which may produce only marginal results"" and did not meet the constitutional standard of vagueness simply because it may be prone to error. The court concluded that the EVAAS tool did not meet the equal protection claim, and even if it did, it already passed the rational basis substantive due process review.The settlement agreement determined that HISD would cancel its contract for EVAAS and only use the model for ""informational purposes"" and instead form an instructional consultation committee to recommend how to evaluate and appraise teachers.","Summary of Facts and Activity to DateThe Houston Independent School District contracts teachers for a three-year probation, and then a term contract, except for continuing contracts decided prior to 1996. In 2012-2013, on top of evaluating teacher instructional practice through classroom observations, HISD began appraising teachers by their students' success on end of year State of Texas exam, measuring growth and achievement. HISD then evaluates teachers of core subjects under value added and comparative growth measures under the EVAAS system. This value-added calculation impacts teacher contracts, retirement, and teaching plans, with no explanation of the scores. Other issues include that 1. the end of year Texas state exams do not test middle school science/social studies, so the teachers are evaluated compared to national standards, 2. the end of year exams are in English which disadvantage English language learners, and 3. high achieving students are less likely to show """"improvement.""""The plaintiffs, including the labor union Houston Federation of Teachers, sued under both equal protection and due process under the 14th amendment, and that the teachers had a continued property interest in their employment, over termination of employment based on the value-added models.On September 28, 2015, the court granted a protective order for the plaintiffs.The court granted partial summary judgement for HISD on the substantive due process and the equal protection claims but denied summary judgement on the procedural due process claims as the lack of verification lead to deprivation of property interests on May 4, 2017.In the settlement agreement, both parties agreed to settle without admission on any of the merits of the claims and contentions, with HISD specifically still denying plaintiff's claims. It provided: 1. future VAM scores would not be used as the basis to terminate contracts, 2. HISD forms an instructional consultation committee to make recommendations on teacher evaluation process, 3. HISD pays attorney’s fees, 4. plaintiffs dismiss lawsuit with no pending claims and no admission of liability.",Order granting motion to abate because of settlement,2014.0,Decided
47,47,Huckabee v. Meta Platforms,"A group of book authors seek to bring a class action on behalf of all owners of copyright in works that were used to train the large language models of defendants Meta Platforms, Microsoft, and Bloomberg, claiming copyright infringement, removal of copyright management information, conversion, negligence, and unjust enrichment.","BloombergGPT, LLaMA",Federal: US Dist. Ct. S.D.N.Y.,Generative AI,"Conversion, Copyright Infringement, Negligence, Unjust Enrichment, 17 U.S.C. 1202 Removal of Copyright Management Information",Copyright Infringement,2023-10-17,10/17/2023,https://blogs.gwu.edu/law-eti/?page_id=10&pid=104,Active,,"Summary of Facts and Activity to DateComplaint filed October 17, 2023. A number of authors, including former Arkansas governor Mike Huckabee, filed suit against Meta, Bloomberg, Microsoft, and Eleuther AI Institute, for using 183,000 e-books to train their LLMs which the plaintiffs claim is an infringing use.",Complaint filed,2023.0,Active
48,48,"Hudson v. Tesla, Inc.","Customer brought suit against Tesla for autonomous vehicle crash when his vehicle did not detect another vehicle, arguing that Tesla's advertising convinced customers that the autopilot could safely operate with minimal driver input and oversight",Autopilot,State: Florida,Autonomous Vehicles,"Breach of Implied Warranty, Florida’s Deceptive and Unfair Trade Practices Act, Negligence","False Positive Dilemma, Product Liability, Underperformance",2018-10-30,4/29/2021,https://blogs.gwu.edu/law-eti/?page_id=10&pid=26,Closed,"A personal injury and consumer protection lawsuit for injuries plaintiff suffered when his Tesla crashed into another vehicle while in autopilot mode. In this case the Autopilot of the Tesla was unable to detected a disabled vehicle that had stalle in his lane, and in turn crashed into it.","Summary of Facts and Activity to DateOn the Morning of October 12, 2016 Hudson was travelling southbound at approximately 80 mph in the left lane on a stretch of Florida Turnpike. He had engage the Tesla's autopilot and was relaxing during his commute. Unbeknownst to Hudson, his model S was rapidly approaching a disabled vehicle that had stalled in his lane of travel. Suddenly, and without any warning, the Model S crashed into the disabled vehicle. The entire front area of Hudson’s model S was destroyed. Hudson suffered permanent injuries.Hudson specifically bought his 2017 Tesla Model S with the autopilot feature because Tesla represented that the autopilot system could detect a hazard, and alert the driver if necessary. The sales rep assured Hudson that all ne needed to da as the ""driver"" was to occasionally place his hand on the steering wheel and the vehicle would do everything else.The case was dismissed voluntarily by the plaintiff on April 29, 2021.",Case Dismissed,2018.0,Closed
49,49,Huskey v. State Farm Fire & Casualty Company,"Jacqueline Huskey sued the insurer Dec. 14 in the U.S. District Court for the Northern District of Illinois, alleging its reliance on biased algorithms disproportionately subjects claims made by Black policyholders to ""greater suspicion"" and ""greater administrative process and delay"" than those made by white policyholders.",,US District Court for the Northern District of Illinois,"Civil Rights, Generative AI, Housing","Fair Housing Act, Permanent Injunction","Lack of Human Review, Lack of Remedy, Programmer Bias, Socioeconomics Bias, Use of Race",2022-12-14,12/29/2023,https://blogs.gwu.edu/law-eti/?page_id=10&pid=116,,"The lawsuit has potential to be groundbreaking, not only in scope — hundreds of unnamed plaintiffs may join Huskey once the case receives class action certification, exposing State Farm to hundreds of millions in potential liability — but also because of its reliance on the insurer’s allegedly discriminatory internal data-mining.","Summary of Facts and Activity to DateThe plaintiffs filed this putative class-action lawsuit against State Farm in the U.S. District Court for the Northern District of Illinois on December 14, 2022 under the Fair Housing Act (FHA), 42 U.S.C. § 3601 et seq. The lawsuit alleged that State Farm dealt with homeowners insurance claims in a racially discriminatory manner. Represented by private counsel and the Center on Race, Inequality, and the Law at NYU School of Law, the plaintiffs sought a declaratory judgment, injunctive relief, damages, and attorneys' fees and costs. The plaintiffs alleged that the program State Farm used to predict if claims might be fraudulent was biased against Black homeowners, causing them to have to go through more hurdles when they submitted claims than white homeowners.The case was assigned to Judge Virginia M. Kendall. On March 31, 2023, the plaintiffs filed an amended complaint, in which an additional individual plaintiff was added. State Farm filed a motion to dismiss the amended complaint on May 15, 2023, claiming that the claims were preempted under the McCarran-Ferguson Act, the plaintiffs did not plausibly allege a disparate-impact claim, and neither plaintiff adequately alleged the elements of an FHA violation.On September 11, 2023, the court granted in part and denied in part State Farm's motion to dismiss. The court dismissed the plaintiffs’ claims under 42 U.S.C. § 3604(a) and § 3605 of the FHA without prejudice. The court dismissed the claim under § 3604(a) because the plaintiffs failed to allege that State Farm's actions were responsible for their homes becoming ""unavailable,"" as the statute requires. The court dismissed the claim under § 3605 because insurers are not considered an “entity” within the meaning of the statute. It also dismissed one of the named plaintiffs' claims for injunctive relief due to lack of standing, as the plaintiff was not a State Farm customer anymore. Plaintiffs’ remaining claim under § 3604(b) survived because homeowners insurance is sufficiently related to housing sales for the statute to apply.The court also held that the plaintiffs had sufficiently alleged a disparate impact claim because they cited statistical evidence and connected it to State Farm's claims-processing algorithms. Finally, the court rejected State Farm's argument that the plaintiffs' claims were barred by the McCarran-Ferguson Act, which prevents certain federal laws from interfering with state insurance law. However, the court acknowledged that the applicability of the McCarran-Ferguson Act could change based on how the litigation proceeded. 2023 WL 5848164.As of October 19, 2023, the case is ongoing.",Local Rule 3.2 Annual Reminder Order,2022.0,Not specified
50,50,IBM Corp. v. Indiana,"Algorithm-adjacent, this case involves electronic automation including statistical methods to determine eligibility for Indiana benefits programs, and after four appeals the Supreme Court ruled for the State who terminated a billion dollar contract with IBM after three years of performance issues.",,State: Indiana,"Disabilities Benefits, Health","Breach of Contract, Performance Metrics","Lack of Remedy, Underperformance, Unreliability/Miscalculationns, AI Adjacent",,12/9/2020,https://blogs.gwu.edu/law-eti/?page_id=10&pid=52,Active,"The electronic automation of Indiana's benefits selection program. The dissent of the March 2019 Supreme Court opinion disagreed that the damages awarded to the state largely to fund the ""hybrid"" system the State eventually implemented instead of IBM's modernization, viewing the implementation as not direct damages because IBM was only required to implement modernization and not hybrid as well.","Summary of Facts and Activity to DateIn 2006, Indiana contracted with IBM to modernize the welfare system with electronic automation. The billion-dollar contract was for 10 years. After three years, Indiana terminated the contract for performance issues. Both IBM and Indiana filed lawsuits about this terminated contract, and the issue was whether Indiana could terminate the ten year contract over performance issues. The Marion County Superior Court consolidated the case before them in 2010. The State separately appealed to the Supreme Court to avoid a deposition by Governor Daniels. The trial court granted partial summary judgement for assignment fees to IBM, and then in 2012 found no material breach by IBM. The first appeal, filed by both parties, saw the Supreme Court reverse the material breach finding and reverse other damages except the assignment fees. The case remanded to the trial court for damages calculations, which was appealed to the Supreme Court by both the State and IBM in calculating pre- and post-judgment damages. In 2017, the trial court rejected IBM's motion for post-judgement interest on the 2012 partial summary judgment award for assignment damages, but granted the State's motion for post-judgement interest damages. The rationale was to ""compensate[] plaintiffs for the loss of money that has been determined to be have rightfully belonged to them."" IBM appealed and in 2019 the Supreme Court affirmed the trial court and Court of Appeals' calculation of damages for State. The State filed a Verified Motion to Enter Final Judgement, and the trial court denied this motion in March of 2020. The State appealed, but the Supreme Court affirmed the proper denial.",Court denied state to receive more money from IBM,,Active
51,51,In re BlueCrest Capital Mgmt Ltd.,SEC found both negligent and willful violations against BlueCrest for omissions and misstatements to both potential and existing investors and indpendent directors about the use of their Rates Management Trading in that it underperformed compared to live traders and misrepresented its high usage of the algorithm it had told investors was merely experimental.,RMT,Government: SEC Adjudication,"Investment, Trading","Negligence, Securities Act Section 17A, Willful Violation","Conflict of Interest, Failure to Disclosure, Misrepresentation to Client, Unaware of Use of Algorithm, Underperformance",2020-12-08,2/18/2022,https://blogs.gwu.edu/law-eti/?page_id=10&pid=11,Active,,"Summary of Facts and Activity to DateIn total Bluecrest was fined 170 million dollars and paid the fine in full. On February 18, 2022, the SEC released a Corrected Order Approving Plan of Distribution for the 170 million dollars.",Corrected Order Approving Plan of Distribution,2020.0,Active
52,52,In Re Clearview Litigation,"The consolidation of ten multidistrict litigation class action lawsuits against Clearview AI for 1. violating BIPA 2. unjust enrichment and 3. violating the plaintiffs' civil rights: Calderon, Broccolino, McPherson, Burke, John, and Roberson from SDNY; Mutnick, Hall, and Marron in ND Ill; and Renderos in ND Cal. A case not consolidated was Carmean v. Macy's.",Clearview,Federal: US Dist. Ct. N.D. Illinois,"Biometric Data, Facial Recognition","BIPA, Civil Rights, Unjust Enrichment","Misrepresentation, Privacy",2021-01-08,11/30/2023,https://blogs.gwu.edu/law-eti/?page_id=10&pid=48,Active,"Clearview intended to consolidate these cases because they each spurred from the same facts and allegations. The state law claims against Clearview for violating the Biometric information Privacy Act (""BIPA"") section 15(c) for profiting and sharing biometric data, but the claims do not include section 15(a) or 15(b) for consent and data retention.The current motion for injunction is to enjoin Clearview from future uses of its facial recognition software in a global context, particularly given its pending patent.","Summary of Facts and Activity to DateEleven cases were brought in 2020 relating to Clearview and co-defendants unlawfully collecting and profiting off of biometric data from three million photographs online, violating BIPA, unjustly enriching Clearview, and violating the civil rights of these plaintiffs. The first case was filed in January 2020.Clearview intended to consolidate eleven cases in federal court in New York, but nine cases were consolidated in Illinois under a MultiDistrict Litigation Order in January 2021. Six of these cases came from SDNY and three from ND Illinois. Clearview had previously removed these claims to federal court under the Class Action Fairness Act. In addition, the cases Thornley and ACLU in Cook County of Illinois charge BIPA violations, and there is a California state case filed.In late October 2020, the circuit judge ruled that because ""plaintiffs are seeking only statutory damages, not actual damages for “a concrete, particularized harm,” the suit fails to meet the criteria for standing in federal court."" Clearview appealed to the Seventh Circuit Court of Appeals in January, but the court rejected the appeal. Clearview filed a motion to rehear its appeal in February, arguing that they have federal standing because previous cases have ruled that data is a property harm.The parties mediated throughout February, and filed a Joint Proposed Case Management and Discovery Plan on March 22. Plaintiffs are challenging ""Clearview's entire operation over multiple years"" and proposed six months for factual discovery whereas Clearview proposed one year and emphasized that the fact that other state law cases are being brought should not impact this discovery. Clearview also urged the court to reject the plaintiff's request to reserve the right to file for class certification prior to defendant's ""anticipated"" motion to dismiss.On November 30, 2023, a minute entry before the court stated that the parties had settled the case in principle and an in person status hearing will be held on January 23, 2024.",Minute Entry stating parties have settles in principle,2021.0,Active
53,53,In re Google Assistant Privacy Litigation,"The California District court allowed the proposed class action to pursue California Privacy law claims, and to refile consumer protection claims, for Google devices accepting ""False Accepts"" from their smartphone voice assistants and then illegally recording and disseminating the private conversations",,Federal: Northern District of California,Privacy,"Biometric Information Privacy Act, Commercial Misappropriation","Failure to Disclosure, Notice, Privacy",2019-07-25,,https://blogs.gwu.edu/law-eti/?page_id=10&pid=64,Active,The court found GooglePdid not have authorization to disclose any audio recordings or transcripts resulting from false accepts. It did so for analyses and improvement of Google Assistant for its own financial benefit and targeting personalized advertising to users.,Summary of Facts and Activity to DateGoogle Assistant produces a script of each audio recording that it stores. Google hires human subcontractors to comparing the script to the audio recording and check the accuracy of the Google Assistant's interpretation. Google Assistant may be triggered into active listening mode (false accepts). Google stores these recordings for future advertisements.,,2019.0,Active
54,54,IN RE: TransUnion Rental Screening Solutions FCRA Litigation,"The lawsuit claims that TURSS failed to maintain reasonable procedures to ensure maximum possible accuracy in its reporting of certain Criminal and/or Landlord-Tenant Records. Plaintiffs claim that Defendant's alleged practices violated the federal Fair Credit Reporting Act (""FCRA""). TURSS denies it did anything wrong. The Court did not decide whether either side was right or wrong. Instead, both sides agreed to the Settlement to resolve the case and provide benefits to Class Members.",,"District Court, N.D. Georgia","Civil Rights, Housing",Unfair Competition,"Lack of Human Review, Unreliability",2020-04-27,10/3/2023,https://blogs.gwu.edu/law-eti/?page_id=10&pid=137,Inactive,"TURSS provides background screening reports about consumers to thousands of clients, including rental property owners, property management companies, employers, and other background screening companies, for tenant and employee selection. These reports may include information about consumers’ criminal and eviction records, including the amount sought by a landlord in court, any judgment amount the court may award, and the amounts owed by consumers. Trans Union LLC manages and oversees TURSS’s compliance with the FCRA.Inaccurate and outdated information in tenant screening reports can significantly hamper consumers’ ability to find housing, costing them time and money by prolonging their search for housing, requiring them to pay additional application fees and spend time correcting errors in their background reports.TURSS obtains eviction records from third-party provider LexisNexis Risk and Information Analytics Group, Inc. but has failed to take steps to ensure the accuracy of the data it was provided.","Summary of Facts and Activity to DatePlaintiffs filed class action lawsuit against TransUnion Rental Solutions (TURSS). Plaintiffs claimed that TURSS included false information in consumer reports which wrongfully attributed criminal records and evictions to consumers.The Court held a Final Approval hearing on September 21, 2023, and granted Final Approval of the Settlement. The Policy Settlement provides injunctive relief benefits to all Policy Settlement Class Members. An injunction occurs when a court orders a person or company to do or not to do something. In this case, the Court ordered TURSS to change its business practices. The Settlement requires TURSS, at its expense, to design, implement, and maintain specific and substantial procedures that address the lawsuit’s concerns about TURSS’s reporting of criminal and landlord-tenant records.Changes to TURSS’s business practices will include:1. implementing matching procedures whereby Criminal Records will not be attributed to any consumer in a Consumer Report unless TURSS matches the following identifying information of the applicant received by TURSS from the applicant and/or its customer at the time of the matching to the following identifying information contained within the public Criminal Record maintained by TURSS at the time of the matching: (i) a qualifying match on name; plus (ii) a qualifying match on date of birth, address or Social Security Number;2. implementing changes in the formatting of its reporting of Landlord-Tenant Records in a Consumer Report to group records relating to a single legal proceeding between a landlord and tenant3. implementing changes to reasonably ensure that TURSS does not report Landlord-Tenant Records from sources that are visited less frequently than every sixty days.",CONSENT INJUNCTIVE RELIEF ORDER,2020.0,Inactive
55,55,In the Matter of [Juvenile Client],"Superior Court granted defendant's motion not to consider SAVRY (Structured Assessment of Violence and Risk in Youth) to calculate sentencing for felony assualt and possession of prohibted weapon because of a lack of research proving efficacy and racially targetted risk factors, declining to set precedent for future cases",SAVRY,State: Dist. of Columbia,"Criminal Justice, Sentencing",Federal Rule of Evidence 702,"Insufficient Research, Role of Expert Testimony, Socioeconomics Bias, Use of Race, Unreliability/Miscalculationns",2017-09-20,3/15/2018,https://blogs.gwu.edu/law-eti/?page_id=10&pid=6,Inactive: Judgement for D,"While the court ultimately decided against using the Violence Risk Assessment algorithm in this juvenile's case, the court declined to rule against the algorithm's use for all future cases, and thus did not result in the discontinuation of the algorithm for future cases.Juvenile's team took issue with SAVRY that it was not valid because 1. could not be tested for falsity, noting there was no error rate and therefore no false positive rate for SAVRY, 2. peer review journals did not support the validity of SAVRY, 3. the lack of known error rate and bias leads to racial disparities and misuse of SAVRY when used against lower income children of color, 4. evaluators can rely on empirical data rather than SAVRY, 5. SAVRY is being used for different purpose than it was originally designed, as children are almost always found to be high risk, no matter the factors.Juvenile's team also argued that SAVRY was inadmissible evidence because 1. using as a general violence predictor was inconsistent with its intended use for continuous monitoring and prevention, 2. in this case the SAVRY model did not follow best practices as it only used data from an interview with the juvenile's father, his probation officer, and a secret source in Metro PD, 3. it miscalculated and elevated certain factors, and 4. it resulted in subjective and unsubstantiated judgements","Summary of Facts and Activity to DateOn September 20, 2017, the Juvenile was charged with one count each of Assault with Intent to Commit Murder while Armed, Possession of a Prohibited Weapon (knife), Assault with Intent to Kill while Armed, Aggravated Assault while Armed, Felony Assault, and Carrying a Dangerous Weapon (knife).On October 30th, the Juvenile entered into a Plea Agreement to One Count Felony Assault, One Count Possession of Prohibited Weapon.Juvenile's team filed a request for the exclusion of results and testimony related to VRA Violence Risk Assessment based on Dabuert v. Merrel Dow and FRE 702 for being generally unreliable and for racial disparities in the factors. The Court conducted an evidentiary hearing on the Juvenile's motion and statements on March 13, 2018.The court ultimately granted in part Juvenile's motion to exclude the Violence Risk Assessment conclusions and recommendations but denied in part to consider the underlying information contained in the Assessment in determining an appropriate disposition in this case.",Exclusion of VRA in sentencing,2017.0,Decided
56,56,"In the Matter of HireVue, Inc.","EPIC filed a complaint and request for investigation, injunction, and other relief with the FTC, arguing HireVue's opaque and proprietary tools were unproven, biased, and invasive as it claimed to measure ""cognitive ability,"" ""psychological traits,"" ""emotional intelligence,"" and ""social aptitudes"" of job applicants without using facial recognition technology.",HireVue,Government: FTC,"Employment, Facial Recognition, Hiring","FTC Act, Public Policy, Unfair and Deceptive Trade Practices","Lack of Scholarly Review, Programmer Bias, Transparency/Trade Secrecy, Use of Race, User of Gender",2019-11-09,1/21/2021,https://blogs.gwu.edu/law-eti/?page_id=10&pid=46,Active,"HireVue provides a service to companies to evaluate their job candidates' facial expressions, gestures, posture, and tone. Candidates do not have access to the data or factors used to generate the algorithmic assessment. EPIC cites statistics that facial recognition technology discriminates based on skin tone, neurological differences with eye movement, gender. EPIC asserts that these algorithms were programmed with the top performers being white males, thus inherently biased.The main issues of the public policy principles are that HireVue's findings cannot be challenged, subject ot trade secrecy that candidates do not know how they are evaluated and cannot access that information, and that HireVue has not shown the accuracy and validity of its assessments.EPIC's argument relies heavily on public policy and cites to the FTC's 2019 finding that Facebook's facial recognition technology was deceptive and misrepresented how much the consumer could control their privacy.In response to public outcry, HireVue announced on January 21, 2021 that it would stop relying on facial analysis for job assessment.","Summary of Facts and Activity to DateEPIC filed a complaint with the FTC on November 19, 2019 that HireVue has violated Section 5 of the FTC Act engaging in unfair and deceptive practices by making claims to consumers without a reasonable basis for the claims, and causes or is likely to cause substantial injury ot ht consumer, and misrepresented the amount of control consumers had over their privacy.HireVue uses both an applicant-recorded video interview and online games to evaluate ""thousands of data points"" from a candidate, then using predictive algorithms to calculate the job candidate's employability. EPIC notes that job candidates do not have access to the ""training data, factors, logic, or techniques used to generate each algorithmic assessment. In some cases, even HireVue is unaware of the basis for an algorithmic assessment."" EPIC claims that HireVue is incorrect to say it does not engage facial recognition technology. Next, EPIC claims that HireVue's recruiting tools are biased and discriminatory by gender, those with neurological disorders, by race, and attempting to identify sexual orientation.Along with the FTC Act, EPIC brings this action citing to public policy AI Principles from the Organization for Economic Cooperation and Development (""OECD"") and the Universal Guidelines for Artificial Intelligence (""UGAI"") The complaint states HireVue violated the policies of Fairness, Security/Safety, Transparency and Explainability, Accountability, Accuracy/REliability and Validity.The FTC has not published any indication of where the investigation is into the matter.","Hirevue is under investigation and announced that it will stop relying on ""facial analysis"" to assess job candidate",2019.0,Active
57,57,"Inkie Lee v. Tesla, Inc.","A class action lawsuit accuses Tesla of selling vehicles with a defect that causes unexpected and dangerous acceleration. Numerous plaintiffs have lodged their claims in the Tesla class action lawsuit, arguing the Model X, Model S and Model 3 can accelerate suddenly without the driver’s doing. The defect allegedly produces full power and acceleration, even if the driver is not pressing the acceleration pedal.",Autopilot,"District Court, C.D. California",Autonomous Vehicles,"Breach of Contract, Breach of Implied Warranty, Express Warranty Breach, False Advertising, Magnusson-Moss Warranty Act, Unfair Competition","Product Liability, Underperformance",2020-01-20,10/1/2020,https://blogs.gwu.edu/law-eti/?page_id=10&pid=126,Inactive,"According to the plaintiffs, the integrated electronic hardware and operating software of Tesla’s 2013-2020 Model S, 2016-2020 Model X, and 2018-2020 Model 3 all suffer from a defect which causes the unexpected acceleration.This case is not alone; the issue was reportedly exposed in a high profile case where a Tesla Model 3 accelerated suddenly, ran off a public highway and struck an office building – killing an office worker in the impact.In another incident, consumer Hacene Djemil was trying to park his car and reportedly ended up ramming across the parking lot into the wall of a Subway restaurant. Djemil claims that the car accelerated without his input, resulting in serious injuries to his wife and children. The plaintiffs say they have also had similar experiences.","Summary of Facts and Activity to DateThe suit, which was first filed in January on behalf of eight Tesla vehicle owners in five states, was expanded in July to include 23 named plaintiffs in 11 states alleging Tesla's Model S, Model X and Model 3 electric vehicles contained a ""sudden uncommanded acceleration"" defect.The plaintiffs contend they have ""empirical and anecdotal evidence"" indicating that the integrated electronic hardware and operating software of Tesla's 2013-2020 Model S, 2016-2020 Model X and 2018-2020 Model 3 all suffer from the acceleration defect.The allegations stem from a preliminary review the National Highway Traffic Safety Administration launched in January after receiving a petition requesting a formal investigation into complaints that as many as 500,000 Tesla vehicles contained a defect that can cause sudden unintended acceleration, which may result in crash and injury.The named plaintiffs are seeking to represent a nationwide class as well as classes of drivers in California, Arizona, Florida, Georgia, Massachusetts, New Jersey, North Carolina, Oregon, Pennsylvania, Texas and Washington.Tesla's motion seeks to dismiss the claims of all but one each of the California, Arizona and Texas plaintiffs, and the only plaintiffs named in New Jersey and Massachusetts.Tesla argued that the plaintiffs named in the motion agreed to arbitrate their claims either through signed agreements or through an online process. The company argues the arbitration agreements were clearly outlined with fair, reasonable terms that would not qualify as being unconscionable.Tesla also argued that the arbitration agreements are meant to benefit the customers by being ""designed to ensure that Tesla's customers have a simple and efficient means of resolving disputes"" with the company.The District Court of Central District of California grants in part Telsa's Motion to Compel. For the residents of California listed in Tesla’s motion to compel, the Court compels arbitration of their individual claims but declines to compel arbitration of their requests for public injunctive relief. For the residents of Arizona, Florida, Georgia, Oregon, Pennsylvania, Texas, and Washington listed in Tesla’s motion to compel, the Court compels arbitration of all their claims. The Court also STAYS the proceedings for all parties pending the binding arbitration.",Order Regarding Defendant Tesla's Motion to Compel Arbitration,2020.0,Inactive
58,58,"John v. Clearview AI, Inc.","Class transferred and consolidated into In re Clearview, complaint charged that Clearview violated BIPA, Cal. UDAP (unfair), Cal. right to publicity, Cal. Const. privacy, interference with K with social media companies, and unjust enrichment and sought seeking injunctive relief, damages, restitution, disgorgement, and litigation costs",Clearview,Federal: US Dist Ct. S.D. New York; Transferred to US Dist. Ct. N.D. Illinois,Facial Recognition,"BIPA, Contracts, Right to Privacy, UDAP, Right to Publicity, Unjust Enrichment",Privacy,2020-05-04,1/12/2021,https://blogs.gwu.edu/law-eti/?page_id=10&pid=24,Active,"The fifth of the six New York cases consolidated under MDL, this case was brought after Judge McMahon's April 22 Directive regarding Calderon, Broccolino, Burke, and Roberson.Of the class, there are four subclasses: Nationwide, Illinois, New York, and California. John is from New York, Balfanz is from California, and Jais and the rest of the class are from Illinois. This is the first action where the class is from three or more states.The complaint emphasizes Clearview's lack of data security on top of its violation of privacy.","Summary of Facts and Activity to DateThe complaint is brought in SDNY against Clearview and its cofounders Hoan Ton-That and Richard Schwartz for violating BIPA. Like other complaints, complaint emphasizes Clearview's marketing of its proprietary facial recognition technology, and its paid contracts with ICE, foreign governments, and fitness, retail and entertainment companies.Judge McMahon ordered a statement of relatedness to Calderon, which was filed on May 5, 2020, finding that the SDNY cases and Illinois case 1. concern the same or substantially similar parties, transactions and events, 2. the facts substantially overlap, 3. the parties could get conflicting orders and 4. there would be duplication of effort and expense on the court, parties and witnesses if there is not a determination of relatedness.The six New York cases were stayed by Judge McMahon on September 9 pending a decision on MDL.On January 12, 2021, the case was transferred to the Northern District of Illinois. Assigned Case Number 1:21-cv-00173.",MDL Transferred out,2020.0,Active
59,59,"Justine Hsu v. Tesla, Inc.","Justine Hsu, a resident of Los Angeles, sued the EV maker in 2020, saying her Tesla Model S swerved into a curb while it was on Autopilot and then an airbag was deployed ""so violently it fractured Plaintiff's jaw, knocked out teeth, and caused nerve damage to her face.” Hsu alleged negligence, fraud and breach of contract in her 2020 suit. Tesla denied liability for the 2019 accident. Tesla was found by a Los Angeles jury not to be at fault following a trial.",Autopilot,Los Angeles County Superior Courts,"Advertising, Autonomous Vehicles, Generative AI","Breach of Contract, Breach of Implied Warranty, Common Fraud, Express Warranty Breach, Failure to Warn, Fraud, Implied Warranty Breach, Intentional Torts, Negligence, Product Liability","Product Liability, Underperformance",2020-05-14,5/30/2023,https://blogs.gwu.edu/law-eti/?page_id=10&pid=132,Inactive,The verdict gives the electric-car maker a victory in what appears to be first such case to go to trial amid years of controversy over the safety record of its assisted self-driving feature and continuing federal probes into whether Autopilot has defects.,"Summary of Facts and Activity to DateThe plaintiff, Justine Hsu, was driving her Tesla in stop and go traffic on a surface street with a concrete median in Arcadia, California. She activated Autopilot, a suite of features that includes “traffic aware cruise control,” a system that automatically adjusts speed based on traffic conditions and that is, according to her complaint, popular among Tesla owners in heavy traffic. The car was driving about 20-30 miles per hour when it suddenly swerved off the road and into the median. At this point the car’s airbag deployed, shattering Hsu’s jaw and knocking out several of her teeth. (The airbag manufacturer was also a defendant in the case, and was also found not liable by the jury).Hsu filed in Los Angeles County Superior Courts on 5/14/2020. Hus sued Telsa for negligence, fraud and breach of contract.Hsu said in her lawsuit that the Tesla Model S she was driving had Autopilot engaged when it turned into and hit a median on a city street. Airbags deployed fracturing her jaw and causing nerve damage.Tesla argued that Hsu didn’t follow instructions in the manual for her 2016 Model S that the driver must be in control of the car at all times and not to use the “auto steer” function on city streets. When her car crashed, it went through an intersection and her lane shifted to the right. Hsu didn’t have her hands on the steering wheel and she failed to correct the course of the car, Tesla said.Following a three-week trial, the jury ruled Tesla wasn't to blame in the $3 million lawsuit. According to the jury, the airbags were not defective and they performed safely as intended, and Autopilot did not malfunction as alleged by the plaintiff. In addition, the jury agreed that Tesla was clear that Autopilot is to assist a driver and does not make the car self-driving.In the end, Hsu received nothing for damages as the jury said distracted driving was the cause of the crash and injuries.",Jury Verdict,2020.0,Inactive
60,60,K.W. v. Armstrong,"Class action reached a settlment after the ACLU of Idaho sought injunctive relief against the Department of Healht and Welfare cutting disabilities services because of a trade secret algorithm, resulting in development of new ADS (algorithmic decision system) to calculate disabilities benefits, litigation ensues to define the scope of the settlement",,Federal: US Dist. Ct. D. Idaho,"Agency Budget, Constitutional Law, Disabilities Benefits, Health","42 C.F.R. § 431.210(b) Medicaid Adequate Notice, Preliminary Injunction","Assigned Budget Amount, Lack of Remedy, Transparency in Change of Algorithm, Transparency/Trade Secrecy",2012-01-18,3/24/2021,https://blogs.gwu.edu/law-eti/?page_id=10&pid=5,Active,"Idaho Department of Health and Welfare program, the DD Waiver Program, had a change in formula to calculate the dollar value amount each adult patient with physical or intellectual disabilities would receive in Medicaid services led to severe drop for in-home care and services. The IDHW began building the budget tool by collecting 2009 and 2010 data for 3,500 patient records, but 66% of the sample size was discarded for various errors including missing information. The Court concluded that this formula resulted in 10-15% of patients receiving inadequate budgets, and 62% of the budgets were reconsidered after Independent Assessment Providers who are contracted by the state, so regular testing must be conducted on the formula.The Individual Assessment Provider contracted by IDHW would determine the level for factors such as type of disability and need for nursing and living services, level of hearing, vision and mobility, and then enter into the algorithm. The IAP then carries over this data to categories in the Individualized Budget Calculation, and from there the budget tool automatically calculates what Medicaid would need to pay for these needs. The budget has a standard dollar figure for each item called the ""constant"" which increases or decreases based on the IAP's evaluation, to total the Assigned Budget Amount. The Care Manager then approves the budget if it is deemed to meet the patient's needs. While disputed, the court concluded that the Service Plan Notice contains an attachment that includes copies of the IBC and the Inventory of Individual Needs for that participant, what services the Care Manager approved and denied, and the right to appeal this decision. However, the patient has 28 days to appeal to a hearing officer who can affirm or remand the decision back to the care manager, but the hearing officer themselves cannot modify the budget.Idaho's automated decision-making system algorithm was initially not disclosed as a trade secret, the ACLU succeeded in disclosure of the formula. Once the court determined the formula was ""unconstitutionally arbitrary"" it forced the Medicaid program to reconfigure its automated decision-making system so that the patients received the proper dollar value services, as well as restore the dollar value services the patients previously received before the drop in the ADS. Another important requirement is that the State Medicaid program must evaluate the new ADS formula regularly to ensure no severe drops occur like this again. The settlement negotiations are still in litigation, with the state requesting an extended timeline and scope to make these changes. It is also important to note that the court left the onus on the Medicaid program to fix the formula, but it would need support and assistance from outside firms and from the impacted patients.The settlement addressed the class three concerns: 1. the need for an accurate budget tool, 2. revising the budget notice to inform participants more clearly about changes to their budgets, and 3. aid with appeals. The settlement acknowledged the costs of developing a new budget tool by setting a deadline of two years and provided cushion for plaintiffs in that they retained their 2011 level of benefits in the meantime. After the January 2020 deadline passed, IDHW requested until January 2023 to implement structural changes and creating the new budget tool, but the court set a short-term deadline for the creation of a new budget tool because the restructuring delay is not an identical delay for the creation of a new budget tool that was promised in the 2017 settlement.Importantly, the settlement provided that the public would have the right to inspect and copy the data ""about the IDHW’s budget setting methodologies, models, and tools"" and particularly DD Waiver program participants would have the right to inspect past, present, and future information, all with redaction only when necessary to protect PII.The settlement agreed that a permanent injunction was not necessary.","Summary of Facts and Activity to DatePlaintiffs filed complaint on January 18, 2012. They brought class claims and individual claims: the class claims challenge the budget tool, the lack of notice, and the exclusion from hearings on this new tool, while the sixteen named plaintiffs bring individual claims that the change to the algorithm lead to a significant risk of them being institutionalized.injunction restored the Plaintiffs’ budgets to the levels they were at prior to July 1, 2011, the date IDHW sent the unconstitutional budget notices. The injunction also prohibited IDHW from reducing Plaintiffs budgets until it (1) provided Plaintiffs with notices, approved by this Court, and (2) made available for copying specified documents it used to calculate Plaintiffs’ budgets.The Ninth Circuit affirmed the injunction on June 5, 2015, agreeing that court approval of a proper notice that explains the budget reductions are necessary.On March 28, 2016, the District Court awarded plaintiffs’ attorneys fees for establishing the record. The court then considered cross-motions for summary judgement on both class and individual claims, motions to strike, as well as a joint motion for preliminary approval of a settlement.disclosure of formula, finding formula unconstitutional and require new formula, -- so this was reported in later orders but i can't find the initial order so i don't have the exact datesThe parties reached a preliminary settlement on the class action claims in October 2016, requiring IDHW to 1. develop a new budget tool within two years, and 2. retain plaintiffs’ benefits at their 2011 level until the new budget tool was approved. The settlement provided that if the budget tool were not implemented in three years by January 2020, the plaintiffs could ask the court to set a ""reasonable deadline"" for IDHW. The court approved the proposed notice of this settlement by sending a copy to each class member, each class member's guardian, support programs, and advocacy programs. The court granted the joint motion for preliminary approval of the settlement for the class action claims but denied approval of the revised budget because it required the class members can comment on the budget before it could be approved. Additionally, the settlement did not account for the individual claims made by the 16 named plaintiffs, called the Olmstead claims.In September 2017, the court denied IDHW's motion to dismiss the Olmstead individual claims on the grounds that they are moot with the class action settlement, but the Court disagreed and ordered that once the new budget tool is released, trial will be set for the individual claims as the settlement did not grant all the relief that the plaintiffs sued for.After the deadline for a new budget tool and restructuring passed, plaintiffs requested 120 days for IDHW to implement the new budget tool, whereas IDHW requested until January 2023 in order to implement: (1) redefine the supported living service and restructure how supports are paid; (2) developing habilitation and prevocational services; (3) improving the person-centered planning process; and (4) restructuring medical transportation. On June 4, 2020, the court granted in part plaintiff's motion to enforce judgement and defendant's motion to set reasonable deadlines by setting up a two-track deadline system: ""longer deadline for the restructuring of services and the other track being a shorter deadline for creation of the new budget tool."" The court granted the defendant's other two motions for COVID-19 relief and to allow sur-reply brief.Most recently, on November 24, 2020, the district court concurred with Plaintiffs of the need to resolve the ongoing dispute for a proper schedule for settlement but decided further mediation would only prolong complications and instead ordered a hearing to set a briefing schedule.","Strike filed, attorneys hosted Zoom update for members of the class action: http://ourhealthandwelfare.org/news/2021/3/24/latest-updates-about-kw-v-armstrong",2012.0,Active
61,61,"Kadrey v. Meta Platforms, Inc.","Authors Richard Kadrey, Sarah Silverman, and Christopher Golden sue Meta Platforms on behalf of themselves and all persons domiciled in the United States owning copyright in any work used as training data for the LLaMA language models, alleging copyright infringement, removal of copyright management information, unfair competition, unjust enrichment, and negligence.",LLaMA,Federal: US Dist. Ct. N.D. Ca.,Generative AI,"Copyright Infringement, Unjust Enrichment, Unfair Competition, 17 U.S.C. 1202 Removal of Copyright Management Information",Copyright Infringement,2023-07-07,1/16/2024,https://blogs.gwu.edu/law-eti/?page_id=10&pid=90,Active,"The court's November 20, 2023 dismissal of all but one of the plaintiffs' claims undermines some of the theories on which copyright owners are challenging the use of their works as training data for generative AI models.  The court dismissed the claims of negligence, unjust enrichment, and unfair competition as preempted by copyright law on the facts alleged, and although it left open the possibility that the plaintiffs could amend their complaint to assert other facts about unjust enrichment and unfair competition, it is unlikely that the plaintiffs will be able to do so. The court also dismissed the plaintiffs' DMCA copyright management information claim, concluding that there was no allegation that the defendants distributed copies of plaintiffs' works, with or without their copyright management information.  Finally, the court dismissed two theories involving derivative works.  It held that the defendant's generative AI model was not itself derivative of the plaintiff's works, and also that the works that the model generated could not be called derivative of the plaintiffs' works without their being substantial similarity between the two.","Summary of Facts and Activity to DatePlaintiffs allege that Meta Platforms trained its large language model LLaMA with data that included ""the Books3 section of The Pile,"" which is compiled by an organization called EleutherAI.  Books3 is allegedly derived from a collection of 196,640 books on a website called ""Bibliotik."" That collection includes many books that are still under copyright, including books written by the individual plaintiffs.  Plaintiffs' claims arise out of Meta's use of those books to train LLaMA without the authorization of the plaintiffs or of anyone in the proposed class of US-domiciled authors and copyright owners whose books were so used.  Plaintiffs filed their complaint on July 7, 2023.  On November 20, 2023, Judge Vince Chhabria granted Meta's motion to dismiss all claims other than the claim that the unauthorized copying of the plaintiffs’ books for purposes of training LLaMA constitutes copyrightinfringement.","Administrative Motion to determine if  the Kadrey proceeding should relate to the Huckabee, et al. v. Meta Platforms, Inc., et al. proceedings.",2023.0,Active
62,62,Kisting-Leung v. Cigna Corp.,"Plaintiffs, consumers in California, filed a class action complaint alleging that the denial of certain medical claims by a national health insurance company using an algorithm constituted breach of the implied covenant of good faith and fair dealing, unjust enrichment, intentionally interfered with contractual relations, and violated California’s Unfair Competition Law. Wrongful claims denials can result in patients having to pay substantial out-of-pocket costs or even forgoing important procedures.",,US District Court for the Eastern District of California,"Civil Rights, Health","Breach of Contract, Contracts, Unjust Enrichment, Unfair Competition","Accountability, Individualized Assessment, Lack of Human Review, Lack of Remedy, Misuse of AI",2023-07-24,12/18/2023,https://blogs.gwu.edu/law-eti/?page_id=10&pid=113,Active,"The litigation highlights the growing use of algorithms and artificial intelligence to handle tasks that were once routinely handled by human workers. At issue in health care is whether a computer program can provide the kind of ""thorough, fair, and objective"" decision that a human medical professional would bring in evaluating a patient's claim.","Summary of Facts and Activity to DateThe suit, which was filed in the US District Court for the Eastern District of California on July, 24th, 2023, and is seeking class action status, was brought forth by a pair of plaintiffs who were denied coverage by Cigna. One plaintiff, Suzanne Kisting-Leung, was referred for an ultrasound because of a suspected risk of ovarian cancer. Another, Ayesha Smiley, had been tested for a vitamin D deficiency at the order of her doctor.The health insurer’s digital claims system, called PXDX, is an “improper scheme designed to systematically, wrongfully, and automatically deny its insureds medical payments owed to them under Cigna’s insurance policies,” the complaint alleges.After the lawsuit was filed Monday, Cigna defended the software system. “PXDX is a simple tool to accelerate physician payments that has been grossly mischaracterized in the press,” spokesperson Justine Sessions said in a statement. “The facts speak for themselves, and we will continue to set the record straight.”",Plaintiff filed second amended complaint,2023.0,Active
63,63,"Kyland Young v. NeoCortext, Inc.","The case, Kyland Young v. NeoCortext, Inc., involved a photo-editing app, called Reface, that uses generative AI technology to allow users to manipulate photos and videos, including to swap faces with celebrities within photos and videos. A celebrity sued, and, in rejecting the app developer’s motion to dismiss, the U.S. District Court for the Central District of California held that the developer’s use of generative AI to superimpose user faces onto celebrity images could violate California’s right of publicity law.",,"District Court, C.D. California",Generative AI,Right of Publicity,Personally identifiable Information,2023-04-03,9/19/2023,https://blogs.gwu.edu/law-eti/?page_id=10&pid=122,Inactive,"Although the Young decision has attracted scant attention, it addresses issues that will be relevant to more closely watched generative AI lawsuits involving right of publicity claims. In particular, the court’s analysis of NeoCortext’s copyright preemption, First Amendment, and the “knowledge” requirement of California’s Right of Publicity statute is likely to be studied and referenced by litigants and courts as the growing number of generative AI disputes work their way through the court system. And, for companies developing or using generative AI tools that implicate the name, image, likeness, or persona of third parties, there are important risk mitigation lessons to be learned from the Young decision.","Summary of Facts and Activity to DateThe face-swapping Reface app was developed by NeoCortext, Inc. (NeoCortext) and allows subscribers to upload pictures of their own face and then recast, with their own image, photos and videos of their favorite celebrities.In April 2023, Kyland Young, a cast member of several reality TV shows, such as Big Brother, filed a putative class action against NeoCortext alleging that it violated California’s Right of Publicity statute by knowingly using “another’s name, voice, signature, photograph, or likeness, in any manner … for purposes of advertising or selling, or soliciting purchases of … services, without such person’s prior consent.”In response, NeoCortext moved to dismiss the complaint for failure to state a claim upon which relief can be granted, and sought a special motion to strike under California’s anti-SLAPP statute.In September 5, 2023, U.S. District Judge Wesley L. Hsu of Central District of California denied NeoCortext’s motion to dismiss and motion to strike, writing that the right of publicity claims were not preempted by the federal Copyright Act. Under California law, significant transformative use would warrant an affirmative defense to a right of publicity claim under the First Amendment, but Judge Hsu found that NeoCortext had failed to prove that the new images combining users’ faces with Young’s photographs were sufficiently altered to be protected by the First Amendment as a matter of law. “While it may ultimately be deemed transformative as a matter of fact, that does not entitle NeoCortext to the defense as a matter of law.”",ORDER GRANTING STIPULATION TO STAY CASE PENDING NINTH CIRCUIT APPEAL 53 by Judge Wesley L. Hsu.,2023.0,Inactive
64,64,L. v. Alphabet,"A number of anonymous plaintiffs bring a class action suit against Alphabet, Inc. and related companies, alleging that their development of Bard, the AI chatbot, involves the conversion/theft of data, invasion of privacy, unfair competition, unjust enrichment, copyright infringement, and removal of copyright management information under the DMCA.",Bard,Federal: US Dist. Ct. N.D. Ca.,Generative AI,"Copyright Infringement, Right to Privacy, Unjust Enrichment, Unfair Competition, 17 U.S.C. 1202 Removal of Copyright Management Information",Copyright Infringement,2023-07-11,1/17/2024,https://blogs.gwu.edu/law-eti/?page_id=10&pid=88,Active,,"Summary of Facts and Activity to DateThe plaintiffs allege that Google has been unlawfully collecting personal data from private individuals across the United States, violating privacy laws, copyright, the Copyright Act's prohibition on removal of copyright management information, unfair competition laws, and is now using that data to develop AI tools such as the Bard chatbot.",Order granting stipulation to set briefing schedule for defendant's anticipated motion to dismiss first amended complaint.,2023.0,Active
65,65,Li v. Liu,"Plaintiff sues for copyright infringement of an image created through prompting a generative AI tool; the court holds that the plaintiff is the author of that image, and awards damages and orders the defendant to post a public apology.",Stable Diffusion,China: Beijing Internet Court,Generative AI,Copyright Infringement,AI as Author,2023-05-25,11/27/2023,https://blogs.gwu.edu/law-eti/?page_id=10&pid=106,Inactive,"The court holds that the plaintiff is the author of and owns copyright in a work that they created by verbally prompting and adjusting the parameters of a generative AI tool. This is the first case in China and perhaps the first case anywhere to find authorship in generative text-to-image AI tool prompting, and the issued opinion contains a detailed description of the creative process, and thorough analysis of the legal issues involved.","Summary of Facts and Activity to DatePlaintiff Li created an image of a woman by entering detailed, iterative verbal prompts to the generative AI tool Stable Diffusion, and by otherwise adjusting the parameters of that tool.  Defendant Liu posted that image on a public platform to illustrate a poem that they had written. Li sued Liu, claiming infringement of their right of attribution and their right of communication through information network. Liu argued, among other things, that Li should not be able to claim authorship of an image created by prompting a generative AI tool. In an opinion released on November 27, 2023, the court held that Li was the author of the image they created through prompting Stable Diffusion, and ordered Liu to post a public apology to Li and to pay 500 Yuan in damages (roughly 70 US dollars).",Beijing Internet Court issues opinion,2023.0,Inactive
66,66,"LivePerson, Inc. v. 24/7 Customer, Inc.",A federal jury awarded LivePerson Inc. an award of $30 million against 24/7ai misuse of trade secrets claims from online chat platform and customer engagement technology,,Federal: District Court S.D. New York; Transferred to District Court N.D. California,"Copyright, Intellectual Property, Patent",Copyright Infringement,"Predictive Policing, Transparency/Trade Secrecy",2014-03-06,11/3/2023,https://blogs.gwu.edu/law-eti/?page_id=10&pid=65,Active,"The federal jury found that 24/7 misappropriated all 15 of LivePerson’s alleged trade secrets, and awarded more than $6.7 million in compensatory damages and over $23.5 million in punitive damages. The two types of trade secrets at issue were: (1) “rules” trade secrets, the rules and variables specific to each customer and  (2) “data” trade secrets, the XML data gathered during users’ visits to LivePerson’s customers’ websites. 24/7 had tried to exclude LivePerson's expert William Choi, and the court denied this motion using the Daubert standard that Choi's calculations for trade secret damages. The court explained, ""The amount of predictive information contained within each trade secret, according to Dr. Choi, is reflected by the number of individual rules utilized by that trade secret, because the time and cost of generating the trade secret increases with the number of rules.""","Summary of Facts and Activity to DateThe complaint arises out of a 2006 agreement between LivePerson and 24/7. LivePerson is an online chat service that sells its real time chat engagement to its customers who will use the services for sales. LivePerson contracts with each customer and creates an agreement that establishes rules and variables, and that LivePerson collects the data from the exchanges. LivePerson offered up its digital chat platform for 24/7, who would staff the platform with chat agents. This Master Services Agreement (""MSA"") entered into two customer agreements with Adobe and Hoover. After these two customer agreements expired, LivePerson and 24/7 continued its working relationship with Capitol One, Sears, and Optus. Each customer signed a separate agreement to use LivePerson's digital chat platform and to use 24/7's chat agents. However, in 2013, 24/7 introduced its own chat platform. In March of 2014, LivePerson filed its complaint in New York and amended in May to add a Jury Demand that 24/7 gained access to LivePerson's trade secrets during the time of their 2006-2010 agreements. This agreement allowed 24/7 to market LivePerson’s technology to prospective clients.   Both parties agreed that the agreement allowed 24/7 access to LivePerson's technology, 24/7 rejects the argument that they used the trade secrets to develop their own platform that would compete with LivePerson, and take LivePerson's customers of  Capital One, Optus and Sears.The first ruling came on January 13, 2015, where the judge denied in part and granted in part defendants motion to dismiss for failure to state a claim or motion for more definite statement. LivePerson was granted 20 days to replead the inadequately pled sections, and was asked to give a more definite statement about its Lanham Act claims. LivePerson filed a second amended complaint on February 4, 2015. The court granted a motion for extended time to file a protective order to protect electronically stored information including software code during discovery. On July 31, 2015, the court ruled published an opinion that (1) denied defendant's motion to compel and (2) modified the the PPO to include the proposed Expert Disclosure, Source Code and Patent Prosecution Provisions and (3) provided that the parties shall meet and confer to generate a list of competitors to be used in conjunction with the Expert Disclosure Provision. The subsequent motion to compel discovery was litigated for the first half of 2016, with numerous memoranda in support of motion to compel and in opposition, discovery requests, hearings on updates. On September 6, 2016, the court ruled on the motion to compel in a sealed opinion: Defendant's motion to compel identification of alleged trade secrets and for a protective order is denied, Plaintiff's cross-motion to compel production of source code is granted, and Plaintiff's motion to compel Defendant to collect and produce documents and identify employment status and locations is granted in part and denied in part. The parties agreed to transfer venue on March 9, 2017 to Northern District of California to consolidate with litigation filed there. After failed ADR attempts, 24/7 responded with a first amended answer to the second amended complaint. Deposition hours were approved by the court on December 13, 2017. On July 13, 2018, 24/7 filed a motion for summary judgement, which the court granted in part on the Lanham Act claim and denied in part on the trade secrets claims on November 7. The case underwent pretrial motions and deadlines for the first half of 2019. On July 19, 2019, the court denied 24/7's motion to exclude LivePerson's expert witness. The jury intstructions were approved in September 10, 2019. The trial was delayed until 2021 due to the pandemic. The jury verdict was June 17, 2021. On October 14, both LivePerson and 24/7 filed proposed orders for Post-Trial Relief, with LivePerson requesting a permanent injunction.",Mandate of USCA notice of cross appeal to 9th Circuit,2014.0,Active
67,67,Loomis v. Wisconsin,"Wisconsin Supreme Court rejects post-conviction Due Process challenge to the state's criminal sentencing use of COMPAS risk assessment algorithm, which was proprietary and which took gender into account",COMPAS,State: Wisconsin,Criminal Justice,"Due Process, Petition for Post-Conviction Relief","Individualized Assessment, Transparency/Trade Secrecy, User of Gender",2013-02-13,6/26/2017,https://blogs.gwu.edu/law-eti/?page_id=10&pid=1,Inactive: Judgement for D,"COMPAS is a proprietary predictive algorithm used to assess the risk of recidivism. The Wisconsin Supreme Court held that the use of the proprietary algorithm does not violate a defendant's due process rights.First, it held that the use of COMPAS does not violate the right to be sentenced based upon accurate information, even though the proprietary nature of COMPAS prevents a defendant from assessing its accuracy.  The court held that it was sufficient that judges presented with COMPAS risk scores be cautioned that (1) there is no disclosure of how factors are weighed or risk scores are determined; (2) that the assessment compares defendants to a national sample and no cross-validation study of Wisconsin defendants has been completed, (3) some studies have raised questions about whether COMPAS disproportionately gives minorities higher risk scores; and (4) risk assessment tools must be updated due to changing populations.Second, the court held that the use of COMPAS does not deny a defendant's right to an individualized sentence, because although the risk score is determined on a group basis, the court ultimately imposes the sentence on the basis of all of its knowledge of the defendant.  Third, the court held that the algorithm does not improperly use gendered assessments in sentencing, even though it takes the defendant's gender into account.  Because men have a higher risk of recidivism, use of gender promotes accuracy rather than discriminating.","Summary of Facts and Activity to DateEric Loomis was charged with five crimes; he entered into a plea agreement under which he pled guilty to two crimes. Before sentencing, the court ordered a presentence report that included an algorithmic assessment using a tool called COMPAS, developed by Northpointe, Inc.  The COMPAS risk assessment is based on data gathered from a defendant's criminal file and from an interview with defendant. The challenged assessment predicts the risk of pretrial recidivism, general recidivism, and violent recidivism.  Loomis scored high on all three risk measures. In rejecting a sentence of probation, and sentencing Loomis to a prison term, the Circuit Court referenced the COMPAS risk assessment.   Loomis filed a motion for post-conviction relief requesting a new sentencing hearing, arguing that the use of the COMPAS risk assessment violated his right to due process.  All three levels of Wisconsin courts denied his motion, and the U.S. Supreme Court denied certiorari.",Denial of Certiorari by U.S. Supreme Court,2013.0,Decided
68,68,Louis et al. v. SafeRent et al.,"The court denied defendants’ motion to dismiss Fair Housing Act claims, holding that SafeRent Solutions, LLC is subject to the Fair Housing Act’s ban on racial discrimination in housing. Even though SafeRent is not a landlord, the court determined that the plaintiffs adequately alleged that property owners relied solely on SafeRent’s tenant screening score, and adequately alleged those scores had a disparate impact on Black and Hispanic renters.",,the U.S. District Court for the District of Massachusetts,"Civil Rights, Housing",Fair Housing Act,"Lack of Human Review, Socioeconomics Bias, Miscalculation, Reliability",2022-05-25,7/26/2023,https://blogs.gwu.edu/law-eti/?page_id=10&pid=108,Active,"On July 26, 2023, the Honorable Angel Kelley of the United States District Court of Massachusetts denied defendants’ motion to dismiss Fair Housing Act claims, holding that SafeRent Solutions, LLC, a national tenant screening provider formerly known as CoreLogic Rental Property Solutions, is subject to the Fair Housing Act’s ban on racial discrimination in housing. Even though SafeRent is not a landlord, the court determined that the plaintiffs adequately alleged that property owners relied solely on SafeRent’s tenant screening score and adequately alleged those scores had a disparate impact on Black and Hispanic renters. FHA claims against landlord Metropolitan were also permitted to proceed.On January 9, 2023, the U.S. Department of Justice and the U.S. Department of Housing and Urban Development filed a statement of interest in this case.","Summary of Facts and Activity to DateOn January 9, 2023, the United States filed a Statement of Interest in Louis et al. v. SafeRent et al. (D. Mass.), a case brought under the Fair Housing Act (FHA).  The Louis lawsuit was filed on behalf of two plaintiffs, Mary Louis and Monica Douglas, Black rental applicants who use housing vouchers to pay part of their rent. Plaintiffs applied for rental housing but allege they were denied due to their “SafeRent Score,” a score derived from Defendant SafeRent’s algorithm-based screening software. The plaintiffs allege that SafeRent scores result in an unlawful disparate impact against Black and Hispanic rental applicants because the underlying algorithm relies on certain factors that disproportionately disadvantage Black and Hispanic applicants, such as credit history and non-tenancy-related debts, while failing to consider one highly relevant factor, that the use of housing vouchers funded by HUD makes such tenants more likely to pay their rents. In its Statement of Interest, the United States sets out the appropriate standard for pleading disparate impact claims under the FHA and clarifies that the FHA’s text and caselaw support the FHA’s application to companies providing residential screening services. On July 26, 2023, the Honorable Angel Kelley of the United States District Court of Massachusetts denied defendants’ motions to dismiss plaintiffs’ FHA claims. In its order, the Court held that defendant SafeRent was subject to the FHA and that plaintiffs had alleged a plausible claim for disparate impact discrimination under the FHA against both defendants.",Order on Motions to Dismiss,2022.0,Active
69,69,Louisiana v. Hickerson,"Court denied motion to overturn the conviction of racketeering and a new trial in light of the Prosecutor not disclosing the use of the Palantir Gotham system that mapped gang members' connections, as Gotham was not used in Hickerson's case, Hickerson files full appeal",Gotham,State: Louisiana,Criminal Justice,Conviction Challenge,"Predictive Policing, Unaware of Use of Algorithm, Use of Race",2013-06-01,12/30/2020,https://blogs.gwu.edu/law-eti/?page_id=10&pid=18,Inactive: denial of motion for new trial,,"Summary of Facts and Activity to DateAfter a multiyear investigation, the state of Louisiana charged Mr. Hickerson with, (1) conspiracy to commit racketeering, (2) conspiracy to distribute heroin in furtherance of gang activity, and (3) conspiracy to distribute cocaine in furtherance of gang activity.","Affirm in part, vacate in part Hickerson's conviction",2013.0,Inactive
70,70,Lynch v. Florida,"Defendant appeals conviction claiming he was misidentified by the facial recognition software comparing a photo an undercover cop snapped during a drug deal, noting even the analyist did not know how the facial recognition algorithm worked",FACES,State: Florida,Facial Recognition,Due Process,"Human Programming Flaws, Transparency/Trade Secrecy, Unaware of Use of Algorithm, Use of Race, Unreliability/Miscalculationns",,7/19/2019,https://blogs.gwu.edu/law-eti/?page_id=10&pid=19,Inactive: Appeals denied,"In this case undercover officers bought cocaine from an individual called ""midnight"". The officers later identified Lynch as the seller and brought charges. At trial the defense was misidentification because facial recognition software was used to identify Lynch as ""midnight"" off of a photo the officers took during the drug exchange.The program used was the Face Analysis Comparison Examination System (FACES), a program the Pinellas County Sheriff’s office operates and makes available to law enforcement agencies throughout Florida. The algorithm operates in two steps. First it processes the image it is seeking to match (the “probe image”). This often involves “pose correction” and “face normalization” which rotates the image to match the pose of the photos to be matched and approximates what any missing parts of the face look like. It also generates a “faceprint” of features like eye position or skin texture. Second, the algorithm compares the faceprint of the probe image to the faceprint of images in the database and returns several potential matches. The accuracy of FACE is directly affect by the quality of the photos being searched, and can be extremely poor at identifying a person in a low resolution image. It also requires an analyst to utilize the program and evaluate whether the results are worth sending to the inquiring officers.Although the facial recognition software led the officers to Lynch, the state did not rely on the facial recognition to identify Lynch. The officers identified Lynch as the man who sold them drugs and the analyst did not even testify in the trial. In an amicus brief the ACLU argued, ""If a witness who identified Mr. Lynch stated that other individuals in a line-up looked like the perpetrator, the state would have had to disclose that information, an well as any information indicated that the witness was uncertain or impaired when making the identification. Here, those same principles should have required the state to disclose the other photos and information on how the algorithm functions."" But the court here seems to be unconcerned with the accuracy of FACE because although it led the officers to Lynch, the officers still identified Lynch as Midnight.","Summary of Facts and Activity to DateTwo officers routinely drove around high-crime areas and posed as drug buyers looking for drugs. In this particular instant a dealer called Midnight flagged the officers down and asked if they “were good”, and then proceeded to sell them cocaine. Normally the officers would record these transactions but because Midnight approached them so suddenly they were not able to activate the recording system. One officer did snap a photo with his phone of Midnight leaning on the car. The phone used was not a modern smartphone rather an old tracfone from Walmart. The quality of phone combined with the photo being snapped while the officer pretended to be making a call, resulted in a photo that was from an oblique angle, off-axis, and blurred in places.The officers had no idea who Midnight was, so they emailed the photos to an analyst to identify Midnight. To begin with she looked up the nickname “midnight” in the law-enforcement database and found several people with that alias, but none who looked like the man in the photo. She then proceeded to use a facial-recognition program (FACES) that compared the photo against photos in the law-enforcement database.FACES could have been utilized as an open search, but she limited her search to black males and only considered Duval County booking photos. The program then returns photos almost like a photo lineup. Then the analyst makes a judgment call on whether to send that information to the detective. The program also gives you some amount of stars indicating the likelihood of a match, but the analyst was unsure how many stars were possible or how the program worked. She did remember that Lynch’s photo only had one star next to it, but it was the highest ranked match. According to an amicus brief filed by the ACLU his photo was actually just the first-listed photo in the list of possible matches but the first-listed photo is not necessarily the best match. The analyst told the officers that Lynch was a possible match to the man in the cell photo so the officers concluded that Lynch and Midnight were the same person. The Analyst did not testify at trial.At trial Lynch, as a pro se motion, sought to compel the state to produce the photographs of the other “Midnights” contained in the database, as well as the other photographs the facial-recognition program returned. The court denied the request concluding the photos were not relevant. Then court also revoked Lynch’s self-representation at this point and re appointed a public defender.Lynch argued on appeal that he should have access to the other photos because those photos could cast doubt on the State's case, and that by not providing the photos the state violated Brady v. Maryland. The court rejected this argument because lynch could not show that the other photos in the database resembled him, and that the attorney chose to not call the analyst as a witness because the analyst would only corroborate the officers testimony, and the jury convicted only after comparing the photo the officer took to Lynch himself.",Supreme Court of Florida denied review,,Inactive
71,71,"Main Sequence, Ltd. v. Dudesy, LLC","The estate of George Carlin sued a pair of podcasters for using artificial intelligence to create a script and voice imitating the late comedian for a new comedy routine, citing the right of publicity and copyright infringement.",,US District Court for the Central District of California,"Copyright, Generative AI, Infringement, Intellectual Property","Copyright Infringement, Permanent Injunction, Preliminary Injunction, Right to Publicity, Right of Publicity","Infringement, Copyright Infringement",2024-01-25,1/25/2024,https://blogs.gwu.edu/law-eti/?page_id=10&pid=118,Active,"The case, brought by the estate and Jerold Hamza—Carlin’s longtime manager and executor of his estate—will explore the boundary of what AI can permissibly do when it comes to both using copyrighted material and imitating famous performers.","Summary of Facts and Activity to DateGeorge Carlin’s estate has filed a copyright infringement lawsuit against Dudesy, the media company that claimed to have used generative artificial intelligence to produce a fake hour-long comedy special that imitates the deceased star’s voice and comedic style. The complaint filed in Los Angeles federal court on January 25th, 2024, alleges that Carlin’s copyrighted materials and likeness were used without permission or appropriate licenses, calling the special a “piece of computer-generated click-bait which detracts from the value of Carlin’s comedic works and harms his reputation.”The complaint alleges that the use of Carlin’s work to create the new AI material infringes copyright. It also said that the routine purporting to reflect what Carlin would have thought about current issues—along with the use of Carlin’s name and AI-generated images of Carlin—violated his posthumous right of publicity under California law, which allows commercial control of an individual’s name and likeness for commercial purposes.According to the compliant, Dudesy previously removed an AI-generated video of Tom Brady performing a stand-up comedy routine after the retired NFL star threatened to sue.Dudesy and Sasso didn’t immediately respond to requests for comment made to their Facebook pages.",Complaint filed,2024.0,Active
72,72,Malenchik v. State,,LSI-R,State: Indiana,"Criminal Justice, Sentencing",,,,,https://blogs.gwu.edu/law-eti/?page_id=10&pid=35,,,Summary of Facts and Activity to Date,,,Not specified
73,73,"Marron v. Clearview AI, Inc.","Violates BIPA; seeking injunctive relief, statutory damages, and litigation costs",Clearview,Federal: US Dist. Ct. N.D. Illinois; Transferred to US Dist Ct. S.D. New York.; Transferred to US Dist. Ct. N.D. Illinois,Facial Recognition,BIPA,Privacy,2020-05-20,1/8/2021,https://blogs.gwu.edu/law-eti/?page_id=10&pid=40,Active,The last of the Clearview class action suits to be filed.,"Summary of Facts and Activity to DatePlaintiffs Chris Marron and Maryann Daker brought this class action against Clearview AI, Inc., Hoan Ton-That, an Individual, Richard Schwartz, an Individual (collectively with Hoan Ton-That, “Individual Defendants”) and CDW Government LLC, an Illinois Company (“CDW”) for violating BIPA.The basis of the complaint is the February 2020 leak that showed Clearview's 6,000 clientele, which included large companies and government agencies.The claims are that since plaintiffs are residents of Illinois, they have posted their pictures or had their pictures posted online, and Clearview has scraped 3 billion images and thus violated plaintiffs' privacy. For CDW in particular, plaintiffs allege that the company provides services to local government agencies, and was Clearview's agent to ""advertise, license, and sell Clearview’s proprietary facial recognition platform to .... upon information and belief, to the Chicago Police Department""The complaint describes the process of defendants finding a match in Clearview's system, and the ways in which it can use the plaintiff's private data.Plaintiffs also brings actions against Clearview founder Richard Schwartz and Clearview founder and CEO Hoan Ton-That, citing statements that the algorithm always makes a match with no error, and that Clearview has been subject to numerous cyber attacks.The case was consolidated under MDL in January 8, 2021.",Consolidated into MDL,2020.0,Active
74,74,Matsko v. Tesla,"Plaintiff seeks to bring class action against Tesla for misrepresenting what its Autopilot software can do, alleging that those misrepresentations violated the Magnusson-Moss Warranty Act, breached express and implied warranties, and give rise to other causes of action.",Autopilot,Federal: US Dist. Ct. N.D. Ca.,Autonomous Vehicles,Breach of Implied Warranty,"Misrepresentation, Autonomous Vehicle",2022-09-04,1/18/2024,https://blogs.gwu.edu/law-eti/?page_id=10&pid=97,Active,,"Summary of Facts and Activity to DatePlaintiff seeks to bring class action against Tesla for misrepresenting what its Autopilot software can do, alleging that those misrepresentations violated the Magnusson-Moss Warranty Act, breached express and implied warranties, and give rise to other causes of action.  Plaintiff filed complaint on September 14, 2022, and Amended Complaint on September 23, 2022.  Defendants filed motion to dismiss and motion to compel arbitration.  Plaintiffs filed motion for preliminary injunction and motion for class certification.  As of July 20, 2023, court had not yet ruled on motions.",Administrative Motionper Local Civil Rule 7-11,2022.0,Active
75,75,Matter of Nonhuman Rights Project Inc. v Stanley,"Denying a writ of habeas corpus for two chimpanzees and dismissing a petition by the NonHumanRightsProject, even with over 100 affidavits recounting cognitive ability and autonomy.",,State; New York,Constitutional Law,Habeas Corpus,AI Adjacent,2013-12-01,7/29/2015,https://blogs.gwu.edu/law-eti/?page_id=10&pid=70,Inactive: Dismissed,"To support their petition that chimpanzees are autonomous and self-determining beings entitled to fundamental rights, NonHuman Rights offered offers affidavits from ""psychologists, zoologists, anthropologists, and primatologists, who have conducted in-depth research into the behavior, personality, cognition, intelligence, communication, and language skills of chimpanzees and other nonhuman primates. Each expert attests, collectively and generally, to the complex cognitive abilities of chimpanzees."" This relates to algorithms in the necessity of experts to testify about the complex abilities and autonomy of algorithms and machine learning. While the petitioners focus on DNA and similarities to humans, algorithms share other similarities to human decision making. The judge acknowledges that corporations and partnerships have been deemed persons for certain purposes, but these corporations are still composed of humans.","Summary of Facts and Activity to DateBeginning in 2013, the NonHumanRights began petitioning for writ of habeas corpus for chimpanzees Hercules and Leo in order to transfer from Stony Brook University and move them to a sanctuary. This petition did not attack the conditions the chimpanzees were kept in, but that they were contained. The petition failed in Suffolk County for  Hercules and Leo because the judge refused to hear either side to decide the issue as there was no issue to show cause and the petitioners had a remedy to remove them to a sanctuary. Petitioner's motion to reargue was granted despite the Attorney General filing a memorandum in opposition. On May 13, 2015 petitioners filed a demand, oral argument was held on May 27, 2015. The court determined that Hercules and Leo do not possess attributes sufficient to establish legal personhood. The court notes that the writ of habeas corpus is typcially brought in criminal rather than civil suits but the judge acknowledges that CPLR 7002 (b) provides that a habeas petition must be made to ""(1) the supreme court in the judicial district in which the person is detained; or . . . (3) any justice of the supreme court."" The court relies on statutory interpretation and dictionary definition of detention in a ""state institution"" and that in turn it is irrelevant that the instiuttion is the State University, and thus does not require a transfer of venue. Respondents claim that Suffolk County declining to hear Article 70 arguments barred petitioners ""from filing another order to show cause seeking the same relief from a different justice"" however the court notes that there must be final judgement before being barred as res judicata. Getting to legal personhood, the judge acknoweldges this term is not defined and that legal personhood does not have to be synonymous with human. The judge acknowledges that corporations and partnerships have been deemed persons for certain purposes, but these corporations are still composed of humans. Personhood has evolved since the constiuttion only considered white, land owning males, and that while animals are beginnign to be treated as more than property, they are ultimately quasi persons owed some rights and not others. However, the court in Lavery held that a failure to establish a common law relief nature the court does not have to grant writ. The judge ultimately concluded even without being bound by Lavery, the writ of habeas corpus is ""best decided, if not by the legislature, then by the Court of Appeals, given its role in setting state policy.""",Judgement,2013.0,Dismissed
76,76,"McPherson v. Clearview AI, Inc.","Class transferred and consolidated into In re Clearview, complaint charged that Clearview violated Violates BIPA and receives unjust enrichment. Sought injunctive relief, declaratory jt., restitution, damages, and litigation costs",Clearview,Federal: US Dist Ct. S.D. New York; Transferred to US Dist. Ct. N.D. Illinois,Facial Recognition,"BIPA, Unjust Enrichment",Privacy,2020-04-15,1/12/2021,https://blogs.gwu.edu/law-eti/?page_id=10&pid=32,Active,"One of the last complaints to be filed against Clearview in SDNY, it brought identical claims using almost identical wording. Unlike the other cases, which also included Clearview co-founders as defendants, McPherson also sued Does 1-10 who are other owners, directors, officers, and/or shareholders of Clearview to carry out the ""unlawful scheme""","Summary of Facts and Activity to DatePlaintiff filed its complaint on April 15 under BIPA but in SDNY. The two subclasses are the subclass one: the BIPA class and subclass two: the unjust enrichment class.Judge McMahon's directive on April 22, she wrote of Calderon, Burke, Broccolino, and McPherson, McMahon suggested the cases are better brought in Illinois because they concern BIPA.On May 29, Judge McMahon denied Mutnick's motion to intervene. However, like the other cases, the case was stayed in September to wait for the MDL decision.",MDL Transfer Out,2020.0,Active
77,77,"McRO, Inc. v. Bandai Namco Games America, Inc.","A patent infringement case of video game design involving software applications to automatically animate lip synchronization and facial expression, the court found no infringement and found invalidity based on the lack of specificity in enablement",,"Federal: U.S. District Court, C.D. California","Intellectual Property, Patent",Patent Application,Functionality,2012-12-04,9/13/2016,https://blogs.gwu.edu/law-eti/?page_id=10&pid=62,Inactive,,Summary of Facts and Activity to Date,Judgement,2012.0,Inactive
78,78,"Mobley v. Workday, Inc.","A class action lawsuit was brought to challenge to Workday's artificial intelligence systems and screening tools, arguing that these tools are biased against applicants who are either over the age of 40, Black, or disabled. The lawsuit argues that Workday violated the Age Discrimination in Employment Act, the Americans with Disabilities Act, and the Civil Rights Act.",ATS,N.D. Cal,"Civil Rights, Employment, Hiring",Civil Rights,"Programmer Bias, Transparency/Trade Secrecy, Use of Race",2023-02-21,1/11/2024,https://blogs.gwu.edu/law-eti/?page_id=10&pid=86,Active,,"Summary of Facts and Activity to DateDerek Mobley, the Plaintiff, filed suit against Workday alleging violation of the Civil Rights Act of 1964, Age Discrimination in Employment Act of 1967, and the ADA Amendments Act of 2008 because Workday provides potential employers an algorithm which that they can use to screen applicants. The plaintiff alleges that the program disproportionately discriminates against, African Americans, people over the age of 40, and the disabled.",,2023.0,Active
79,79,Molander v. Tesla Inc.,"Lindsay Molander and her son, Parker Austin, sued Tesla in 2020 over the crash, alleging that the Autopilot system caused the car to swerve off the road without warning while traveling at about 65 mph. The car smashed into a palm tree and burst into flames, according to court documents. Molander and Austin, who were passengers in the Tesla Model 3, were seriously injured in the June 2019 crash. The driver, Micah Lee, was killed. A California jury ruled that a crash involving a Tesla vehicle that left one person dead and two seriously injured was not caused by a manufacturing defect in the company’s Autopilot system.",Autopilot,SUPERIOR COURT OF THE STATE OF CALIFORNIA FOR THE COUNTY OF RIVERSIDE,Autonomous Vehicles,"Negligence, Product Liability",Autonomous Vehicle,2020-06-26,10/31/2023,https://blogs.gwu.edu/law-eti/?page_id=10&pid=136,active,"Telsa faces federal probes into whether defects in Autopilot have contributed to at least 17 deaths since June 2021, as well as regulatory investigations and lawsuits over claims that it has over-hyped its progress toward hands-free driving. Several suits over fatal crashes have headed to trial in coming months in California and Florida.","Summary of Facts and Activity to DateLindsay Molander and her son, Parker Austin, sued Tesla in 2020 over the crash. According to a third amended complaint in the case against Tesla, Lee's Model 3 veered sharply off the road at 65 MPH, crashing into a tree and bursting into flames. ""Prior to impacting the palm tree, decedent Micah Lee attempted to, but could not, regain control,"" the suit alleged.Tesla argued in the case it wasn't liable for the accident, as Lee had allegedly consumed alcohol before driving, and also claimed it wasn't sure if Autopilot was even engaged let alone defective as described.The jury in state court in Riverside, California, sided with Tesla 9-3.",Jury Deliberating,2020.0,Unknown
80,80,Murphy v. Essilorluxottica,"A 61-year-old grandfather filed suit against Sunglass Hut’s parent company EssilorLuxottica and retailer Macy’s after he was wrongfully arrested and jailed based on facial recognition software that identified him as the man who robbed a Sunglass Hut store. While he was being held, the man was sexually assaulted at the Harris County Jail.",,District Court in Harris County,"Criminal Justice, Detention and Release, Facial Recognition, Generative AI",Negligence,"Facial Recognition, Law Enforcement",2024-01-18,1/18/2024,https://blogs.gwu.edu/law-eti/?page_id=10&pid=127,Active,"Murphy’s case would be the seventh known case of a wrongful arrest due to facial recognition in the US, further highlighting the flaws of a technology already widely adopted by police departments and retailers. However, in all of the publicly known cases of wrongful arrests due to facial recognition up until now, the victims have been Black. Murphy’s would be the first known case of the failure of the technology leading to the wrongful arrest of a white man.","Summary of Facts and Activity to DateA 61-year-old man is suing Macy’s and the parent company of Sunglass Hut over the stores’ alleged use of a facial recognition system that misidentified him as the culprit behind an armed robbery and led to his wrongful arrest. While in jail, he was beaten and raped, according to his suit.Harvey Eugene Murphy Jr was accused and arrested on charges of robbing a Houston-area Sunglass Hut of thousands of dollars of merchandise in January 2022. He was arrested on 20 October 2023. While Harvey was later found innocent, his time in Harris County Jail led to him being sexually assaulted by three men, leaving him with “lifelong injuries.”Harvey sued for malicious prosecution, false improsonment, negligence, and gross negligence.",Plaintiff's Original Petition,2024.0,Active
81,81,"Mutnick v. Clearview AI, Inc.","Class transferred and consolidated into In re Clearview, complaint charged that Clearview violated Violates BIPA, 1A by intefering with use of social media sites, 4A gathering images under color of law, 14A threatening free assembly and exposing users to identity theft and domestic violence etc, Const. contracts clause, unjust enrichment; and sought seeking injunctive relief (deletion of data), damages, and litigation costs",Clearview,Federal: US Dist. Ct. N.D. Illinois; Transferred to US Dist Ct. S.D. New York; Transferred to US Dist. Ct. N.D. Illinois,Facial Recognition,"BIPA, Unjust Enrichment","Facial Recognition, Privacy",2020-01-22,1/8/2021,https://blogs.gwu.edu/law-eti/?page_id=10&pid=29,Active,"Of the nine cases consolidated into In Re Clearview, Mutnick was the first filed and many subsequent cases use the same set of facts/causes of action almost verbatim. Mutnick also spearheaded the consolidation attempts.","Summary of Facts and Activity to DatePlaintiffs filed its complaint on January 22, amending on January 29 to include that plaintiff was bringing claims for all citizens on constitutional grounds and for all Illinois residents as an Illinois class for violating BIPA.As plaintiffs in the other in re Clearview cases will state, the Plaintiff's tie to Clearview is that ""[a]t relevant times, images of Plaintiff’s face appeared on numerous internet-based platforms and websites"" and at no time did Clearview contact the plaintiff for notice or consent.On April 27, Clearview filed a motion to dismiss or alternatively to transfer venue, and on May 6 filed an opposition to a Preliminary Injunction.On May 19 the court denied the stay and motion to dismiss or transfer.On August 12, Mutnick was consolidated with Hall v. Clearview AI, Inc., (1:20-cv-00846) and Marron v. Clearview AI, Inc., (1:20-cv-02989) after unsuccessful attempt on May 29 to intervene and dismiss or transfer six cases in SDNY to Illinois, as eight federal cases had been filed by May, six of which had been brought or transferred to New York.On August 18, Clearview moved to transfer to SDNY.However, on January 8, 2021 the cases were combined into an MDL.Thus on January 15, the court denied plaintiff's motions for preliminary injunction and for reconsideration and defendants' motion to transfer case as moot.",Combined into MDL,2020.0,Active
82,82,National Fair Housing Alliance v. Facebook,"Settlement between Facebook and the National Housing Groups to restructure Facebook's previous advertising settings that allowed advertisers to exclude targeted audiences based on race, gender, or families",,Federal: US Dist Ct. S.D. New York,"Advertising, Credit, Housing",Fair Housing Act,"Advertising DIscrimination, Socioeconomics Bias, Use of Race, User of Gender",2018-03-27,3/29/2019,https://blogs.gwu.edu/law-eti/?page_id=10&pid=22,Inactive: Settled,"Plaintiffs asserted that Facebook's advertising algorithm ""can ensure exclusion and deny access to housing. Facebook’s ability to target groups and promote discrimination so precisely will surely only improve as the company continues to refine its technology.""The Amended Complaint further asserts that ""These algorithms automatically designate each Facebook user as falling into the various categories it has determined fit that user’s demographics, interests, and behaviors."" The complaint and amended complaint do not provide an in-depth discussion into the predictive algorithms or use of machine learning, just the discriminatory effects.The terms of the settlement agreement delineated trainings and verification of implementation of the trainings and programmatic relief for the employment advertisements on Facebook. The training is civil rights training but would apply to Facebook's machine learning team and ranking feature engineers, as well as Facebook's ads teams. To verify the implementation, Facebook will meet with the plaintiffs every six months where they will consider in good faith any recommendations from plaintiffs and share the status of their updates, as well as allow plaintiffs to test ads.There have been no news reports on these biannual meetings, or how long they will continue.","Summary of Facts and Activity to DateThe National Fair Housing Alliance filed its complaint against Facebook on March 17, 2018, which alleged discriminatory advertising practices with its use of ""exclude"" and ""include"" characteristics, boosting to certain characteristics, and Facebook's Ad Manager that facilitates this exclusion. The complaint was brought on by Pro Publica's report of discriminatory practices and filed after NFHA conducted its own investigation.The parties conferenced on May 8, 2018, deciding the defendants must file a motion to transfer or dismiss by June 4 with no pre-motion conference necessary. On June 4, Facebook filed a motion to transfer case or alternatively to dismiss.Plaintiffs filed amended complaint on June 25, which noticeably included 15 mentions to Facebook's algorithm, whereas the initial complaint included a mere 3. The revised language focused on ""algorithmically ranked series of stories and advertisements"" on Facebook User News Feeds.The parties conferenced on June 29, and on July 2, the Judge denied without prejudice the motion to transfer case and denied motion to dismiss as moot. On July 30, Facebook filed a new motion to transfer case or dismiss. The judge granted plaintiffs an extension of time to respond to the motion to transfer on August 31.On November 26, parties were notified of oral arguments to be held on December 13. The parties submitted a joint motion to continue for February 11 due to the holiday season on December 27.Plaintiffs filed the proposed order February 6 that stipulated it was dismissed without costs and prejudice. However, on March 29 the case was reopened and dismissed with prejudice pursuant to the terms of the settlement Exhibit 1. The settlement agreement provided terms for programmatic relief, training, dismissal, monetary payment, and verification of implementation.",Dismissed per the terms of the settlement agreement,2018.0,Settled
83,83,"Nevarez v. Forty Niners Football Co., LLC","In a mobility disability access class action, a trial court ruled that the Federal Rules of Evidence would prohibit the use of AI to identify non-responsive documents without identifying a “cut-off” point during review",,Federal: U.S. District Court N.D. California,Disabilities Benefits,Evidence,Transparency/Trade Secrecy,2016-12-07,7/23/2020,https://blogs.gwu.edu/law-eti/?page_id=10&pid=60,Inactive: Settlement,"The issue of machine learning programs came up in October 2018 regarding discovery in ORDER REGARDING DISCOVERY SUBMISSIONS ECF 244, ECF 245 AND ECF 246. Plaintiffs requested almost 300,000 documents from third parties Live Nation and Ticketmaster. The defendants pushed back that the unreviewed documents that had been identified could have been no-responsive documents protected by privilege. The court says: ""This dilemma is not uncommon in ESI productions. Defendants have, constructively, adopted the use of predictive artificial intelligence programs to assist in the identification of non-responsive documents en masse within the unreviewed documents However, Defendants do not have sufficient data from those programs to argue for a supportable “cut-off” point among the unreviewed documents to avoid producing, and thus reviewing, some portion of the 297,000 documents. Given that the Parties are already well past the close of discovery, there is not time to develop such an argument, and the Court will not permit Defendants to adopt such a cut-off point arbitrarily. Fortunately, the Parties have other safeguards in place to prevent the mis-use of produced documents that contain the agreed upon search terms but are either unresponsive, privileged or otherwise protected, such as the Protective Order (ECF 97) and Federal Rule of Evidence 502(b) protections against inadvertent disclosures, which the Parties have agreed will apply under these circumstances. The Parties may, at Defendants discretion, continue to meet and confer regarding the use of predictive coding as a means of identifying documents that are unlikely to be responsive and thus do not need to be produced in this action. However, absent any agreement on such identification, Defendants’ entire ESI production, whether or not Defendants have been able to review all of the documents in advance of production, must be turned over.""","Summary of Facts and Activity to DateThis class action was filed on behalf of three classes: the Injunctive Relief Class; the Companion Injunctive Relief Class; and the Damages Class. The three classes are those with mobility disabilities who were allegedly denied ""full and equal access"" to Levi’s Stadium’s facilities, services, accessible seating, parking, and other amenities because Levi Stadium and defendants did not construct the Stadium in compliance with disability access standards. The final class settlement was accepted on July 23, 2020. The terms included the Stadium updating thousands of barriers at the Stadium: the parking lot, the pedestrian right of way, shuttle access, and ticket access.  On top of the Stadium changes, the 49ers also created a $24 million Damages Fund distributed to the Damages class  under California Civil Rights Act for incidents of discrimination they suffered between April 13, 2015 and March 9, 2020.",Settlement Approved,2016.0,Settled
84,84,Nilsson v. General Motors,"General Motors settled with motorcyclist injured in crash with a self-driving car, arguing GM negligently breached the duty of care for obeying traffic laws by swerving into another lane",,Federal: US Dist.Ct. N.D. California,Autonomous Vehicles,Negligence,"Product Liability, Underperformance",2018-01-22,6/26/2018,https://blogs.gwu.edu/law-eti/?page_id=10&pid=27,Inactive: Settled,Personal injury complaint by a motorcyclist injured y a self-driving car,"Summary of Facts and Activity to DateNilson was driving in the middle lane on his motorcycle and Salazar was driving ahead of him in a 2016 Chevrolet bolt Vehicle. The car was in ""self-driving mode"" so Salazar kept his hands off the wheel. Salazar commanded the car to change lanes to the left. The car changed lanes, Salazar proceeds to travel straight, however at the same time the self-driving car suddenly veered back into Nilsons lane, sticking him and knocking him to the ground. Nilson suffered neck and shoulder injuries and was forced to take disability leave form his work. The case eventually settled.",Dismissed,2018.0,Settled
85,85,Ogletree v. Cleveland State University,A student sued his university arguing that the use of remote proctoring tools violated his Fourth Amendment rights. The court found that the room scans were a search and that the student's privacy interests outweighed the university's interests in conducting the scans.,Rospondus; Honorlock,U.S Distr. Ct. N.D. Ohio,"Constitutional Law, Privacy",Fourth Amendment,Privacy,2021-03-02,9/25/2022,https://blogs.gwu.edu/law-eti/?page_id=10&pid=80,Active: Appeal Filed,,Summary of Facts and Activity to Date,District Court Opinion,2021.0,Active
86,86,Oliver v. City of Detroit,"Michael Oliver, a 25-year-old Black man from Detroit, was wrongfully arrested because of a false face recognition match in 2019. This appears to be the second known case of someone being wrongfully arrested in the United States as a result of face recognition technology.",,"filed in the Wayne County Circuit Court, removed to District Court, E.D. Michigan","Criminal Justice, Detention and Release, Facial Recognition, Generative AI","42 USC 1983, Due Process, Equal Protection, Fourth Amendment, Intentional Torts, Negligence, Procedural Due Process","Facial Recognition, Law Enforcement, Socioeconomics Bias, Unreliability",2020-09-04,2/6/2024,https://blogs.gwu.edu/law-eti/?page_id=10&pid=125,Active,"Oliver is the second Detroiter to come forward with a story of a wrongful arrest due to the technology. And as protests around police misconduct swell across the country, Detroit activists have zeroed in specifically on DPD’s 2017 purchase of facial recognition technology from South Carolina vendor DataWorks Plus. They suggest Oliver and Robert Williams, who was wrongly accused of stealing watches from Shinola due to a facial recognition misidentification, are just the tip of the iceberg.DPD maintains that the Oliver misidentification — like the Williams misidentification — was the product of questionable detective work (both relied solely on facial recognition technology and photo line-ups) and is not indicative of systemic problems with the technology.This incident, underscores a bigger issue: mounting tension around Detroit Police Departments' use of facial recognition software.","Summary of Facts and Activity to DateIn September, Oliver filed a lawsuit in the Wayne County Circuit Court against the city of Detroit for at least $12 million. The lawsuit accuses Detroit Police of using ""failed facial recognition technology knowing the science of facial recognition has a substantial error rate among black and brown persons of ethnicity which would lead to the wrongful arrest and incarceration of persons in that ethnic demographic.""The plaintiff sued the City of Detroit (“COD”) and an individual COD police officer under 42 U.S.C. § 1983, equal protection under the 14th Amendment. He alleged that Defendant COD allowed others to engage in a pattern of racial discrimination of plaintiff and other African-American citizens in violation of the equal protection guaranteed by Elliott-Larsen Act. He also sued the police officer for negligence and intentional infliction of emotional distress.",NOTICE TO APPEAR BY TELEPHONE,2020.0,Active
87,87,P.M. v. OpenAI LP,"Anonymous plaintiffs sue OpenAI and Microsoft alleging theft of private information from users of ChatGPT and of many other applications with which ChatGPT is integrated, resulting in a variety of privacy and property-based claims.",ChatGPT,Federal: US Dist. Ct. N.D. Ca.,Generative AI,"Conversion, Failure to Warn, Illinois Biometric Information Privacy Act, Intrusion Upon Seclusion, Larceny / Receipt of Stolen Property, New York General Business Law, Negligence, Right to Privacy, Unjust Enrichment, Unfair Competition",Privacy,2023-06-28,9/15/2023,https://blogs.gwu.edu/law-eti/?page_id=10&pid=93,Inactive,,"Summary of Facts and Activity to DateSixteen anonymous plaintiffs, both adults and minors sue OpenAI and Microsoft alleging misappropriation of private information from users of ChatGPT and of many other applications with which ChatGPT is integrated, resulting in violations of the Electronic Communications Privacy Act, the Computer Fraud and Abuse Act, California privacy and unfair competition laws, Illinois's Biometric Information Privacy Act, negligence, invasion of privacy, intrusion upon seclusion, larceny, conversion, unjust enrichment, failure to work, and the New York General Business Law.  The complaint seems to be concerned both with collection of data to train GPT models, and ongoing collection of data through interactions with ChatGPT, both directly and through other apps and websites into which it is integrated. Plaintiffs voluntarily dismissed the complaint on September 15, 2023.",Plaintiffs filed a Notice of Voluntary Dismissal,2023.0,Inactive
88,88,"Pandolfi v. AviaGames, Inc.","Gamers have brought a suit involving AI, alleging that AviaGames Inc. engaged in a racketeering scheme by using AI to manipulate games of skill to dupe unwitting gamers out of nearly $1 billion. In their November 2023 suit, the gamers said they believed they were competing against humans, when they were actually playing against bots that were programmed to win.",,US District Court for the Northern District of California,"Fraud, Generative AI",Unfair Competition,Unaware of Use of Algorithm,2023-11-17,1/26/2024,https://blogs.gwu.edu/law-eti/?page_id=10&pid=117,Active,"Cash-gaming app maker AviaGames Inc. and its founders were targeted in a class-action suit by players who say they were deceived by secret “bots” that tilted the odds on the company’s platform.“Avia users collectively have wagered hundreds of millions of dollars to compete in these games of ‘skill’ against what Avia says are other human users,” says the complaint filed Friday in US District Court for the Northern District of California. “However, as it turns out, the entire premise of Avia’s platform is false: Instead of competing against real people, Avia’s computers populate and/or control the games with computer ‘bots’ that can impact or control the outcome of the games.”The heart of the suit comes from documents made public in a 2021 lawsuit filed against Avia by Las Vegas-based rival Skillz Platform Inc. that alleged infringement of a pair of patents. Two years into that case, lawyers for Skillz flagged text messages turned over by Avia in discovery that purportedly included coded references to “bots” on Avia’s gaming platform.Avia founder and CEO Vickie Chen, a defendant in the class suit, had previously testified that the company doesn’t use bots, though at a deposition in the case she declined to answer questions about “skills-based gaming,” invoking her Fifth Amendment right against self-incrimination.The class-action suit also refers to a recent US Department of Justice investigation into Avia’s alleged use of bots, also apparently prompted by the disclosures in the patent case. Judge Beth Labson Freeman, who’s presiding over the patent case, indicated at a recent pretrial hearing that the investigation is being overseen by the New Jersey US Attorney’s Office and is in the very early stages.At a pretrial hearing for the patent suit case on Nov. 9, a lawyer for Mountain View, Calif.-based Avia argued Skillz said the bot allegations weren’t relevant to the patent issues, but that Skillz had sought to publicize the criminal investigation to gain an edge at trial. Avia’s lawyer said Skillz hoped potential exposure to criminal liability would force Skillz’s executives to plead the Fifth Amendment while on the stand, prejudicing the company in front of jurors.","Summary of Facts and Activity to DateA proposed class action lawsuit against AviaGames accuses the company of using bots against human players on its purportedly peer-to-peer skill-based games. The accusation arises from claims made during the discovery phase of a separate patent lawsuit against AviaGames by its rival, Skillz. This new action on behalf of AviaGames’ customers argues that such use of bots in a purported skill game amounts to racketeering and conspiracy.Filed on November 17th, 2023, in Northern California District Court, plaintiffs Andrew Pandolfi of Texas and Mandi Shawcroft of Idaho allege players are pitted against bots when playing Avia titles such as Bingo Tour on its Pocket7Games platform.Avia, the brief explains, is a “leading provider of online games” where users “compete in games of skill against other real people for money.”Collectively, the filing states users have spent hundreds of millions of dollars on these games of “skill,” supposedly matched against other humans.The plaintiffs claim that, by allegedly manipulating their games with computer bots, Avia has turned games that were marketed as skilled into “an unapproved gambling enterprise.”“Recently uncovered evidence indicates that Avia has perpetuated a lie on its customers and that players are actually playing against computer bots in a stacked game of chance,” the class action states.The plaintiffs claim Avia is guilty of violating the federal Racketeer Influenced and Corrupt Organizations Act and California’s Unfair Competition Law and Consumer Legal Remedies Act.",Order on Administrative Motion,2023.0,Active
89,89,Parsa et al v. Google L.L.C. et al,"AI Foundation brought suit against Big Tech companies and notable political figures for ""developing code, algorithms, and ecosystems"" to polarize hate among political parties, supply biometric information and algorithms that have resulted in and perpetuate mass genocide, and making it difficult for the AI Foundation to spread awareness of the dangers of AI, dismissed for failure to show cause",,Federal: US Dist. Ct S.D. California,"Crimes Against Humanity, Genocide, Nuremberg Laws, Social Media","18 U.S.C. §1038 False Information and Hoaxes, 22 U.S.C. §2551, CECPA, CFAA, FTC Act, Genocide Convention, Negligence","Facial Recognition, Hate Speech, Misinformation, Misuse of AI",2019-12-16,6/6/2020,https://blogs.gwu.edu/law-eti/?page_id=10&pid=9,Inactive: Dismissed for failure to prosecute,"While the court dismissed on procedural grounds so the judge did not consider the claims, the claims included misuse of artificial intelligence, endangering of the human race by building AI systems, treason, complicit in genocide, transfer of bio weapon to China in violation of Biological Weapons Anti Terrorism Act, social engineering, brain washing, breach of implied good faith and fair dealing, defamation, intentional infliction of emotional distress, cultural genocide with the use of AI, negligent creation of technology, fraud and deceit, negligent misrepresentation, breach of privacy, and preventing Parsa from saving the public from AI and bio tech.The majority of the complaint focuses on providing the Chinese government and Chinese companies with AI, facial recognition, and biotechnology relating to the deaths of Uyghurs and democracy journalists and lawyers, as well as all minorities in China, as well as data on Americans to the Chinese. The negligence claim was negligence in algorithm fairness that allowed ""hate speech, misinformation and slander"" from Google for masking posts about the genocide in China. The complaint poses the question: can big tech companies be charged under Article 3 of the Genocide Convention?The complaint requested relief of $4 Trillion, with the individual persons named to forfeit assets and spend the rest of their lives in jail, with companies submitting public apologies, explanatory corrective statements, and dedicating years of public service to the alleged victims.These claims are popular among conspiracy theorists, and could be the first of many to bring these theories to a court, of which it would be interesting to see how many survive on substantive claims.","Summary of Facts and Activity to DateIn response to current events, namely the role of algorithms in the 2016 election, facial recognition software in China, the genocide of Uighurs, the general dominance of Google, Facebook, and Big Tech, and the blocking of Parsa's book on the dangers of artificial intelligence, Parsa filed a complaint in December 2019, amending in February of 2020. Parsa is the President of The AI Organization, and filed this complaint on behalf of "" Christians, Cyrus A. Parsa, Falun Dafa Practitioners, John Does 1-Unlimited, Lawyers, Judges, Journalists killed in China, The AI Organization, Inc, Tibetans, Uyghurs, and Victims of Persecution, Rape, Torture, Concentration Camps, Sex, Human, and Organ Trafficking and Organ Harvesting in China, Hong Kong, America and Around the World.The case was brought against Google L.L.C., Barack Hussein Obama, Joe Biden, Hunter Biden, Hillary Clinton, Eric Schmidt, Nancy Pelosi, John 0. Brennon, James Corney, AndrewMcCabe, James Clapper, Facebook, Inc, DeepMind Inc, Alphabet Inc, The World Bank, Neuralink Inc, 20 Tesla Inc, Larry Page, Sergey Brin, Sundar Pichai, Mark Zuckerberg, Elon Musk, Amazon, Jeff Bezos, Microsoft. Bill Gates, CISON PR NewsWire. CNN Cable News Network. Anderson Cooper. Don Lemon. MSNBC, Rachel Maddow. James Clapper, Washington Post. New York Times. Time Magazine. Massachusetts Institute of Technology, Harvard. Adam Schiff, Wyss Institute, Daroer, Qualcomm. George Soros, Soros Fund Management. Open Societv 25 Foundations. University of Vermont. Joshua Bongard and Sam Kriegman. Rockefeller Foundation. Huawei, Boston Dynamics. Hanson Robotics. Didi Chuxing, Megvii Face++. Alibaba, Sensetime, !Carbon X, Festa, Chinese Communist Party, & John Doe's 1-Unlimited Defendants.The court ordered on May 5, 2020 for plaintiffs to show cause by May 19 under FRCP rule 4(m) as no other activity had occurred since the amended complaint on February 26. When no such activity occurred, the lawsuit was dismissed without prejudice for failure to prosecute without considering any claims.",Dismissed without prejudice for failure to prosecute,2019.0,Dismissed
90,90,"Patel v. Facebook, Inc.",A plaintiff whose common law privacy rights or biometric privacy rights are violate establishes an injury in fact that is required under Article III standing.,,U.S. District Court for Northern California,Biometric Data,Illinois Biometric Information Privacy Act,Facial Recognition,,,https://blogs.gwu.edu/law-eti/?page_id=10&pid=74,,The collection of an individual’s biometric data in violation of the Illinois Biometric Information Privacy Act is sufficient to establish Article III standing.,"Summary of Facts and Activity to DateFacebook users in Illinois allege that Facebook collected their biometric data without notice or consent through the Tag Suggestions tool. This tool undergoes four steps, one of which is to search the stored “face templates” from users for a match. Facebook collects face templates from users without their consent or notice.",Cert Denied,,Not specified
91,91,People v. H.K,"On the heels of People v.Wakefield, the court found that TrueAllele's source code running DNA found at the crime scene against defendant DNA to produce probabilities was not sufficient to make the source code a declarant",TrueAllele,State: New York Criminal County Bronx,"Constitutional Law, Criminal Justice, Sentencing","Biometric Information Privacy Act, 6th Amendment","Reliability, Confrontation Clause",2018-10-28,5/15/2020,https://blogs.gwu.edu/law-eti/?page_id=10&pid=55,Inactive,"The court contrasts this case with Wakefield in that the defendant here did not assert that they did not have access to the source code. However, the defense called for a Frye Hearing for admissibility of this DNA analysis because the algorithm used, STRMix, is not identical to TrueAllele and requested a hearing to ascertain the acceptance within the scientific community. The court overviews the four steps in DNA genotyping:  (1) extraction of the DNA from a sample through heating to isolate; (2) quantifying the amount of DNA,  (3) amplification or copying the DNA; and (4) detection of any usable DNA in the sample.  After this process either a criminologist or an algorithm compare the samples for a probability of matching. An algorithm is used for two or more DNA sources to differentiate the mixing of the DNA into the separate samples, like STRMix. The algorithm assigns a probability for each genotype loci using both biological and mathematical modeling.  When STRmix and the analyst differ in opinion, the analyst reexamines the inputs into the algorithm and rerun the correct parameters.  On cross-examination, the defense questioned the witness on the issues with STRMix, which include: ""stutter, drop-in, drop-out, random walk standard deviation, effective sample size thinning, degradation, saturation burn-in accepts, highest posterior density iterations and duplicate runs."" These are accounted for in the parameters input so that they do not change the probability ratio provided.  The criminologist expert also testified of how the criminalists are trained first to interpret DNA and then exercises showing how STRmix works using assumptions and parameters with samples. STRmix differs from TrueAllele in that the raw data is input directly into TrueAllele whereas STRmix needs an analyst to go through the extraction-quantification process. Finally, the expert witness compared algorithms like STRmix to Google Maps: ""a driver could use a map to get their destination, calculate the mileage and make an approximation about travel time. With Google maps, the driver could see all that information mapped out in front of them—but they would still have to check that they are going to the correct place and verify that they had gotten there.""","Summary of Facts and Activity to DateThe defendant here was a tenant of the victims' grandmother, and on October 28, 2018 entered their bedroom and sexually molested the two victims. The victims informed their family members who called the police. The defendant told the police there was no sexual contact in their interaction. Both victims and the defendant voluntarily gave DNA samples for testing from the touched areas. Defendant was charged with two counts of Forcible touching, one count of Endangering the welfare of a child, two counts of Sexual abuse in the third degree and two counts of Harassment in the second degree. The DNA samples tested from one of the two victim did not have enough DNA to type. However, the DNA sample secretion from the first victim showed over a quadrillion likelihood that the sample came from defendant and the victim and not two unknown parties. The defense called for a Frye Hearing for admissability of this DNA analysis because the algorithm used, STRMix, is not identical to TrueAllele. At the hearing, the defense did not present any witnesses, and the prosecution presented a criminologist with a background that the court found credible. The criminologist frequently worked with STRMix. The court admitted the evidence, and ruled on the sixth amendment argument found that raw data was not testimonial even if it linked to the accused defendant. The court further held that an analyst that who testifies to the facts that were assisted by an algorithm means the analyst can be meaningfully cross-examined. The STRmix is the tool that the analyst uses, so the motion to deny criminalist testimony was denied.",Trial Court ruling,2018.0,Inactive
92,92,People v. Superior Court (Chubbs),"Similar to H.K. and Wakefiled, the confrontation clause is not violated when the defendant does not have access to the source code of the DNA genotyping algorithm.",,State: Los Angeles County Super. Ct.,Criminal Justice,Due Process,Confrontation Clause,2012-11-18,,https://blogs.gwu.edu/law-eti/?page_id=10&pid=66,Inactive,,Summary of Facts and Activity to Date,,2012.0,Inactive
93,93,People v. Wakefield,"Acknowledging the intersection of due process and scientific advancements, the highest court affirmed a trial court finding that TrueAllele Casework System, the DNA software program used to identify defendant in a murder scene, was generally accepted by the scientific community and did not violate defendant's right to face accusers by not having access to the source code by differentiating DNA collection vs. DNA probability",TrueAllele,State: New York,"Constitutional Law, Criminal Justice, DNA Analysis, Sentencing","Biometric Information Privacy Act, Conviction Challenge, Due Process, Evidence, 6th Amendment","Admissibility, Transparency/Trade Secrecy, Unreliability, Reliability, Confrontation Clause",,8/15/2019,https://blogs.gwu.edu/law-eti/?page_id=10&pid=54,Inactive,"The two issues relating to algorithms in this case was the scientific validity of TrueAllele and the defendant's right to face his accuser as an algorithm. First, the court notes that TrueAllele uses the MCMC algorithm to ""solve high dimension calculus problems that would be impossible or impractical without a computer so as to identify all possibilities, not just the maximum possibility."" At the trial court Frye hearing, expert witness testified that TrueAllele uses the Markov Chain Monte Carlo algorithm give probabilities of all different possibilities, as it proposes the possibilities for different genotypes based on the lab generated data from the DNA electropherogram rather than the traditional interpretation by a person. The expert witness added that ""after objectively generating all genotype possibilities, TrueAllele answers the question of ""how much more the suspect matches the evidence [than] a random person would,"" and the answer takes the form of a likelihood ratio."""" For the second issue of the right to face accuser violated because he was not granted access to the source code. The court grappled with the intersection of due process and science. The court differentiates that the DNA extraction done by state police traditionally go through combined probability inclusion to simplify the DNA for human observation whereas TrueAllele is a fully-continuous probabilistic systems uses all available data to look at more patterns. There is human interaction with True Allele as it tells the software what to download and what questions to ask when running the data.","Summary of Facts and Activity to DateThe defendant was brought on murder and robbery charges in Schenectady County. After the murder victim was found by a mental health case worker after not responding, the police published request for information. A friend of the defendant informed police that the defendant had admitted to murdering the victim, leading to the defendant's arrest. The police performed a nasal swab and sent the DNA to a private lab, Cybergenetics, hat used TrueAllele for testing. At the trial court, the defendant moved to exclude all evidence regarding TrueAllele until it was established that it was recognized by the scientific community in a Frye hearing. The trial court granted the Frye hearing and heard testimony from Cybergenetics' founder and chief scientist in July of 2014.  The court allowed the DNA probability into evidence, a jury trial found the defendant guilty of first degree murder and first degree robbery, anhd he was sentenced for life in prison without parole. The defendant appealed. In affirming the trial court's finding under the Frye protocol of hearing expert testimony"" based on a scientific principle or procedure which has been sufficiently established to have gained general acceptance in the particular field in which it belongs."" TrueAllele has gone through 25 validation studies and had been published in six forensic science journals, has been recognized by The DNA Subcommittee of the New York State Forensic Science Commission, and has used it to identify remains from 9/11. Defendant's other claim on appeal is that the DNA evidence does not establsih robbery, however TrueAllele's probability the defendant's DNA on the missing items was categorically more probable than coincidental. Even viewing the DNA evidence in a neutral light, the addition of witness testimony convinced the appellate court to affirm. The defendant's third claim on appeal is that the defendant did not have the right ot face his accuser against TrueAllele. Unlike traditional DNA analysis that does not use all the data extracted and relies on a human analyst, True Allele uses all the data to come up with probabilities through a calculus algorithm. The source code is protected by trade secret as only two people know it, and the source code was designed with a high level of mathematical understanding.  The court found that Cybergenetics was acting to assist law enforcement, the report of comparing the defendant's DNA to the DNA on the crime scene was testimonial in nature and thus True Allele is not a declarant and affirmed the trial court. The concurring judge said it was unnecessary to decide this issue because the defendant did not move for the source code to be disclosed post Frye Hearing.",Highest Court Opinion,,Inactive
94,94,People v. Younglove,,COMPAS,State: Michigan,"Criminal Justice, Sentencing",,,,,https://blogs.gwu.edu/law-eti/?page_id=10&pid=37,,,"Summary of Facts and Activity to DateThis appeal about COMPAS is brought relating to: PEOPLE OF THE STATE OF MICHIGAN, Plaintiff-Appellee, v. ERIN RENEE YOUNGLOVE, Defendant-Appellant. PEOPLE OF THE STATE OF MICHIGAN, Plaintiff-Appellee, v. DARRELL WAYNE HEGLER, Defendant-Appellant. PEOPLE OF THE STATE OF MICHIGAN, Plaintiff-Appellee, v. LUKE MATTHEW WILSON, Defendant-Appellant. PEOPLE OF THE STATE OF MICHIGAN, Plaintiff-Appellee, v. FREDERICK ANTHONY BRADFORD, Defendant-Appellant.",,,Not specified
95,95,Rana v. Amazon et al,"A lawsuit against Amazon for vicarious liability of a delivery truck driver Williams, the contracting delivery company Harper Logistics and the delivery business’s insurance provider, Old Republic Insurance Co. for a car crash by Amazon Delivery Driver that left plainitff paralyzed.",,State: Georgia,Personal Injury,"Negligence, Vicarious Liability",Misuse of AI,2021-06-25,,https://blogs.gwu.edu/law-eti/?page_id=10&pid=71,Active,"Although have been over 100 lawsuits filed against Amazon Logistics in the last year for crashes by delivery vans, this case is the most severe in its argument of control by Amazon rather than the contracted delivery companies and insurance providers. The outcome of this case will influence future cases against Amazon, and could result in the public exposure of Amazon's algorithms. By demonstrating managerial ownership of Harper Logistics rather than Amazon merely being a customer, plaintiff hopes to show Amazon's algorithm controlled the driver route and speed, and therefore is vicariously liable for negligently making drivers work unreasonable shifts.","Summary of Facts and Activity to DateOn March 15, 2021, plaintiff was in a car accident in Atlanta when an Amazon Delivery truck hit their car. Plaintiff suffered spine and brain injuries, on a ventilator and now in a wheelchair. Plainitiff filed complaint in state Atlanta court in June 2021 against Amazon, the delivery driver Williams, the contractor delivery truck company Harper Logistics, and the delivery company's insurance provider. Through the theory of vicarious liability, plaintiff argues that Amazon's algorithms controls the whole delivery operations of the delivery truck drivers and trucks to deliver all the packages in a speedy manner. The arguments for vicairous liablity are that Amazon controls the route, the hours, the number of packages, and requires drivers to wear the Amazon logo.",,2021.0,Active
96,96,"Renderos v. Clearview AI, Inc.","Plaintiffs initially filed suit against Clearview in County of Alameda Superior Court in California on March 9, 2021. Clearview filed an action to remove the matter to the Northern District of California (N.D. Cal.). This case was transferred to N.D. Ill. on Oct. 5, 2021, to be joined with the existing MDL, In re Clearview.",Clearview,California,"Biometric Data, Facial Recognition, Privacy","Right to Privacy, Right to Publicity","Facial Recognition, Law Enforcement",2021-03-14,10/5/2021,https://blogs.gwu.edu/law-eti/?page_id=10&pid=73,Inactive,"Renderos was the first case against Clearview in California.  The plaintiffs also filed claims against police departments in California for uploading photographs of plaintiffs and other California citizens to the Clearview database, despite the City of Alameda (where one of the police departments resided) banning facial recognition in 2019.  The Renderos claims were primarily focused on the use of facial recognition for speech chilling and police action, rather than solely Clearview's acquisition of biometric data.The Renderos plaintiffs, resting on their claims against the California municipal defendants, attempted to remain in California state court rather than be transferred to the MDL in N.D. Ill.  However, the Judicial Panel on Multidistrict Litigation determined that the issues in the case were substantially similar to the other cases in In re Clearview.  Although the arguments were different, the issues regarding collection, distribution, and profiting off of citizens' biometric data were the same.  The case was transferred to N.D. Ill. and combined with In re Clearview on Oct. 5, 2021.","Summary of Facts and Activity to DateRenderos et al. filed suit in California Superior Court against Clearview and the Alameda County District Attorney, Alameda Police Department, El Segundo Police Department, Antioch Police Department, and anonymous police officers on Apr. 22, 2021.Clearview filed a motion June 14, 2021, to remove the case to N.D. Cal., arguing that the diversity and amount in controversy requirements had both been met.On June 21, 2021, the United States Judicial Panel on Multidistrict Litigation filed a conditional transfer order to transfer this case to N.D. Ill. and join it with the other cases in In re Clearview.  Plaintiffs requested that the panel vacate the order on the grounds that their case involved California municipal defendants and was centered on fear of police action, rather than loss of privacy.On Oct. 5th, 2021, the United States Judicial Panel on Multidistrict Litigation upheld the conditional transfer order and ordered the transfer to N.D. Ill. and consolidation with In re Clearview.",10/05/2021,2021.0,Inactive
97,97,"Roberson v. Clearview AI, Inc.",,Clearview,Federal: E.D. Va.; Transferred to Federal: US Dist Ct. S.D. New York; Transferred to US Dist. Ct. N.D. Illinois,Facial Recognition,,Privacy,2020-02-03,1/12/2021,https://blogs.gwu.edu/law-eti/?page_id=10&pid=33,Active,"Chronologically, this was the second case filed of the nine consolidated into In Re Clearview. It is the only case not filed in either Illinois or New York, and it was brought under the Virginia Code and the Virginia Computer Crimes Act. Unlike similar cases, Roberson only brought claims against Clearview and not its founders (and obviously not the Illinois company who acted as a third party contractor).","Summary of Facts and Activity to DateRoberson filed complaint on February 3, 2020 on behalf of a Virginia class whose photographs were unlawfully used by Clearview under the Virginia Computer Crimes Act.The Virginia Code provides statutory damages for ""any person whose name, portrait, or picture is used without having first obtained the written consent of such person . . . for the purposes of trade"" and the Virginia Computer Crimes Act provides a private right of action regardless of any malicious intent. The specific claim against Clearview is obtaining the property of another without consent from the data scraping online, and then making copies of the data into their database, and third because the information collected is identifying personal information and then used trickery or deception by not obtaining consent.Clearview filed its motion to transfer or dismiss in March.Court transferred the case to SDNY on May 13, 2020, which the Virginia court granted.On May 29, the SDNY Court denied Mutnick's motion to intervene and dismiss or transfer the cases to Illinois, as eight federal cases had been filed by May, six of which had been brought or transferred to New York.",MDL Transfer,2020.0,Active
98,98,Rodriguez v. Massachusetts Parole Board,"Mr. Rodriguez, an incarcerated plaintiff in Massachusetts, was consistently denied parole based on a predictive algorithm that gave him a high-risk score for reoffense. Rodriguez sued the Massachusetts Parole Board, arguing that the use of this algorithm failed to consider relevant factors and violated his due process rights. The Supreme Judicial Court of Massachusetts held that the board had appropriately considered the relevant factors and affirmed its decision to deny parole.",LS/CMI,Massachusetts Supreme Judicial Court for the Commonwealth,"Civil Rights, Criminal Justice",5th Amendment,"Individualized Assessment, Misuse of AI, Transparency/Trade Secrecy",2022-11-23,3/7/2022,https://blogs.gwu.edu/law-eti/?page_id=10&pid=79,Inactive: Judgment for D,"Mr. Rodriguez, an incarcerated plaintiff in Massachusetts, was consistently denied parole based on a predictive algorithm that gave him a high-risk score for reoffense. Rodriguez sued the Massachusetts Parole Board, arguing that the use of this algorithm failed to consider relevant factors and violated his due process rights.","Summary of Facts and Activity to DateThe Massachusetts Parole Board (“MPB”) has started using a predictive analytical tool from a third-party contractor. The MPB uses a tool called the Level of Service/Case Management Inventory (“LS/CMI”) to generate risk scores that purport to predict how likely a parole applicant is to end up back in prison. Mr. Jose Rodriguez, has been consistently denied parole based on the high risk score that LS/CMI gives him. Mr. Rodriguez is challenging the Parole Board’s use of LS/CMI to give him a high risk score, and the Parole Board’s refusal to share any useful information about how his score was calculated.",Opinion Issued,2022.0,Decided
99,99,Sancton v. OpenAI Inc.,"Nonfiction author Julian Sancton files a copyright infringement suit against OpenAI and Microsoft, proposing a class action involving all authors of nonfiction works registered at the Copyright Office that have received ISBNs or were published in academic journals and that were copied as training data for ChatGPT.",ChatGPT,Federal: US Dist. Ct. S.D.N.Y.,Generative AI,Copyright Infringement,"Copyright Infringement, Fair Use",2023-11-21,11/22/2023,https://blogs.gwu.edu/law-eti/?page_id=10&pid=105,Active,"This is the first lawsuit involving ChatGPT that names Microsoft, on a theory of contributory infringement, as well as OpenAI, on a theory of direct copyright infringement.","Summary of Facts and Activity to DateComplaint filed November 21, 2023; case referred to Judge Sidney Stein as possibly related to Authors Guild v. OpenAi.",Case referred to Judge Sidney Stein,2023.0,Active
100,100,"Sevatec, Inc. v. Ayyar",The court allowed expert testimony at trial to understand complex evidence related to artificial intelligence,,State: Fairfax County of Virginia,Corporate Law,"Evidence, Fiduciary Duty",Role of Expert Testimony,2018-10-09,,https://blogs.gwu.edu/law-eti/?page_id=10&pid=57,Active,"The two issues for expert testimony concerned (1) explaining complex artificial intelligence to the jury and (2) explaining the corporate business opportunity. For the complex issues, Hermus was an appropriate expert witness with 20 years of experience in information technology and could explain data analytics, artificial intelligence, and machine learning to the triers of fact. His background gave him ""knowledge beyond that of persons of common knowledge and ordinary experience.""","Summary of Facts and Activity to DatePlaintiff is a corporation, Sevatec, who provides ""data analytics"" solutions involving machine learning, artificial intelligence, and open source technologies. Sevatec brought suit in Fall 2018 against its former President and CEO Ayyar and Chief Technology Officer Bangalore. Sevatec alleges Ayyar and Bangalore ""conspired to develop a new technology solution involving artificial intelligence and data analytics prior to their departures and formed Defendant Percipient.AI, Inc. whose flagship offering is the technology solution developed while in the employ of Sevatec."" In March 2019, Sevatec assigned expert witness Hermus who is a technology specialist to testify on their usurpation of business from Sevatec. Defendants moved to exclude his testimony for three reasons: (1) Hermus's opinions  will mislead the jury about Virginia law by using a Delaware test, (2) ""Hermus's opinions will invade the province of the jury because they are rudimental and will not assist the jury in resolving any facts  at issue,"" and (3) Sevatec failed to identify all the documents and information relied upon by Hermus in his expert disclosure. On June 3, 2019, the court denied this motion in limine. For the first contention, the court compares the Usurpation of Corporate opportunity Standard with the Line Business Test of Delaware  as well as the Multiple Factors test and Fairness tests, concluding that Virginia has not adopted a test and thus can rely on an expert from another jurisdiction. Second, the court disagrees with the defendant that the issues are noncomplex, as his ""scientific, technical, or other specialized knowledge will assist the trier of fact"" in determining whether Defendants usurped a technology solution from Sevatec. Third, the court held that Sevatec was not required to identify Hermus' sources of information.",,2018.0,Active
101,101,"Silverman v. OpenAI, Inc.","Authors Sarah Silverman, Christopher Golden and Richard Kadrey sue OpenAI, Inc. on behalf of themselves and all persons domiciled in the United States owning copyright in any work used as training data for OpenAI's ChatGPT large language models, including GPT-3.5 and GPT-4, alleging copyright infringement, removal of copyright management information, unfair competition, unjust enrichment, and negligence.",ChatGPT,Federal: US Dist. Ct. N.D. Ca.,Generative AI,"Copyright Infringement, Negligence, Unjust Enrichment, Unfair Competition, 17 U.S.C. 1202 Removal of Copyright Management Information",Copyright Infringement,2023-07-07,7/24/2023,https://blogs.gwu.edu/law-eti/?page_id=10&pid=91,Active,,"Summary of Facts and Activity to DatePlaintiffs allege that OpenAI trained its ChatGPT large language models, include GPT-3.5 and GPT-4, with literary works that were still under copyright, without the authorization of the owners of copyright in those works, including the plaintiffs or of anyone in the proposed class of US-domiciled authors and copyright owners whose books were so used. Plaintiffs filed their complaint on July 7, 2023; the case was assigned to Judge Trina L. Thompson on July 24, 2023",Case assigned to Judge Trina L. Thompson,2023.0,Active
102,102,State of Washington v. Flanigan et al,"Defendants Flanigan et al sought discovery from Washington State Patrol for access to the Draeger machine for dynamic testing comparing the software to what the machine actually does as opposed to time-consuming static testing, the court granted discovery of the materials reasonably in possession or in control of by the State Snohomish County Prosecuting Office: two instruments and the software code under a protective order",Draeger Alcotest,"State: Washington Snohomish County Court, South County",Breathalyzer,"Discovery, Evidence, Protective Order","Admissibility, Transparency/Trade Secrecy",2015-01-01,,https://blogs.gwu.edu/law-eti/?page_id=10&pid=41,,,"Summary of Facts and Activity to DateNeed information about the four cases that were consolidated into this case in 2015In November 2015, the court granted Flanigan et al's discovery for access to two of the Snohomish County's Draeger machines for dynamic testing, as it was material and reasonable evidence.The Court on December 16th granted Draeger's Motion to Quash Subpoenas as Draeger was categorized as witness and there was no evidence that Flanigan filed appropriate actions for a witness in Texas.The court on December 17th granted a motion to modify the subpoena ad granted a protective order for the Washington State Patrol: the modified order required WSP to provide the two Draeger Alcotest to defendant experts, and under a protective order provide the software source code to defendant experts",,2015.0,Not specified
103,103,State v. Pickett,"Court of Appeals ruling that the source code must be revealed under a protective order for effective review of the reliability of the state's proprietary DNA analysis when there was not enough DNA for traditional DNA analysis to identify a criminal defendant, emphasizing the importance of independent review and the dangers of programmer bias",TrueAllele,State: New Jersey,"Criminal Justice, DNA Analysis, Intellectual Property","5th Amendment, N.J.R.E. 702, 6th Amendment","Insufficient Research, Role of Expert Testimony, Transparency/Trade Secrecy, Unreliability/Miscalculationns",2017-04-16,2/3/2021,https://blogs.gwu.edu/law-eti/?page_id=10&pid=21,Active: On Remand,"This is the first case on appeal to tackle the issue of trade secrecy in determining the reliability of forensic evidentiary technology TrueAllele in New Jersey. The solution to balancing constitutional and intellectual property rights was a protective order.The Court of Appeals highlighted True Allele’s competitor who was forced to reveal the source code in another criminal case and multiple errors were found. The court also found the need for independent review for both the judge and the defendant to independently evaluate the State's expert's testimony but acknowledged the concerns about the proprietary information getting out. The court also recognized that the data programmed might be inherently biased, thus exacerbating bias. TrueAllele is designed to evaluate cases where there are low amounts of DNA where other DNA analysis tests will not work.Many groups wrote amicus briefs highlighting the necessity for algorithmic transparency, which are excerpted in the order.","Summary of Facts and Activity to DateOn April 16, 2017, police witnessed defendant and co-defendant shoot into a crowd and flee, where police pursued and arrested them. The police picked up two handguns after retracing Pickett's path and a ski mask retracing the co-defendant's path. The forensic scientist said the small amount of DNA amylase from the saliva on the ski mask was not enough for a traditional DNA analysis but compared to swabs from the Defendant that produced results. The rest of the DNA samples did not produce any results, so the State sent it out.Hudson County Grand Jury indicted and charged defendant with first degree murder and charges relating to weapons.The State sent the samples to Cybergenetics lab in Pittsburgh who used TrueAllele to make up for the smaller samples that often result in more ""probabilistic"" analysis and ""leaves more room for interpretation than for the single-source or simple-mixture samples that have been traditionally DNA tested."" The TrueAllele program calculates likelihood that the given individual was a contributor compared to an unrelated individual to account for the effects of the smaller sample.At the Hudson County court Frye hearing in late April 2019, the State's DNA expert (and co-founder of Cybergenetics) used a software to conclude that the defendant's DNA was connected to the murder in question. After briefs and oral arguments, on June 23, 2020 the judge denied the defendant's request for discovery to this software source code and documents under trade secrecy, finding that the hearing testimony and documents were sufficient. The State's opposition brief included statements from Cybergenetics saying this software was thousands of lines long, not included in the patent because the industry is too highly competitive, and that defendant could examine parts of the source code on a specific computer after signing an NDA. The Judge's order did not engage with the reliability of the software.Defendant appealed this ruling, arguing that the source code was necessary to determine the reliability and therefore admissibility. The Court of Appeals determined that the defendant was entitled to True Allele’s source code for the purpose of challenging the reliability of expert testimony and reliance on the DNA analysis. The court found that defendant was entitled to the source code and documents because the defendant showed particularized need for this discovery: testing, design, bug reporting, change logs, program requirements, any documents needed to challenge the reliability, an example of other jurisdictions safeguarding IP with protective orders.",Court of Appeals Ruling,2017.0,Active
104,104,Tewson v. DoNotPay,"Plaintiff files suit claiming that the ""robot lawyer"" powered by AI the defendant is advertising is incapable of providing the services that the defendant says it can do. Plaintiff wants defendant to properly preserve and produce documents that will allow her to bring suit under other statutes.",,Supreme Court of the State of New York County of New York,Advertising,False Advertising,"Accountability, Reliability, Functionality",2023-02-13,,https://blogs.gwu.edu/law-eti/?page_id=10&pid=134,Active,,"Summary of Facts and Activity to DateDefendant claims that they have created the first ""robot lawyer"" that will be able to provide legal services without having to use real people. Plaintiff was curious about the product and signed up for an account and asked for a few documents. The quality of the documents was poor and the plaintiff had to wait upwards of an hour for some documents. Plaintiff wants a pre-discovery action under New York's CPLR Section 3102(c) for defendant to preserve and produce documents so she may then bring suit under, N.Y. Gen Bus. § 349 and Wash St.§ 19.86.020.",,2023.0,Active
105,105,Thaler v. Commissioner of Patents,The Court upheld the UKIPO's dismissal of Thaler's patents for not having followed the statutory requirements for an application that the inventor be a natural person.,DABUS,International: England and Wales Court of Appeal (Civil Division),Intellectual Property,Patent Application,AI as Inventor,2019-08-29,9/21/2021,https://blogs.gwu.edu/law-eti/?page_id=10&pid=51,Inactive: Decision for P,"The three issues the case presented: (1) does the Patent Act regard a non-human inventor as an invenotr? (2) how has the inventor's right to grant a patent transfer to Thaler to entitle him to apply for this patent, merely as the owner of DABUS? (3) Finally, was the Comptroller required to wait the 16 months before withdrawing or can it be immediate?. The High Court judge noted that although the Patent Act of 1977 was deemed to mean inventor as a natural person, the case at hand was not about whether an AI could be an inventor but rather statutory interpretation, and that the underlying issue should be addressed on appeal.","Summary of Facts and Activity to DateDr. Stephen Thaler applied for a patent in the UK, naming DABUS (Device for Autonomous Bootstrapping of Unified Sentience) as the inventor on October 17 and November 7, 2018. For the application to be considered complete, Thaler had to submit a statement of inventorship, which he submited on July 23, 2019. On August 8, the IPO replied that Thaler must submit the name of the inventor and how he derived the right from the inventor. Thaler's attorney responded with a request for a hearing on August 28, 2019. In November, IPO rejected Thaler's application, and Thaler requested an appeal hearing to a Hearing Officer, which was rejected. Thaler then unsuccessfully appealed to the Patent Court, which dismissed its appeal on September 21, 2020 because the legislation was clear that inventor was a natural person. On September 20, 2021, the Court of Appeals rejected his appeal on the basis of three issues, although two judges dissented. The judges agreed that an inventor must be a person, and that Thaler did not meet the requirements in the application. They found that the IPO did not have to conduct factual or legal investigations, but one of the three judges found that Thaler had fulfilled the requirements because the IPO is not entitled to investigate. The case is being taken to the Supreme Court.",Highest Court Opinion,2019.0,Decided
106,106,Thaler v. Comptroller General of Patents Trade Marks and Designs,"In a landmark decision, the Australian Federal Court set aside the Deputy Commissioner's decision that an artificial intelligence program could not be an inventor, allowing application to go forward when scientist Thaler listed the algorithm DABUS as the inventor for which he owns the copyright to the DABUS source code. Australia sides with South Africa, who outright granted Thaler's application, whereas the US, EU, and UK do not view AI as inventors.",DABUS,International: Federal Court of Australia,Intellectual Property,Patent Application,AI as Inventor,2021-02-09,8/30/2021,https://blogs.gwu.edu/law-eti/?page_id=10&pid=50,Active: On Appeal,"The judge argues the Deputy Commissioner and Commissioner before him confused the identity of a patentee with an inventor, arguing that the inventor does not have to be human, because by that logic one with a patentable invention but no inventor could not apply for the patent, which goes against Section 2A of the Patent Act. The judge explicitly stated that he does not offer a definition for ""artificial intelligence."" The judge also distinguished DABUS as semi-autonomous rather than an automation. The judge also goes into depth explaining how artificial neural networks are the most sophisticated form of machine learning.","Summary of Facts and Activity to DatePlaintiff Dr. Stephen Thaler filed this appeal from the Deputy Commissioner and Commissioner's ruling on his patent application. Thaler owns the copyright to the source code of DABUS (Device for Autonomous Bootstrapping of Unified Sentience) a type of machine learning, trained by both supervised and unsupervised learning, that learns new concepts which are encoded as chained associative memories. With each new memory, DABUS generates new patterns of information and can adapt without human input. Thaler applied for a patent for ""food container and devices and methods for attracting enhanced attention"" on September 17, 2019. The Deputy Commissioner found the application had lapsed on September 15, 2020, because an inventor had to be a person. Because the Commission decided Thaler did not comply with application instructions by listing a human inventor. Judicial review found that this was incorrect because there is no definition of an inventor or explicit statement that an inventor has to be a human in the Act. The statute only provides that ""reg 3.2C(2)(aa), an applicant must provide the name of the inventor of the invention to which the application relates."" Section 9 requires the applicant to be a human person. Upon a finding for Thaler, the IP Commission noted it would appeal this Federal Court Decision.",Notice of Appeal of Federal Court Decision,2021.0,Active
107,107,Thaler v. Iancu (Vidal),The court ruled that AI could not be an inventor.,,Federal: U.S. Dist. Ct. E.D. Va.,"Intellectual Property, Patent",Patent Application,AI as Inventor,2020-08-06,,https://blogs.gwu.edu/law-eti/?page_id=10&pid=69,Active,"The district rule found that the language of the Patent Act indicates an ""inventor"" is a natural person because it: was amended in 2011, when AI was already in existence.The Act includes a definition for ""inventor"" that uses the term ""individual"" and pronouns ""himself or herself."" Finally, the Act requires the inventor to make an oath.The US Supreme Court considered the Dictionary Act, which would apply to the Patent Act, and concluded that the ordinary meaning of ""individual"" is a natural person.Furthermore, Federal Circuit precedent has held that inventors must be natural persons, and this is relevant even though those decisions concerned states and corporations.","Summary of Facts and Activity to DateStephen Thaler develops and applies advanced artificial intelligence (AI) systems that are capable of generating patentable output and is the owner of DABUS. He applies for patent on behalf of DABUS. Because DABUS could not execute the necessary oath or declaration that the Patent Act requires of an inventor, Thaler signed the substitute statement for DABUS and assigns DABUS's ""rights"" in the patent to him.",Appeal,2020.0,Active
108,108,Thaler v. Perlmutter et al,"Stephen Thaler, owner of an artificial intelligence system that he calls a ""creativity machine,"" challenges the refusal of Shira Perlmutter, in her capacity as the Register of Copyrights, to issue a copyright registration for a graphic art work entitled ""A Recent Entrance to Paradise,"" which Thaler alleges was authored by his ""creativity machine."" The District Court ruled that a work authored wholly by a machine is not protected by copyright, and the case is now on appeal.",Creativity Machine,Federal: US Dist. Ct. D. D.C.,Generative AI,Administrative Procedure Act,AI as Author,2022-06-02,10/18/2023,https://blogs.gwu.edu/law-eti/?page_id=10&pid=81,Active,"This is the first US federal court case holding that a work generated entirely by an artificial system absent any human involvement was not eligible for copyright protection, because human authorship is an essential part of a valid copyright claim.  It is now on appeal, but will likely be affirmed. It is important to note that Thaler misrepresented that his ""Creativity Machine"" acted entirely on its own in creating the work.  During the litigation, he tried to revise his story, claiming more human involvement, but the court held that he could not change a closed administrative record.  The question of when we would recognize a machine as ""acting entirely on its own"" raises many complications that the Copyright Office and this court did not face. Thus, this case stands for the proposition that if a machine acts entirely on its own - a claim that the Copyright Office and the court took at face value -- then a work created by that machine would not be subject to copyright protection.","Summary of Facts and Activity to DateOn November 13, 2018, Stephen Thaler applied to the U.S. Copyright Office to register a claim of copyright in a graphic art work titled ""A Recent Entrance to Paradise.""  He listed the ""Creativity Machine"" as the author of the work, noting that the work was ""autonomously created by machine,"" and he listed himself as the Copyright Claimant, by virtue of his ""ownership of the machine."" The Copyright Office refused to register the work on the ground that it lacked human authorship. In a letter opinion dated February 14, 2022, the U.S. Copyright Office Review Board rejected Thaler's Second Request for Reconsideration for Refusal to Register the work. The Review Board concluded that judicial precedent, federal agency precedent, and Copyright Office practice all require human authorship as a condition of copyright protect.  The Review Board also rejected Thaler's contention that the work was a ""work made for hire.""  Thaler then brought this action in federal court under the Administrative Procedure Act, challenging the Copyright Office's refusal to register a work alleged to have been created by artificial intelligence. Thaler moved for summary judgment on January 10, 2023; the Copyright Office filed a cross-motion for summary judgment on February 7, 2023. On August 18, 2023, Judge Beryl A. Howell granted the Copyright Office's motion, ruling that a work ""generated entirely by an artificial system absent human involvement"" is not eligible for copyright.",District Court judgment appealed to the U.S. Court of Appeals for the D.C. Circuit,2022.0,Active
109,109,The New York Times Company v. Microsoft,"The New York Times Company sues Microsoft and OpenAI, alleging that they have committed direct, contributory and vicarious copyright infringement; misappropriation of news items, and trademark dilution through the training and operation of their generative AI services Copilot and ChatGPT.","ChatGPT, Copilot",Federal: US Dist. Ct. S.D.N.Y.,Generative AI,"Copyright Infringement, Trademark Dilution, Commercial Misappropriation, 17 U.S.C. 1202 Removal of Copyright Management Information",Copyright Infringement,2023-12-27,12/27/2023,https://blogs.gwu.edu/law-eti/?page_id=10&pid=107,Active,,"Summary of Facts and Activity to DateThe New York Times Company filed its complaint on December 27, 2023.",Complaint filed,2023.0,Active
110,110,Thomson Reuters Enterprise Centre GmbH v. ROSS Intelligence Inc.,"Thomson Reuters alleges that ROSS Intelligence induced another company to copy content from its Westlaw online legal research service, including both judicial opinions and West key numbers and headnotes, and used it to create its own competing legal research service, giving rise to claims for copyright infringement and tortious interference with contractual relations.",,Federal: US Dist. Ct. D. Del.,"Legal Research, Natural Language Processing",Copyright Infringement,"Copyright Infringement, Fair Use",2020-05-06,9/25/2023,https://blogs.gwu.edu/law-eti/?page_id=10&pid=102,Active,"This case may go to a jury on the question of whether copying of works protected by copyright for the purpose of machine learning is a fair use. The District Court denied cross-motions for summary judgment on that issue, holding that there were open issues of fact, including whether ROSS was training an algorithm to imitate the style of Westlaw attorneys who were writing the headnotes used as training data, or was training the algorithm to recognize ideas conveyed in those headnotes and in the associated judicial opinions.  Importantly, the court's opinion suggests that ROSS's use of the headnotes to train a natural language legal research algorithm might be transformative, even though the resulting service might compete with Westlaw.","Summary of Facts and Activity to DateDefendant ROSS Intelligence allegedly obtained very large portions of the Westlaw database, including both the text of judicial opinions, and key numbers and headnotes added by West, from another company that downloaded them from the Westlaw website, for the purposes of creating a competing legal research database that would use natural language searching. In cross-motions for summary judgment, the parties have focused on whether the copying of Westlaw headnotes by ROSS Intelligence amounts to prima facie copyright infringement, and if so whether that copying is a fair use.  The court denied cross-motions for summary judgment on both issues, thus setting up the case for a jury trial. The court granted ROSS's motion for summary judgment on one of Thomson Reuters's three counts of tortious interference with contract, holding that the claim of breach of a provision prohibiting use of Westlaw materials to build a competing product was preempted by federal copyright law.  However, it denied ROSS's summary judgment motion on two other counts of tortious interference, holding that claims of breach of provisions prohibiting use of a bot to scrape Westlaw content, and prohibiting sharing of passwords, were not preempted.",Opinion and order on cross-motions for summary judgment,2020.0,Active
111,111,"Thornley v. Clearview AI, Inc.",Clearview has appealed Remand in 7th Cir.,Clearview,State: Illinois Cir. Ct. (Cook County); Removd to N.D. Ill.; Transferred to US Dist Ct. S.D. New York BUT Remanded to Ill. Cir. Ct. (Cook County),Facial Recognition,,Privacy,2020-05-27,3/25/2021,https://blogs.gwu.edu/law-eti/?page_id=10&pid=39,Active,"This lawsuit differs from other lawsuits against Clearview because they seek only statutory damages and attorneys fees under BIPA 15(c) instead of seeking damages for actual injury of the scraping, collecting, and compiling of data under BIPA 15(a) and 15(b).","Summary of Facts and Activity to DateClass action from Cook County on June 30, 2020 to ND Illinois for statutory damages and attorneys fees for violating BIPA 15(c) which states that:  “No private entity in possession of a biometricidentifier or biometric information may sell, lease, trade, or otherwise profit from a person’s or a customer’s biometric identifier or biometric information.”Transferred to SDNY August 18, 2020. Plaintiffs then filed motion to remand for lack of Article III standing, because Clearview did not establish injury in fact of a concrete, particularized harm under the 15(c) claim. The court found that the plaintiff was allowed to make a narrow claim of relief, thus allowing the case to remand to state court.On October 30, 2020 order remanding back to Cook County, Clearview appealed to Seventh Circuit who affirmed remand, 7th Circuit Appeal Deny Petition for Rehearing on March 9, 2021. Remanded on March 10, 2021 to Cook County.",Case Set for Status call on 5/4/2021,2020.0,Active
112,112,"Tremblay v. OpenAI, Inc.","Authors Paul Tremblay and Mona Awad sue OpenAI, Inc. on behalf of themselves and all persons domiciled in the United States owning copyright in any work used as training data for OpenAI's ChatGPT large language models, including GPT-3.5 and GPT-4, alleging copyright infringement, removal of copyright management information, unfair competition, unjust enrichment, and negligence.",ChatGPT,Federal: US Dist. Ct. N.D. Ca.,Generative AI,"Copyright Infringement, Negligence, Unjust Enrichment, Unfair Competition, 17 U.S.C. 1202 Removal of Copyright Management Information",Copyright Infringement,2023-06-28,7/19/2023,https://blogs.gwu.edu/law-eti/?page_id=10&pid=92,Active,,"Summary of Facts and Activity to DatePlaintiffs allege that OpenAI trained its ChatGPT large language models, include GPT-3.5 and GPT-4, with literary works that were still under copyright, without the authorization of the owners of copyright in those works, including the plaintiffs or of anyone in the proposed class of US-domiciled authors and copyright owners whose books were so used. Plaintiffs filed their complaint on June 28, 2023.  The case was assigned to Judge Araceli Martinez-Olguin on June 29, 2023.  Plaintiffs filed a motion to relate this case with Silverman v. OpenAI on July 19, 2023.",Plaintiffs filed motion to relate case to Silverman v. OpenAI,2023.0,Active
113,113,Tyndaris v. VWM Limited,"Suit by Tyndaris for unpaid fees, countersuit by VWM for misrepresentation and breach of contract, first determining if under civil liabilty Tyndaris is responsible as a custodian for the algorithm's mistakes, expected to be landmark case as first UK case to discuss machine learning",,"International: London Commercial Court: the UK site is horrendously difficult to navigate, need a link to the case docket","Investment, Portfolio Management, Trading","Article 1465 of the Civil Code of Quebec, Breach of Contract","Misrepresentation to Client, Underperformance",2018-05-01,,https://blogs.gwu.edu/law-eti/?page_id=10&pid=12,Active,,Summary of Facts and Activity to Date,,2018.0,Active
114,114,"Umeda v. Tesla, Inc.","Court dismissed suit by estate of Japanese pedestrian killed by Tesla Autopilot operated by Japanese driver because Japan is an adequate alternative, denying plaintiff's motions for judicial notice of articles about Tesla personnel changes and Tesla's forecasts but granting Plaintiff's motion to include congrsesional hearings about autopilot and an article about the specific accident",Autopilot,Federal: US Dist. Ct. N.D. California,Autonomous Vehicles,"Design Defects, Failure to Warn, Loss of Consortium, Negligence, Survival Action, Wrongful Death","Product Liability, Underperformance",2020-04-28,1/15/2021,https://blogs.gwu.edu/law-eti/?page_id=10&pid=25,Inactive: Dismissed for Forum Non Conveniens,,Summary of Facts and Activity to Date,Motion Denied to Reconsider Dismissal for Forum Non Conveniens,2020.0,Dismissed
115,115,United States v. Curry,"Court found that there were no exigent circumstances to justify the police seizing a defendant with no suspicious activity near the scene of gunshots because an algorithm indicated the area would be a hot spot for criminal activity, where the concurrence and dissent addressed that predictive policing algorithms have been shown to have questionable effectiveness and clear racial bias.",,Federal: US Dist. Ct. E.D. Virginia,"Criminal Justice, Search and Seizure","Exigent Circumstances, Fourth Amendment","Human Programming Flaws, Predictive Policing, Unreliability, Use of Race",2017-10-03,9/25/2020,https://blogs.gwu.edu/law-eti/?page_id=10&pid=3,Inactive: Judgement for D,"Judge Gregory's concurrence concludes that predictive policing used to prevent crimes rather than solve them all depend on how the officers implement the information they are given when they reach the neighborhood to not perpetuate a high-tech version of racial profiling.Circuit Judge Wyn concurs to note that the Supreme Court has been reluctant to rely on studies and statistical inferences for constitutional issues, unlike the dissent suggestion.Judge Thacker concurs to address that predictive policing is just racial profiling with ""at best, questionable effectiveness."" Thacker further observes that the algorithm is only as good as the human programmer, and often the algorithms are programmed with racial biases inherent. An example is hot spot policing, which use neighborhood historical crime to predict future crime, often rampant with racial bias. Thacker and Wilkinson agree that the change must come to the police themselves, as it is the officers and not the algorithm that abuses their authority and causes fourth amendment violations.Judge Wilkinson’s dissent calls this ruling a ""gut punch"" to predictive policing, which is a smart policy that can prevent crimes from occurring. Wilkinson explains computer algorithms have replaced push pins and cork boards for hot spot policing, it is not a new phenomenon it has just improved with algorithms. Wilkinson's attitude is that the inherent dangers and difficulties of police work outweigh the potential for racial bias when considering utilizing hot spot policing.","Summary of Facts and Activity to DateOn September 7, 2017, the Richmond Police patrolled a hot spot neighborhood, and upon hearing gunshots, found Curry and another man walking and told them to show their hands. A struggle ensued after Curry did not show his waistband, with the officer locating a revolver.On October 3, 2017, a Grand Jury Convicted Curry of Possession of a Firearm by a Convicted Felon, for which he was arrested on October 4, 2017. Curry filed a motion to suppress on November 21, 2017 regarding the firearm and statements made during the encounter with the police officer who conducted the Terry stop. The officer stopped Curry and another man who were walking near a neighborhood where gunshots reported. Following a hearing and supplemental briefing into January 2018, where the parties disagreed on the moment that Curry was seized. The court on March 19, 2018 granted the Motion to Suppress because the ""officer's subjective interpretation of Curry's actions"" could not inform whether the stop was justified or violated the 4th amendment, noting particularly that the officer was not just stopping Curry and asking to see his hands.The 4th Circuit remanded back to the district court to determine if the stop and flashlight search violated the Fourth Amendment based on exigent circumstances in September 2019.Amended in July 2020, the 4th Circuit affirmed the granting of a motion to suppress on grounds that exigent circumstances did not justify the ""suspicionless, investigatory stop."" The concurrence and dissent in this opinion provide key insights into algorithms.",Terminated,2017.0,Decided
116,116,"United States v. Meta Platforms, Inc.","On June 27, 2022, the court approved the parties’ settlement agreement and entered a final judgment in United States v. Meta Platforms, Inc., f/k/a Facebook, Inc. (S.D.N.Y.). The complaint, which was filed on June 21, 2022, alleged that Meta’s housing advertising system discriminated against Facebook users based on their race, color, religion, sex, disability, familial status, and national origin, in violation of the Fair Housing Act (FHA). Specifically, the complaint alleged, among other things, that Meta uses algorithms in determining which Facebook users receive housing ads and that those algorithms rely, in part, on characteristics protected under the FHA. Under the settlement, Meta stopped using an advertising tool (known as the “Special Ad Audience” tool) for housing ads and developed a new system, the Variance Reduction System (VRS), to address racial and other disparities caused by its use of personalization algorithms in its ad delivery system for housing ads.",,"District Court, S.D. New York","Civil Rights, Housing",Fair Housing Act,"Advertising DIscrimination, Socioeconomics Bias, Targeted Advertising, Use of Race, User of Gender",2022-06-21,10/30/2023,https://blogs.gwu.edu/law-eti/?page_id=10&pid=111,Inactive,This is the first case the United States has filed challenging algorithmic bias under the FHA.,"Summary of Facts and Activity to DateOn June 21, 2022, the United States filed this suit against Meta (formerly known as Facebook, Inc.) in the U.S. District Court for the Southern District of New York to enforce the Fair Housing Act (“FHA”). The FHA prohibits discrimination in housing, including housing-related advertising, on the basis of race, color, religion, sex, disability, familial status, and national origin (“FHA-protected characteristics”). The United States alleged that Meta’s housing advertising system discriminated against its users by excluding users from receiving certain housing ads based on users’ FHA-protected characteristics. The United States sought declaratory and injunctive relief as well as monetary damages and a civil penalty. U.S. District Judge John G. Koeltl presided over this case. This is the first case the United States has filed challenging algorithmic bias under the FHA.The United States challenged three aspects of Meta’s ad targeting and delivery system for violating the FHA: 1) Trait-Based Targeting (that Meta encouraged advertisers to target ads by including or excluding Meta users based on FHA-protected characteristics); 2) “Lookalike” Targeting (that Meta created a machine-learning algorithm to find users who look like an advertiser’s source audience, partly based on FHA-protected characteristics, and are thus eligible to receive housing ads); and 3) Delivery Determination (that Meta used machine-learning algorithms that party rely on FHA-protected characteristics to help determine which subset of an advertiser’s targeted audience will actually receive a housing ad).On June 21, 2022, the United States obtained a settlement agreement, which was approved by the court five days later. The settlement required Meta to stop using an advertising tool that relied on FHA-protected characteristics to identify which users would be eligible to receive housing ads. Meta was further required to create a new system for housing ads to address racial and other disparities caused by its use of personalization algorithms. After reaching the settlement, Meta created a new system to address its prior algorithmic discrimination and, on January 9, 2023, the U.S. and Meta agreed on that new system’s compliance targets. Consequently, Meta will be subject to oversight and continuing compliance reviews through June 27, 2026. The parties also selected a third-party reviewer to ensure Meta adheres to the targets during the oversight period, although the court will have final say over any disputes regarding the information that Meta provides.On June 29, 2023, the third-party reviewer, Guidehouse Inc., issued its first report on VRS Compliance Metrics Verification.  On October 30, Guidehouse issued its second report on VRS Compliance Metrics Verification.",third-party reviewer issued its second report on VRS Compliance Metrics Verification,2022.0,Inactive
117,117,United States v. Wilson,The 9th Circuit found that the defendant's Fourth Amendment rights were violated when Google's algorithm—without opening the email—detected child pornography attached to one of the emails he sent and reported it to law enforcement.,Image matching system,9th Cir.,"Constitutional Law, Criminal Justice, Privacy, Search and Seizure",Fourth Amendment,"Law Enforcement, Privacy",2023-06-27,,https://blogs.gwu.edu/law-eti/?page_id=10&pid=85,Inactive: Judgment for D,,Summary of Facts and Activity to Date,,2023.0,Decided
118,118,Van Pelt v. Cigna Group,"The action, which was filed in the U.S. District Court for the District of Connecticut, captioned Van Pelt v. The Cigna Group, et al., Case No. 3:23-cv-01135, alleges that Defendants have implemented sophisticated automated intelligence capabilities to systematically defraud consumers by denying medically necessary claims en mass without appropriate physician review. The action further alleges that Cigna’s automated systems allow its medical directors to automatically deny medically necessary claims without even opening patient medical records. The action further alleges that Cigna’s automated review program reportedly automatically denied without review over 300,000 claims, spending an average of 1.2 seconds on each claim.",,US District Court for the District of Connecticut,"Civil Rights, Health","Breach of Contract, Unfair and Deceptive Trade Practices, Unjust Enrichment","Accountability, Individualized Assessment, Lack of Human Review, Lack of Remedy, Misuse of AI",2023-08-25,11/6/2023,https://blogs.gwu.edu/law-eti/?page_id=10&pid=114,Inactive,"This was the second lawsuit against Cigna over its use of the computer algorithm to deny claims. Plaintiff Paige Van Pelt makes similar claims as Kisting-Leung over Cigna's use of an algorithm called PXDX, shorthand for ''procedure-to-diagnosis,” to identify whether claims met certain requirements.","Summary of Facts and Activity to DateThe lawsuit was filed in U.S. District Court in Connecticut Aug. 25, a class action lawsuit filed against Bloomfield-based insurer Cigna, claiming it has used automated intelligence technology to deny medical care claims - sometimes within seconds.The lead plaintiff is Paige Van Pelt, a Minnesota woman, though it was also filed “on behalf of others similarly situated.”Van Pelt has Lynch Syndrome, which can create a genetic predisposition to cancer, according to the lawsuit. Because of this, she needs a colonoscopy every one to two years. In 2018, Cigna automatically denied coverage for her colonoscopy and endoscopy, because the clinic coded it as diagnostic instead of preventative. Van Pelt was billed $3,200, which has since been set to collections, according to the lawsuit.The defendants include The Cigna Group, Cigna Corp. and Cigna Life Insurance Co.The lawsuit claims Cigna used an automated intelligence system referred to as “procedure-to-diagnosis,” or “PxDx.” The litigation alleges the insurer’s automated review program automatically denied without review more than 300,000 claims in a two-month period, spending an average of 1.2 seconds on each claim.The lawsuit asserts denials without appropriate physician review violates state and federal consumer protection laws.The litigation further claims members of the class have had to pay for medical services that should have been covered and paid by their insurance. It alleges Cigna has saved “millions, if not billions, of dollars,” through the practice, since most patients will typically pay the bills or forgo procedures, rather than appeal a denial.The lawsuit alleges breach of contract and violations of the Connecticut Unfair Trade Practices Act,  Connecticut Unfair Insurance Practices Act and the Connecticut Corrupt Organizations and Racketeering Activity Act.Cigna Healthcare issued a written statement denying the claims and any wrongdoing.On November 6th, 2023, Plaintiffs voluntarily dismissed the claims.",Plaintiff's Voluntary Dismissal,2023.0,Inactive
119,119,Velesaca v. Decker,"Class action filed by non citizens detained in New York challenging the ""no release policy,"" arguing that a change to the assessment algorithm resulted in a lack of ICE bond hearings and solely recommending detention, with preliminary injunction granted to return to individualized assessment due to COVID safety",Risk Classification Assessment Tool,Federal: US Dist. Ct. S.D. New York,"Detention and Release, Immigration","5th Amendment, Administrative Procedure Act, Due Process Clause, Immigration and Nationality Act, Preliminary Injunction, Rehabilitation Act","Programmer Bias, Use of Race",2020-02-28,3/8/2021,https://blogs.gwu.edu/law-eti/?page_id=10&pid=49,Active: Settlement Negotiations,"The switch to the risk assessment algorithm from individualized assessments is at the center of this case, and that ICE manipulated the algorithm to remove the release alternative so that detention was the only option. The complaint illustrates this with the statistics: 47% of low risk individuals were granted release from 2013 to 2017, but only 3% of low risk individuals were granted release from June 2017 to September 2019.","Summary of Facts and Activity to DateBefore 2017, ICE conducted individual assessments to determine detention or release, but in 2017 it switched to its Risk Classification Assessment Tool, which the complaint argues always determines detention is necessary. On February 28, 2020, a noncitizen filed this class action against ICE for the lack of bond hearings that are required within 48 hours of arrest in New York City. Now those detained in local jails have to wait months in inadequate conditions before going before an immigration judge.The two subclasses are the Petitioner subclass who were eligible to be considered for bond or release who have been or will be detained without bond, and the Rehabilitation Act subclass who are individuals with a disability eligible for bond or release consideration who have been or will be detained without bond.Preliminary injunction was granted even with defendants arguing that the no release policy does not exist, and that plaintiffs have not exhausted all other remedies before filing this complaint. The court granted the PI on expedited circumstances on March 31, and filed its reasoning on May 4. In its reasoning, the court ordered ICE to return to its pre-2017 policy and conduct individualized release assessments for the named plaintiffs and proposed classes. Citing medical experts who testified that the risk of COVID is more intense in ICE facilities, and a Stanford statistician who verified the change in release rate, the court directed ICE to file a report with the court by April 17 about each individual held without bond.The court denied defendant's motion to amend the PI, stating that ICE now had until May 22 and every week thereafter to report on its progress of identifying and individually assessing each individual held without bond.On July 1, 2020 the court issued a protective order.The court denied defendant's motion to clarify the PI in July 2020. ICE argued that the injunction was ""insufficiently specific as to what ICE must do, unduly broad as to its coverage, and not applicable to persons detained as of April 10, 2020"" but the court denied this order it was clearly meant to apply to those ""now or hereafter arrested"" so including those as of April 10. Defendants filed an appeal but withdrew by October.On August 25 the court ordered defendants to provide custody worksheets of all detainees to petitioners no later than September 8, along with all written correspondence to and from ICE officers after March 31, 2020 and written guidance on court's injunction. By September 1 the defendants were ordered to produce a full administrative record.In September the court granted plaintiff's deposition order about personnel training related to the injunction, set an October deadline for any remaining discovery disputes, and denied ICE's request for extension of time.The court ordered defendants to respond in November, and then submitted on December 4 an order requiring parties to submit their recommended discovery order for Court's consideration, and defendants filed their opposition to enforcing the PI.The case was directed to a magistrate judge for settlement proceedings, and scheduled on March 18.",Settlement proceedings,2020.0,Active
120,120,"Vermont v. Clearview AI, Inc.","Vermont Attorney General brought three Vermonst consumer protection claims: unfair and deceptive practices by collection photographs and making misrepresenations about their program and fraudelently acquiring brokered personal information against Cleaview, and it survived a motion to dismiss where Clearview argued 1A, 230, Standing and Venue in M2D",Clearview,State: Vermont Sup. Ct. (Chittenden Unit),Facial Recognition,UDAP,"Law Enforcement, Privacy",2020-03-01,9/20/2020,https://blogs.gwu.edu/law-eti/?page_id=10&pid=36,Active,"This case survived a motion to dismiss in the lower court.The court allowed the Vermont AG's claim that Clearview's actions qualify under the Vermont Consumer Protection Act for an unfairness claim: immoral, unethical, oppressive or unscrupulous. Additionally, the court did not dismiss the claim relating to substantial injury by the unwanted surveillance and marketing Clearview to law enforcement.","Summary of Facts and Activity to DateVermont's Attorney General brought three claims against Clearview: 1. Clearview's privacy policy misrepresents when it says it does not process data it does not have permission for, 2. unfair and deceptive to scan thousands of pictures from social media without permission, and 3. web scraping social media for images was fraudulent acquisition under Vermont State Law.Ruling on Clearview's motion to dismiss, the superior court struck down two of Vermont's three claims: 1. misrepresentation because no way to verify at the time it was made, and 2. the web scraping was not fraudulent/misrepresentation, and made a comparison to larceny. The court was not convinced by Clearview's arguments for standing, venue, Section 230, or the first amendment. The court allowed the claim of statements about Clearview's use of social media pictures being deceptive to continue. Clearview deceived consumers about the ability to opt out of Clearview's database, the purpose and use of the information (being for law enforcement and not personal purposes), that it had success in assisting in law enforcement investigations, match accuracy success, and removing information based on geography.",Court ruling on motion to dismiss,2020.0,Active
121,121,"Walters v. OpenAI, L.L.C.","Plaintiff sues developer of ChatGPT for defamation, alleging that ChatGPT generated false and defamatory statement about him as having embezzled from an organization called the Second Amendment Foundation. Defendant removes to this federal court.",ChatGPT,Federal: US Dist. Ct. N.D. Ga.,Generative AI,Defamation,Unreliability,2023-07-14,7/14/2023,https://blogs.gwu.edu/law-eti/?page_id=10&pid=96,Active,,"Summary of Facts and Activity to DatePlaintiff sues developer of ChatGPT for defamation, alleging that ChatGPT generated false and defamatory statement about him as having embezzled from an organization called the Second Amendment Foundation. Defendant removes to this federal court.",Filing of Notice of Removal,2023.0,Active
122,122,"Walters v. OpenAI, LLC","Plaintiff sues developer of ChatGPT for defamation, alleging that ChatGPT generated false and defamatory statement about him as having embezzled from an organization called the Second Amendment Foundation. Defendant removed to federal court.",ChatGPT,"State: Georgia, Superior Ct. of Gwinnett County",Generative AI,Defamation,Reliability,2023-06-05,7/14/2023,https://blogs.gwu.edu/law-eti/?page_id=10&pid=95,Inactive,,"Summary of Facts and Activity to DatePlaintiff sued developer of ChatGPT for defamation, alleging that ChatGPT generated false and defamatory statement about him as having embezzled from an organization called the Second Amendment Foundation.  Defendant OpenAI removed the action to federal court (the Northern District of Georgia)",Removal by defendant to Federal Court,2023.0,Inactive
123,123,"Waymo LLC v. Uber Technologies, Inc.","Waymo sued Uber and Ottomotto for patent infringement and violations of trade secret laws, claiming that its former employee, Levandowski, improperly downloaded documents related to Waymo’s driverless vehicle technology, then left Waymo to found Ottomotto, which Uber subsequently acquired.",,Northern District of California,Patent,"Defend Trade Secrets Act Of 2016, Unjust Enrichment",Transparency/Trade Secrecy,2017-02-23,2/9/2018,https://blogs.gwu.edu/law-eti/?page_id=10&pid=131,Inactive,,"Summary of Facts and Activity to DateAnthony Levandowski, a former engineer for Waymo—a subsidiary of Google that has been one of the early companies to specialize in driverless cars—abruptly quit his job at Google in January, 2016 and started his own self-driving vehicle company called Otto. In doing so, though, he allegedly downloaded and stole nearly 14,000 files from Waymo that he took with him. Shortly thereafter, Uber purchased Otto and—according to Waymo—also acquired all of the stolen trade secrets that Levandowski took with him. Uber placed Levandowski in charge of its own driverless car division.The technology that is alleged to have been stolen revolved around Lidar technology (known as “light detection and ranging” technology), which is used in self-driving cars to allow vehicles to “see” around them and to detect other vehicles, bikers, pedestrians, animals, or other obstacles. The technology is integral to autonomous vehicles.Waymo filed a lawsuit in Federal Court in California, alleging that Uber conspired with Levandowski to create a fake company that would then be purchased by Uber (along with the trade secrets). Waymo alleged that the goal was to steal its trade secrets related to its self-driving-car team. As an indication of the value of the technology, Levandowski’s young company, Otto, was purchased by Uber for $680 million in 2016.While Waymo began the suit with both trade secret and patent claims, the latter were dropped, leaving eight trade secrets for the companies to battle over.On February 9th, 2018, only five days into a trial that was expected to go on for weeks, Uber settled a legal battle with Waymo over the latter’s accusation of stolen trade secrets relating to self-driving car technology. Under the settlement agreement, Uber will pay Waymo 0.34% of its equity, a share which is valued at approximately $245 million. The settlement also contains an agreement prohibiting Uber from using Waymo’s confidential information in its autonomous vehicle technology.",ORDER DENYING ADMINISTRATIVE MOTIONS TO FILE UNDER SEAL,2017.0,Inactive
124,124,"Waymo LLC. v. Uber Technologies, Inc.",Plaintiff Waymo filed suit against Uber claiming a violation of trade secrets in the area of self driving vehicles.,,"District Court, N.D. California",Autonomous Vehicles,Defend Trade Secrets Act Of 2016,"Transparency/Trade Secrecy, Autonomous Vehicle",2017-02-23,2/9/2018,https://blogs.gwu.edu/law-eti/?page_id=10&pid=135,Inactive: Settlement,,"Summary of Facts and Activity to DateWaymo was a company under Google and began work on self-driving vehicles back in 2009. Anthony Levandowski was the co-founder of Waymo but eventually left the company to begin his own start-up Otto, which was later acquired by Uber. Waymo's complaint alleges that shortly before Levandowski left the company he downloaded more than 14,000 documents which related to Google's self-driving car plans. Waymo also alleges that Uber sought to acquire Otto with full knowledge of the files and Uber wanted to use them for their own self-driving car plans. On February 9, 2018, the parties settled the case for 245 million dollars.",Settlement,2017.0,Settled
125,125,WeRide Corp. v. Kun Huang,"Autonomous vehicle companies won suit against a former employee and his current autonomous vehicle employer for misappropriation of trade secrets, succeeding on likelihood to succeed on the merits when they demonstrated particular files in the code base and demonstrated that the source code was only accessible on-site or using a VPN by employees.",,"Federal: United States District Court, N.D. California, San Jose Division","Autonomous Vehicles, Intellectual Property",,"Transparency/Trade Secrecy, Functionality, Autonomous Vehicle",2018-11-29,5/8/2020,https://blogs.gwu.edu/law-eti/?page_id=10&pid=59,Inactive,"A key finding for misappropraition cases, the court here found that ""[t]he implausibly fast development of technology can contribute to finding misappropriation"" when AllRide and former WeRide employees developed strikingly similar technology in a fast turnaround from leaving WeRide.",Summary of Facts and Activity to Date,"Date Terminated, last known filing",2018.0,Inactive
126,126,Williams v. City of Detroit,"In January 2020, Detroit police officers arrested Robert Williams on his front lawn, in front of his wife and two young daughters, on charges that he had stolen watches from a Shinola store in Detroit. The arrest was based almost entirely on a facial recognition scan from security footage at the Shinola store, but it was dead wrong: Mr. Williams was not the man in the security footage and was nowhere near the store at the time of the theft. In April 2021, the University of Michigan Law School’s Civil Rights Litigation Initiative (CRLI), the American Civil Liberties Union, and the ACLU of Michigan filed a federal lawsuit on behalf of Farmington Hills, Michigan resident Robert Williams, who is suing the Detroit Police Department for wrongfully arresting and jailing him based on faulty facial recognition technology.",,U.S. District Court for the Eastern District of Michigan,"Criminal Justice, Detention and Release, Facial Recognition, Generative AI","42 USC 1983, Civil Rights, Fourth Amendment","Facial Recognition, Lack of Human Review, Law Enforcement, Socioeconomics Bias, Reliability",2021-04-13,12/7/2023,https://blogs.gwu.edu/law-eti/?page_id=10&pid=124,Active,"Mr. Williams’ experience was the first case of wrongful arrest due to facial recognition technology to come to light in the United States, according to the lawsuit.Discovery in the case has exposed systemic and comprehensive failures to use facial recognition technology responsibly and to train detectives in basic investigatory techniques and legal requirements.","Summary of Facts and Activity to DateThis case involves the use of Facial Recognition Technology (“FRT”) by the Detroit Police Department (“DPD”). The plaintiff, a Black individual, represented by the ACLU of Michigan and the University of Michigan's Civil Rights Litigation Initiative, filed suit in the U.S. District Court for the Eastern District of Michigan on April 13, 2021. The plaintiff sued the City of Detroit (“City”), the DPD Chief, and an individual DPD detective under 42 U.S.C. § 1983. He alleged that the DPD used a blurry FRT image to identify him as a shoplifter in 2018 and that the use of FRT led the DPD to wrongfully arrest and detain him for thirty hours.The complaint alleged that the wrongful arrest and imprisonment violated the plaintiff’s Fourth Amendment rights and Michigan state law, and that the City failed to properly train DPD officers about the deficiencies of FRT. Because FRT misidentifies Black people at disproportionately high rates, the plaintiff further alleged that DPD violated Michigan’s racial discrimination statute. He sought damages, attorneys’ fees, and declaratory and injunctive relief. The case was assigned to District Judge Laurie J. Michelson and Magistrate Judge David R. Grand.The court dealt with discovery issues from July 2021 until July 2023, and Magistrate Judge Grand held a status conference on July 10. The plaintiffs additionally filed an amended complaint on June 23. The case is ongoing as of November 18, 2023.",STIPULATION AND ORDER to Amend Scheduling Order.,2021.0,Active
127,127,"Williams-Sonoma, Inc. v. Amazon.com, Inc.","Williams-Sonoma sued Amazon for, among other things, copyright infringement stemming from Williams-Sonoma-owned photographs that an Amazon algorithm selected for display on Amazon's website from photographs submitted by third-party vendors. The court denied Amazon's motion to dismiss, holding that there were sufficient allegations that Amazon engaged in ""volitional conduct"" through its algorithm in selecting the photographs, and that Amazon's algorithm took actions that disqualified it from DMCA section 512(c) safe harbor protection.",,Federal: U.S. Dist. Ct. N.D. California,Copyright,Copyright Infringement,Infringement,2018-12-13,4/19/2021,https://blogs.gwu.edu/law-eti/?page_id=10&pid=76,Inactive,"The court's ruling on the motion to dismiss the copyright infringement claim in this case suggests that the actions of a computer algorithm that are in some sense ""automatic,"" in the sense that no human being is directly controlling or aware of them, can nonetheless be sufficient ""volitional acts"" of the company that is running that algorithm to render that company liable for direct copyright infringement. The allegations were that ""Amazon's image-selection algorithm affirmatively selects the image using 'multi factor criteria' designed and employed to enhance product sales and boost internet traffic on Amazon's website,"" and picking the most attractive photo increases the risk that it will infringe professionally produced photos. The court also held that, at least on a motion to dismiss, it could not hold that the Williams-Sonoma photos were ""stored at the direction of the user,"" as is required to qualify for the DMCA safe harbor under section 512(c), because Amazon allegedly had complete control over which photos would be displayed on its marketplace web pages.","Summary of Facts and Activity to DateWilliams-Sonoma sued Amazon for trademark infringement, design patent infringement, unfair competition, and copyright infringement arising from the sale of ""Williams-Sonoma""-branded merchandise on Amazon's third-party online marketplace. The copyright infringement claim stemmed from photographs in which Williams-Sonoma owned copyright that an Amazon algorithm selected for display from photographs submitted by third-party vendors.  The court denied Amazon's motion to dismiss, holding that there were sufficient allegations that Amazon engaged in ""volitional conduct"" through its algorithm in selecting the photographs, and that Amazon's algorithm took actions that disqualified it from DMCA section 512(c) safe harbor protection.  The case then settled.",Case settled,2018.0,Inactive
128,128,Woodruff v. City of Detroit,A woman who says she was wrongfully arrested after facial recognition technology misidentified her as a suspect in a carjacking and robbery — while she was eight months pregnant — is suing the police department that detained her.,,"District Court, E.D. Michigan","Criminal Justice, Detention and Release, Facial Recognition, Generative AI",Fourth Amendment,"Facial Recognition, Law Enforcement, Socioeconomics Bias, Unreliability, Use of Race, Reliability",2023-08-03,12/7/2023,https://blogs.gwu.edu/law-eti/?page_id=10&pid=123,Active,"Porcha Woodruff, who was eight months pregnant at the time, is the sixth person to report being falsely accused of a crime as a result of facial recognition technology used by police to attempt to match an unknown suspect’s face to a photo in a database. All six people have been Black and Ms. Woodruff is the first woman to report it happening to her.Experts have pointed out the fact that mistaken identity is built into the software, which has always worked less effectively when it comes to people of color. The Detroit Justice Center has condemned the use of this technology since its inception due in large part to its faulty nature. However, even if it were effective 100% of the time, facial recognition would be used disproportionately against Black and brown Detroiters by nature of racial bias in policing and incarceration. Technology like facial recognition software, Shotspotter and license plate readers are being used in Detroit as substitutes for solutions that get at root causes of harm and crime.","Summary of Facts and Activity to DateWoodruff, 32, learned that the police had charged her with robbery and carjacking after facial recognition software mistakenly matched an eight-year-old photo of her — taken when she was detained for driving with an expired license — with video footage of a suspect. The victim, who had been robbed and carjacked at gunpoint, had also pointed to the old photo of her on a lineup.She filed a lawsuit against the city of Detroit and a detective in the U.S. District Court for the Eastern District of Michigan on August 3, 2023, alleging false arrest, false imprisonment and a violation of her Fourth Amendment rights to be protected from unreasonable seizures.Upon arriving at the Detroit Detention Center, she informed staff that she has gestational diabetes. Detective LaShauntia Oliver, who is named in the lawsuit, then questioned her on whether she knew certain people or frequented a gas station linked to the case, and asked her to show her tattoos. The detective also told Woodruff that the carjacking victim had not described the suspect as a pregnant woman.“Despite knowing the plaintiff was not involved in the robbery or carjacking, Detective Oliver directed plaintiff back to the holding cell,” the complaint stated. It also accused the police department of failing to use a more recent driver’s license photo of Woodruff in the facial recognition software and in photo lineups, and of neglecting to ask another suspect in custody whether he recognized Woodruff.She was released from custody around 11 hours after her arrest, after being arraigned on robbery and carjacking charges, according to the complaint.",Preliminary WITNESS LIST by All Defendants,2023.0,Active
129,129,Zalatel v. Prisma Labs,"The district court balanced the trademark infringement likelihood of confusion factors, focusing on the functionality of the defendant's machine learning programming that creates a machine redrawn image rather than photo filtering",,Federal: District Court District of Delaware,"Infringement, Intellectual Property",Trademark infringement,Functionality,2016-09-19,6/8/2017,https://blogs.gwu.edu/law-eti/?page_id=10&pid=56,Inactive,"In considering the motion to dismiss, the court contrasted the defendant's app from Zaletel in its interactions with indiivduals: individuals do not make an account, it is free to download from a third party platofrm, and it does not track the location of the app.","Summary of Facts and Activity to DatePlaintiff Zaletel created an app ""Prizmia for GoPro"" to edit pictures from GoPro and first launched it in the app store in August of 2014. The marketed features of this app included ""professional filters and effects, independent color grading controls for contrast, saturation, gamma and brightness, optical slow motion speed adjustment, live filters preview, Direct GoPro media library access and full control over all GoPro settings and features."" Zaletel subsequently registered a trademark for this photoediting app ""Prizmia"" on February 3, 2015. As of 2016, the app evolved to ""allow users to modify photographs or videos with filters that alter the photo's style or add an artistic effect."" In May of 2016, Zaletel renamed the app merely ""Prizmia"" to avoid infringing on GoPro's mark. Defendant is a Russian software company with a Bay Area office who launched a photoediting app ""Prisma"" in June 2016. Prisma is marketed as using artificial intelligence to make a user's image look in the style of famous artists like Van Gogh and Picasso. While Prizmia costs 99cents in Apple Store, Prisma is free in Google Store and Apple Store that then links to a third party download site.  On August 31, 2016 Zaletel sent Prizmia a cease and desist letter. On September 29, 2016, Zaletel filed in Eastern Virginia for a jury trial, claiming that defendant, through defendant’s use of the “Prisma” mark, infringes on plaintiff’s registered “Prizmia” mark.  On November 22, Zaletel filed a Motion for Preliminary Injunction and Prisma Labs filed a Motion to Dismiss for Lack of Jurisdiction Or, In The Alternative, To Transfer Venue. On December 22, the court considered the defendant's motion to dismiss and found no personal jurisdiction in Virginia when defendant's servers could not track the location of an app, the app could not be downloaded from defendant's passive website but only through a third party download site, and individuals do not create an account with the Prisma app. Finding no presence in Virginia, especially no purposeful availment, However instead of transferring  to the Northern District of California, the court transferred to the Delaware because Prisma was incorporated in Delaware and thus subject to general jurisdiction. On March 6, 2017, the Delaware District Court judge denied the motion for preliminary injunction, finding Zaletel has made no showing of reverse confusion. The court weighed the Lapp test factors for likelihood of confusion: although the names Prisma and Prizmia sound and look the same and the defendant's intent by uploading the app during the month Zaletel removed it to rename,  the remaining factors weigh for the defendant: the lack of strength of the Prizmia mark, the consumer care to purchase a free Prisma app,  the lack of actual confusion. The most convincing factor was the competition and overlap, determining that the apps had two extremely different functions: Prisma is a photofiltering app using AI to redraw the pictures in a style, whereas Prizmia provides professional filters for pictures taken on GoPro. On April 4, Zaletel filed amendment complaint and counterclaim. However on June 8, 2017, the case was dismissed with prejudice against Zalatel",Dismissal of Case,2016.0,Inactive
130,130,"Zhang v. Baidu.Com, Inc.,",A group of New York residents who advocate for increased democracy in China sued Baidu for blocking their materials in the United States. The court found that allowing plaintiffs to sue Baidu for its editorial judgements would violate the First Amendment.,,S.D.New York,Civil Rights,Civil Rights,Accountability,2011-05-18,8/1/2014,https://blogs.gwu.edu/law-eti/?page_id=10&pid=77,Appeal Withdrawn,It is one of the first courts to decide whether search engines is protected by the First Amendment. It found thatallowing plaintiffs to sue Baidu for what are in essence editorial judgments about which political ideas to promote would run afoul of the First Amendment.,"Summary of Facts and Activity to DateA group of New York residents who advocate for increased democracy in China sued Baidu, the largest internet search engine in China, for blocking their pro-democracy materials in the United States where Baidu also operates.",,2011.0,Withdrawn
131,131,Zynda et al. v. Zimmer et al.,"Settlement agreement in which Michigan's Unemployment Insurance Agency admits no wrongdoing in its use of MiDAS (Michigan Integrated Data Automated System) that wrongfully accused 40,000 residents of fraud, in exchange for terms of reasonable review and investigation into UIA's procedure and policy, requiring future commnications in plain language and with adequate notice, and providing the claimant with reasons for why they were flagged for fraud and ability to appeal",MiDAS,Federal: US Dist. Ct. E. D. Michigan,"Agency, Civil Rights, Fraud, Unemployment Insurance","Due Process, Injunction, Social Security Act","Accountability, Lack of Human Review, Lack of Remedy, Notice, Role of Expert Testimony, Miscalculation",2015-04-21,2/2/2017,https://blogs.gwu.edu/law-eti/?page_id=10&pid=42,Inactive: Settled,,Summary of Facts and Activity to Date,Dismissed,2015.0,Settled
